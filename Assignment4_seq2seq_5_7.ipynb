{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment4_seq2seq_5.7.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Allen001822480/Info7374SpringTeam5/blob/Assignment4/Assignment4_seq2seq_5_7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "LcQiKi_qUvJf",
        "colab_type": "code",
        "outputId": "2889ecf7-df16-4033-d3fc-5e65e54cc1ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/Phylliida/Dialogue-Datasets"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'Dialogue-Datasets' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "mRlCrT_i-4eg",
        "colab_type": "code",
        "outputId": "8c1fad92-3c82-4fda-e78d-0c471152a772",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "import re\n",
        "tw = open('Dialogue-Datasets/BNCCorpus.txt')\n",
        "twitter = tw.read()\n",
        "data = [d for d in twitter.split('\\n')]\n",
        "data = [d for d in data if d != '']\n",
        "#data = eval('[%s]'%repr(data).replace('[', '').replace(']', ''))\n",
        "data = list(map(lambda x:re.sub(r'^A-Za-z\\d\\s\\,\\.\\!\\?\\'\\\"\\+\\-','',x), data))\n",
        "print(data[0:5])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['You enjoyed yourself in America', 'Eh', 'did you', 'Oh I covered a nice tripyes', 'Oh very good']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "f_ZI_NJL_F4d",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "l1 = ['won’t','won\\'t','wouldn’t','wouldn\\'t','’m', '’re', '’ve', '’ll', '’s','’d', 'n’t', '\\'m', '\\'re', '\\'ve', '\\'ll', '\\'s', '\\'d', 'can\\'t', 'n\\'t', 'B: ', 'A: ', ',', ';', '.', '?', '!', ':', '. ?', ',   .', '. ,', 'STA', 'END', 'sta', 'end']\n",
        "l2 = ['will not','will not','would not','would not',' am', ' are', ' have', ' will', ' is', ' had', ' not', ' am', ' are', ' have', ' will', ' is', ' had', 'can not', ' not', '', '', ' ,', ' ;', ' .', ' ?', ' !', ' :', '? ', '.', ',', '', '', '', '']\n",
        "\n",
        "for i, raw_word in enumerate(data):\n",
        "    for j, term in enumerate(l1):\n",
        "        raw_word = raw_word.replace(term,l2[j])\n",
        "    \n",
        "    data[i] = raw_word.lower()\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZJCSozFM_KYM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "data = list(map(lambda x:'STA '+x+' END', data))\n",
        "context = data[:50000:2]\n",
        "answers = data[1:50000:2]\n",
        "all = context + answers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_maMcVGXftv9",
        "colab_type": "code",
        "outputId": "573fe866-a30a-468b-dace-ed1becf75d0c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install vaderSentiment"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: vaderSentiment in /usr/local/lib/python3.6/dist-packages (3.2.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "I62rZb5JfyqB",
        "colab_type": "code",
        "outputId": "f05fa4d8-5b64-4e87-e45e-71303056d790",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "cell_type": "code",
      "source": [
        "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
        "analyzer = SentimentIntensityAnalyzer()\n",
        "context_sentiments = []\n",
        "answers_sentiments = []\n",
        "for sentence in context:\n",
        "  vs = analyzer.polarity_scores(sentence)\n",
        "  context_sentiments.append(vs['neg'])\n",
        "'''\n",
        "for sentence in answers:\n",
        "  vs = analyzer.polarity_scores(sentence)\n",
        "  answers_sentiments.append(vs['pos'])\n",
        "'''\n",
        "print(context_sentiments)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.0, 0.0, 0.0, 0.0, 0.0, 0.368, 0.0, 0.0, 0.0, 0.0, 0.195, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.101, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.524, 0.0, 0.0, 0.524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.153, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.086, 0.0, 0.0, 0.0, 0.082, 0.0, 0.0, 0.134, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.123, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.268, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.168, 0.0, 0.0, 0.0, 0.0, 0.076, 0.231, 0.113, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.141, 0.0, 0.0, 0.0, 0.0, 0.0, 0.235, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.281, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.209, 0.141, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.48, 0.0, 0.0, 0.0, 0.0, 0.0, 0.358, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.118, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.524, 0.0, 0.0, 0.0, 0.0, 0.524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.091, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.106, 0.0, 0.0, 0.263, 0.326, 0.0, 0.0, 0.306, 0.0, 0.0, 0.0, 0.0, 0.133, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.195, 0.174, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.237, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.296, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.252, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.213, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.394, 0.0, 0.0, 0.0, 0.0, 0.0, 0.254, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.138, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.106, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.381, 0.0, 0.0, 0.0, 0.231, 0.0, 0.0, 0.256, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.318, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.115, 0.124, 0.0, 0.148, 0.0, 0.0, 0.268, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.034, 0.078, 0.0, 0.0, 0.0, 0.0, 0.127, 0.0, 0.0, 0.0, 0.076, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.093, 0.0, 0.0, 0.271, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.067, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.142, 0.0, 0.344, 0.068, 0.0, 0.03, 0.111, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.155, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.089, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.174, 0.0, 0.0, 0.0, 0.0, 0.371, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.355, 0.0, 0.0, 0.136, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.219, 0.0, 0.257, 0.0, 0.0, 0.0, 0.0, 0.118, 0.0, 0.0, 0.0, 0.0, 0.444, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.132, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.119, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.245, 0.115, 0.0, 0.394, 0.0, 0.0, 0.0, 0.084, 0.0, 0.0, 0.0, 0.0, 0.127, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.074, 0.0, 0.0, 0.109, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.069, 0.0, 0.0, 0.185, 0.0, 0.0, 0.0, 0.036, 0.0, 0.0, 0.018, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.064, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.22, 0.0, 0.0, 0.0, 0.0, 0.199, 0.0, 0.0, 0.157, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.052, 0.0, 0.0, 0.135, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.131, 0.054, 0.09, 0.0, 0.385, 0.128, 0.113, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.206, 0.123, 0.25, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.085, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.022, 0.0, 0.04, 0.031, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08, 0.0, 0.0, 0.0, 0.076, 0.053, 0.0, 0.0, 0.0, 0.0, 0.126, 0.0, 0.077, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.109, 0.0, 0.013, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.161, 0.0, 0.0, 0.109, 0.0, 0.0, 0.0, 0.0, 0.0, 0.108, 0.0, 0.284, 0.0, 0.0, 0.0, 0.041, 0.0, 0.0, 0.0, 0.0, 0.0, 0.209, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.018, 0.0, 0.0, 0.0, 0.0, 0.396, 0.131, 0.37, 0.0, 0.044, 0.0, 0.0, 0.0, 0.0, 0.0, 0.018, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.106, 0.0, 0.0, 0.012, 0.0, 0.0, 0.0, 0.0, 0.076, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.394, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.093, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.524, 0.0, 0.048, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.189, 0.423, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.302, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.071, 0.0, 0.0, 0.0, 0.0, 0.123, 0.0, 0.0, 0.0, 0.129, 0.083, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.097, 0.0, 0.098, 0.156, 0.08, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.138, 0.0, 0.0, 0.0, 0.0, 0.353, 0.0, 0.0, 0.0, 0.0, 0.162, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.524, 0.093, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1, 0.088, 0.086, 0.524, 0.121, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.444, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.19, 0.0, 0.375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.268, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09, 0.0, 0.0, 0.0, 0.0, 0.296, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.524, 0.0, 0.0, 0.0, 0.0, 0.141, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.181, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.437, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.117, 0.0, 0.0, 0.0, 0.0, 0.212, 0.0, 0.0, 0.297, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.268, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.177, 0.0, 0.0, 0.0, 0.0, 0.137, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.365, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.268, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.155, 0.0, 0.0, 0.0, 0.0, 0.0, 0.524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.244, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.302, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.095, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.097, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.512, 0.0, 0.0, 0.0, 0.0, 0.054, 0.0, 0.0, 0.0, 0.524, 0.0, 0.0, 0.0, 0.0, 0.04, 0.0, 0.212, 0.0, 0.087, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.143, 0.0, 0.0, 0.0, 0.0, 0.0, 0.104, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.178, 0.0, 0.143, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.204, 0.0, 0.0, 0.154, 0.0, 0.0, 0.0, 0.394, 0.0, 0.0, 0.0, 0.027, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.355, 0.0, 0.0, 0.128, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.095, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.207, 0.301, 0.061, 0.153, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.065, 0.0, 0.0, 0.0, 0.124, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.151, 0.0, 0.0, 0.0, 0.118, 0.0, 0.0, 0.251, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.057, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.169, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.086, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.115, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.277, 0.0, 0.0, 0.0, 0.0, 0.448, 0.0, 0.0, 0.124, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05, 0.0, 0.0, 0.215, 0.0, 0.0, 0.274, 0.0, 0.0, 0.0, 0.348, 0.193, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.286, 0.28, 0.0, 0.0, 0.088, 0.042, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.333, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.508, 0.371, 0.0, 0.0, 0.109, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.355, 0.123, 0.524, 0.0, 0.0, 0.223, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.111, 0.0, 0.121, 0.0, 0.0, 0.0, 0.0, 0.099, 0.0, 0.0, 0.0, 0.113, 0.172, 0.0, 0.043, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.116, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.118, 0.0, 0.217, 0.0, 0.0, 0.0, 0.091, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.096, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13, 0.184, 0.0, 0.145, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.244, 0.0, 0.0, 0.0, 0.0, 0.0, 0.324, 0.0, 0.302, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.162, 0.0, 0.0, 0.0, 0.493, 0.0, 0.0, 0.306, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.167, 0.0, 0.0, 0.0, 0.0, 0.0, 0.26, 0.101, 0.102, 0.0, 0.0, 0.0, 0.0, 0.116, 0.364, 0.0, 0.0, 0.0, 0.298, 0.0, 0.0, 0.128, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.237, 0.253, 0.0, 0.524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.026, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.216, 0.0, 0.0, 0.524, 0.0, 0.0, 0.524, 0.0, 0.136, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.305, 0.0, 0.0, 0.0, 0.0, 0.268, 0.0, 0.119, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.068, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.119, 0.0, 0.17, 0.0, 0.0, 0.474, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.258, 0.086, 0.0, 0.0, 0.0, 0.0, 0.0, 0.31, 0.0, 0.231, 0.0, 0.0, 0.0, 0.324, 0.0, 0.222, 0.0, 0.0, 0.0, 0.0, 0.275, 0.0, 0.0, 0.266, 0.0, 0.42, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.104, 0.128, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.085, 0.0, 0.0, 0.0, 0.0, 0.524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.064, 0.0, 0.04, 0.0, 0.085, 0.0, 0.0, 0.0, 0.138, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.266, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.224, 0.0, 0.0, 0.524, 0.0, 0.0, 0.0, 0.176, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.15, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.195, 0.0, 0.0, 0.0, 0.049, 0.0, 0.0, 0.0, 0.0, 0.268, 0.0, 0.0, 0.0, 0.0, 0.524, 0.0, 0.0, 0.179, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.181, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.282, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.524, 0.0, 0.0, 0.199, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.141, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.39, 0.0, 0.0, 0.0, 0.524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.139, 0.0, 0.139, 0.0, 0.0, 0.0, 0.0, 0.0, 0.157, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.168, 0.0, 0.053, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.097, 0.0, 0.0, 0.0, 0.0, 0.0, 0.789, 0.0, 0.524, 0.106, 0.0, 0.0, 0.524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.266, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.524, 0.524, 0.0, 0.241, 0.256, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.211, 0.0, 0.0, 0.0, 0.0, 0.097, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.216, 0.0, 0.0, 0.0, 0.0, 0.0, 0.256, 0.237, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.225, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.423, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.244, 0.0, 0.0, 0.0, 0.0, 0.0, 0.325, 0.037, 0.545, 0.0, 0.0, 0.0, 0.204, 0.0, 0.0, 0.355, 0.0, 0.094, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.075, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.207, 0.33, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.209, 0.0, 0.0, 0.209, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.139, 0.0, 0.0, 0.0, 0.0, 0.04, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.524, 0.0, 0.22, 0.091, 0.0, 0.0, 0.111, 0.0, 0.0, 0.0, 0.175, 0.39, 0.0, 0.091, 0.18, 0.0, 0.0, 0.0, 0.0, 0.524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.068, 0.0, 0.0, 0.062, 0.181, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.524, 0.0, 0.162, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.31, 0.0, 0.0, 0.0, 0.524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.367, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.154, 0.0, 0.0, 0.0, 0.0, 0.081, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.087, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.268, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.091, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.127, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.234, 0.0, 0.0, 0.0, 0.0, 0.167, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.524, 0.213, 0.0, 0.0, 0.0, 0.0, 0.101, 0.0, 0.0, 0.0, 0.0, 0.0, 0.419, 0.0, 0.0, 0.524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.326, 0.0, 0.0, 0.0, 0.231, 0.524, 0.0, 0.0, 0.0, 0.0, 0.26, 0.0, 0.0, 0.0, 0.0, 0.0, 0.181, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.368, 0.299, 0.188, 0.0, 0.266, 0.0, 0.0, 0.0, 0.0, 0.367, 0.483, 0.0, 0.437, 0.0, 0.286, 0.286, 0.196, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.524, 0.0, 0.0, 0.0, 0.162, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.195, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.211, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.176, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.152, 0.0, 0.252, 0.0, 0.0, 0.0, 0.093, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.524, 0.0, 0.167, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.243, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.184, 0.0, 0.225, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.131, 0.0, 0.0, 0.0, 0.289, 0.0, 0.0, 0.0, 0.244, 0.0, 0.0, 0.524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.221, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.524, 0.0, 0.4, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.168, 0.153, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.187, 0.42, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.636, 0.146, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.218, 0.102, 0.367, 0.0, 0.0, 0.0, 0.0, 0.195, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.127, 0.0, 0.0, 0.0, 0.0, 0.152, 0.0, 0.0, 0.0, 0.0, 0.225, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.123, 0.524, 0.0, 0.0, 0.084, 0.0, 0.492, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.368, 0.0, 0.183, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.146, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.288, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.429, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.524, 0.239, 0.0, 0.0, 0.0, 0.0, 0.0, 0.479, 0.467, 0.138, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.329, 0.0, 0.31, 0.435, 0.0, 0.0, 0.0, 0.0, 0.106, 0.0, 0.0, 0.0, 0.0, 0.524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.423, 0.0, 0.0, 0.108, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.239, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.268, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.203, 0.0, 0.087, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.162, 0.0, 0.0, 0.242, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.268, 0.0, 0.266, 0.0, 0.0, 0.244, 0.0, 0.0, 0.389, 0.196, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.394, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.286, 0.524, 0.326, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.255, 0.0, 0.182, 0.0, 0.0, 0.0, 0.0, 0.252, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.423, 0.26, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.461, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.774, 0.0, 0.0, 0.0, 0.0, 0.0, 0.176, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.444, 0.0, 0.0, 0.0, 0.789, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.142, 0.0, 0.268, 0.0, 0.0, 0.0, 0.0, 0.524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.524, 0.0, 0.205, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.098, 0.0, 0.789, 0.0, 0.0, 0.0, 0.0, 0.324, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.249, 0.078, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.138, 0.0, 0.0, 0.0, 0.053, 0.23, 0.0, 0.0, 0.0, 0.0, 0.138, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.058, 0.0, 0.0, 0.0, 0.151, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.195, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.098, 0.236, 0.227, 0.0, 0.0, 0.205, 0.142, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.412, 0.0, 0.0, 0.297, 0.0, 0.118, 0.0, 0.0, 0.237, 0.0, 0.0, 0.0, 0.0, 0.355, 0.0, 0.0, 0.383, 0.0, 0.0, 0.0, 0.0, 0.0, 0.261, 0.0, 0.0, 0.0, 0.0, 0.326, 0.0, 0.0, 0.0, 0.0, 0.524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.051, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.161, 0.195, 0.0, 0.0, 0.0, 0.322, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.128, 0.0, 0.0, 0.0, 0.195, 0.0, 0.492, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.237, 0.0, 0.0, 0.0, 0.0, 0.0, 0.072, 0.0, 0.0, 0.0, 0.091, 0.524, 0.0, 0.0, 0.385, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.524, 0.0, 0.0, 0.26, 0.0, 0.0, 0.0, 0.0, 0.0, 0.166, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.348, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.205, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.262, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.324, 0.0, 0.174, 0.0, 0.0, 0.266, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.139, 0.267, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.187, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.286, 0.0, 0.524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.452, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.437, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.268, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.147, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.167, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.239, 0.188, 0.524, 0.121, 0.0, 0.0, 0.0, 0.0, 0.423, 0.423, 0.189, 0.0, 0.0, 0.0, 0.0, 0.0, 0.524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.28, 0.0, 0.0, 0.0, 0.0, 0.235, 0.368, 0.0, 0.0, 0.28, 0.524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.54, 0.524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.237, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.524, 0.125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.524, 0.0, 0.0, 0.0, 0.0, 0.524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.132, 0.0, 0.0, 0.437, 0.0, 0.42, 0.0, 0.326, 0.0, 0.0, 0.0, 0.086, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.265, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.677, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.254, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.423, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.171, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.278, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.114, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.101, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.422, 0.0, 0.0, 0.0, 0.0, 0.16, 0.308, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.355, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.42, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.512, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.63, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.172, 0.0, 0.0, 0.437, 0.0, 0.0, 0.184, 0.0, 0.0, 0.0, 0.287, 0.0, 0.0, 0.484, 0.0, 0.0, 0.0, 0.0, 0.0, 0.252, 0.286, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.264, 0.225, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.155, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.524, 0.524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.524, 0.0, 0.075, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.508, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.053, 0.155, 0.0, 0.0, 0.0, 0.0, 0.402, 0.0, 0.131, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.064, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.423, 0.524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.174, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.064, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.306, 0.0, 0.0, 0.0, 0.268, 0.0, 0.0, 0.0, 0.381, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.129, 0.0, 0.0, 0.106, 0.0, 0.0, 0.31, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.219, 0.244, 0.281, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.359, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.203, 0.0, 0.0, 0.244, 0.15, 0.0, 0.0, 0.0, 0.0, 0.0, 0.365, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.175, 0.0, 0.242, 0.0, 0.0, 0.0, 0.0, 0.038, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.239, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.112, 0.0, 0.154, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.239, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.524, 0.0, 0.0, 0.0, 0.0, 0.267, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.187, 0.256, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.302, 0.0, 0.0, 0.0, 0.084, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.075, 0.0, 0.153, 0.161, 0.0, 0.053, 0.0, 0.0, 0.0, 0.0, 0.326, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.223, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.116, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.066, 0.0, 0.0, 0.0, 0.076, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.209, 0.0, 0.172, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.085, 0.0, 0.167, 0.083, 0.0, 0.0, 0.355, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.162, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.149, 0.0, 0.0, 0.524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.054, 0.18, 0.375, 0.0, 0.0, 0.0, 0.133, 0.0, 0.0, 0.0, 0.0, 0.0, 0.073, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.492, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.126, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.365, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.134, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.239, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.182, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.623, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.255, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.149, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07, 0.0, 0.0, 0.0, 0.068, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.082, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.234, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.209, 0.0, 0.0, 0.0, 0.0, 0.0, 0.353, 0.333, 0.0, 0.0, 0.0, 0.0, 0.139, 0.0, 0.328, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.185, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.18, 0.0, 0.306, 0.0, 0.0, 0.0, 0.0, 0.048, 0.0, 0.0, 0.0, 0.0, 0.259, 0.0, 0.112, 0.068, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.344, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.39, 0.0, 0.0, 0.306, 0.0, 0.0, 0.169, 0.0, 0.524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.228, 0.0, 0.0, 0.174, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.161, 0.524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.14, 0.0, 0.26, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.152, 0.0, 0.0, 0.0, 0.0, 0.0, 0.209, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.294, 0.0, 0.0, 0.0, 0.0, 0.08, 0.0, 0.085, 0.0, 0.075, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.093, 0.0, 0.0, 0.0, 0.0, 0.437, 0.0, 0.029, 0.0, 0.0, 0.0, 0.0, 0.0, 0.043, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.241, 0.0, 0.0, 0.0, 0.298, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.155, 0.0, 0.0, 0.0, 0.0, 0.047, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.214, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.423, 0.0, 0.0, 0.0, 0.0, 0.355, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.42, 0.239, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.524, 0.18, 0.0, 0.247, 0.0, 0.0, 0.0, 0.133, 0.0, 0.193, 0.138, 0.151, 0.0, 0.193, 0.0, 0.0, 0.216, 0.0, 0.147, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.075, 0.0, 0.256, 0.0, 0.0, 0.216, 0.137, 0.0, 0.137, 0.0, 0.0, 0.524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.184, 0.0, 0.0, 0.381, 0.339, 0.095, 0.0, 0.0, 0.0, 0.0, 0.0, 0.26, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.085, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.18, 0.0, 0.0, 0.0, 0.196, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.306, 0.0, 0.0, 0.107, 0.1, 0.0, 0.0, 0.0, 0.198, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.232, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.187, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.078, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.155, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.172, 0.0, 0.0, 0.122, 0.0, 0.122, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13, 0.197, 0.0, 0.0, 0.167, 0.177, 0.0, 0.0, 0.0, 0.0, 0.312, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.524, 0.0, 0.158, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.524, 0.0, 0.155, 0.0, 0.355, 0.355, 0.0, 0.141, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.388, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.244, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.25, 0.524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.081, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.298, 0.0, 0.138, 0.0, 0.0, 0.652, 0.0, 0.0, 0.147, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.259, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.253, 0.0, 0.0, 0.0, 0.0, 0.11, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.083, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.074, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.423, 0.0, 0.0, 0.192, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.307, 0.0, 0.0, 0.143, 0.0, 0.0, 0.091, 0.0, 0.0, 0.0, 0.0, 0.524, 0.113, 0.0, 0.0, 0.107, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.348, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.63, 0.0, 0.0, 0.0, 0.0, 0.155, 0.149, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.205, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.213, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.133, 0.0, 0.0, 0.135, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.259, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.087, 0.0, 0.0, 0.186, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6, 0.0, 0.232, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.524, 0.167, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.298, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.15, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.429, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.31, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.524, 0.0, 0.0, 0.0, 0.083, 0.0, 0.0, 0.232, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.252, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.318, 0.0, 0.0, 0.0, 0.0, 0.252, 0.0, 0.0, 0.0, 0.524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.524, 0.108, 0.0, 0.0, 0.423, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.265, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.139, 0.0, 0.0, 0.0, 0.0, 0.0, 0.524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.226, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.105, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.292, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.251, 0.524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.085, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.286, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.237, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.306, 0.0, 0.0, 0.0, 0.355, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.121, 0.0, 0.368, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.164, 0.0, 0.524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.459, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.524, 0.437, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.207, 0.0, 0.0, 0.0, 0.0, 0.306, 0.0, 0.394, 0.0, 0.0, 0.0, 0.0, 0.0, 0.524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.524, 0.524, 0.524, 0.524, 0.0, 0.0, 0.123, 0.0, 0.0, 0.524, 0.0, 0.524, 0.0, 0.524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.524, 0.0, 0.0, 0.0, 0.0, 0.228, 0.524, 0.0, 0.0, 0.0, 0.0, 0.16, 0.0, 0.0, 0.0, 0.0, 0.0, 0.421, 0.0, 0.0, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.107, 0.0, 0.0, 0.0, 0.0, 0.31, 0.0, 0.0, 0.195, 0.524, 0.168, 0.0, 0.0, 0.0, 0.056, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.293, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.217, 0.0, 0.0, 0.0, 0.0, 0.524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.078, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.149, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.196, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.412, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.306, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.412, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.524, 0.302, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.583, 0.0, 0.0, 0.0, 0.583, 0.0, 0.0, 0.583, 0.0, 0.583, 0.0, 0.156, 0.583, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.423, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.231, 0.0, 0.0, 0.0, 0.153, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.055, 0.0, 0.0, 0.524, 0.0, 0.0, 0.0, 0.0, 0.524, 0.196, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.176, 0.106, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.524, 0.0, 0.14, 0.0, 0.0, 0.0, 0.085, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.306, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.161, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.278, 0.394, 0.0, 0.0, 0.288, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.277, 0.0, 0.0, 0.0, 0.0, 0.084, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.355, 0.0, 0.0, 0.423, 0.423, 0.0, 0.423, 0.0, 0.0, 0.0, 0.0, 0.524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.355, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.434, 0.0, 0.0, 0.398, 0.0, 0.0, 0.0, 0.0, 0.253, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.411, 0.0, 0.0, 0.0, 0.271, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.211, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.236, 0.0, 0.0, 0.524, 0.524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.167, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.088, 0.0, 0.0, 0.167, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.556, 0.0, 0.0, 0.0, 0.0, 0.104, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.293, 0.0, 0.0, 0.0, 0.194, 0.0, 0.0, 0.0, 0.0, 0.423, 0.0, 0.0, 0.0, 0.268, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.114, 0.0, 0.167, 0.0, 0.0, 0.196, 0.204, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.292, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.282, 0.0, 0.0, 0.524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.643, 0.0, 0.0, 0.0, 0.474, 0.0, 0.0, 0.0, 0.0, 0.0, 0.247, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.306, 0.0, 0.0, 0.0, 0.0, 0.0, 0.178, 0.0, 0.0, 0.0, 0.0, 0.238, 0.0, 0.0, 0.0, 0.0, 0.0, 0.124, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.18, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.518, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.342, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.239, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.194, 0.0, 0.0, 0.0, 0.273, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.236, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.239, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.196, 0.165, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.326, 0.296, 0.224, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.457, 0.0, 0.0, 0.0, 0.0, 0.211, 0.166, 0.0, 0.242, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.449, 0.0, 0.444, 0.0, 0.242, 0.0, 0.0, 0.0, 0.171, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.524, 0.0, 0.28, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.349, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.341, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34, 0.155, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.161, 0.302, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.296, 0.0, 0.0, 0.0, 0.0, 0.241, 0.0, 0.0, 0.524, 0.0, 0.0, 0.0, 0.0, 0.302, 0.0, 0.496, 0.219, 0.255, 0.0, 0.0, 0.0, 0.0, 0.216, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.216, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.412, 0.167, 0.0, 0.0, 0.348, 0.244, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.216, 0.213, 0.217, 0.0, 0.0, 0.0, 0.0, 0.017, 0.0, 0.0, 0.0, 0.0, 0.0, 0.088, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.524, 0.0, 0.524, 0.0, 0.0, 0.0, 0.355, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.55, 0.0, 0.0, 0.0, 0.16, 0.0, 0.42, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.714, 0.0, 0.333, 0.0, 0.089, 0.0, 0.0, 0.087, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.074, 0.0, 0.06, 0.0, 0.106, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.171, 0.0, 0.0, 0.0, 0.089, 0.0, 0.239, 0.103, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.524, 0.0, 0.0, 0.0, 0.524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.412, 0.0, 0.0, 0.0, 0.0, 0.608, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.298, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.524, 0.0, 0.524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.459, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.423, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.144, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.524, 0.0, 0.0, 0.211, 0.0, 0.239, 0.0, 0.0, 0.0, 0.167, 0.145, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.272, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12, 0.0, 0.0, 0.0, 0.0, 0.0, 0.373, 0.524, 0.0, 0.0, 0.409, 0.0, 0.0, 0.0, 0.0, 0.0, 0.221, 0.367, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.339, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.423, 0.289, 0.524, 0.173, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.355, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.232, 0.0, 0.0, 0.0, 0.0, 0.068, 0.0, 0.0, 0.0, 0.091, 0.0, 0.0, 0.0, 0.0, 0.157, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.193, 0.0, 0.524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.386, 0.272, 0.0, 0.0, 0.209, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.069, 0.0, 0.0, 0.0, 0.0, 0.0, 0.123, 0.0, 0.524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.239, 0.0, 0.0, 0.0, 0.0, 0.0, 0.592, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.355, 0.0, 0.0, 0.0, 0.0, 0.0, 0.296, 0.0, 0.231, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.412, 0.0, 0.322, 0.0, 0.0, 0.0, 0.193, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.232, 0.467, 0.0, 0.0, 0.0, 0.0, 0.0, 0.524, 0.524, 0.0, 0.0, 0.261, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.231, 0.0, 0.0, 0.0, 0.0, 0.167, 0.355, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.161, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.211, 0.0, 0.0, 0.196, 0.0, 0.0, 0.0, 0.257, 0.084, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.484, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.081, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.245, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.328, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.143, 0.138, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.206, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.524, 0.222, 0.0, 0.0, 0.524, 0.0, 0.0, 0.0, 0.524, 0.0, 0.324, 0.0, 0.0, 0.189, 0.0, 0.0, 0.0, 0.0, 0.0, 0.296, 0.0, 0.135, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.815, 0.0, 0.0, 0.0, 0.0, 0.688, 0.0, 0.0, 0.0, 0.122, 0.0, 0.343, 0.143, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.333, 0.0, 0.0, 0.524, 0.239, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.524, 0.0, 0.0, 0.0, 0.0, 0.307, 0.146, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.484, 0.0, 0.0, 0.455, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.295, 0.0, 0.0, 0.524, 0.0, 0.0, 0.0, 0.0, 0.524, 0.0, 0.423, 0.0, 0.0, 0.157, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.32, 0.248, 0.0, 0.0, 0.0, 0.0, 0.0, 0.423, 0.286, 0.0, 0.0, 0.0, 0.093, 0.524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.195, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1, 0.0, 0.0, 0.789, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.155, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.375, 0.286, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.524, 0.0, 0.0, 0.394, 0.524, 0.245, 0.0, 0.524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.423, 0.0, 0.0, 0.524, 0.0, 0.0, 0.296, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.235, 0.0, 0.423, 0.0, 0.0, 0.0, 0.0, 0.254, 0.231, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.385, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.25, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.239, 0.0, 0.0, 0.0, 0.0, 0.0, 0.137, 0.0, 0.0, 0.0, 0.074, 0.0, 0.0, 0.0, 0.143, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.153, 0.0, 0.0, 0.0, 0.239, 0.0, 0.082, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.174, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.459, 0.0, 0.524, 0.205, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.636, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.464, 0.26, 0.0, 0.306, 0.355, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.268, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.226, 0.524, 0.0, 0.0, 0.158, 0.0, 0.0, 0.0, 0.524, 0.0, 0.078, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.161, 0.0, 0.0, 0.0, 0.0, 0.083, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.244, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.084, 0.098, 0.0, 0.0, 0.0, 0.293, 0.219, 0.0, 0.75, 0.0, 0.196, 0.0, 0.0, 0.0, 0.127, 0.0, 0.0, 0.0, 0.0, 0.0, 0.263, 0.0, 0.0, 0.0, 0.237, 0.0, 0.0, 0.0, 0.06, 0.161, 0.0, 0.412, 0.286, 0.139, 0.228, 0.0, 0.0, 0.0, 0.116, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.423, 0.0, 0.0, 0.508, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.242, 0.213, 0.186, 0.318, 0.309, 0.0, 0.0, 0.0, 0.0, 0.423, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.199, 0.652, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.132, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.256, 0.0, 0.0, 0.198, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.444, 0.0, 0.0, 0.229, 0.0, 0.0, 0.0, 0.355, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.14, 0.0, 0.0, 0.0, 0.0, 0.0, 0.128, 0.0, 0.0, 0.0, 0.0, 0.141, 0.0, 0.388, 0.0, 0.652, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.294, 0.298, 0.0, 0.048, 0.375, 0.234, 0.0, 0.0, 0.0, 0.0, 0.789, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.105, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.312, 0.0, 0.0, 0.0, 0.0, 0.098, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.084, 0.0, 0.0, 0.142, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.104, 0.107, 0.158, 0.298, 0.306, 0.0, 0.0, 0.0, 0.078, 0.0, 0.0, 0.0, 0.0, 0.0, 0.286, 0.0, 0.0, 0.0, 0.0, 0.099, 0.0, 0.0, 0.524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.138, 0.375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.31, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.098, 0.0, 0.0, 0.0, 0.231, 0.0, 0.0, 0.0, 0.0, 0.423, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.054, 0.0, 0.0, 0.0, 0.0, 0.0, 0.115, 0.0, 0.197, 0.0, 0.0, 0.167, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.149, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.216, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.198, 0.0, 0.0, 0.0, 0.0, 0.411, 0.0, 0.0, 0.0, 0.0, 0.0, 0.412, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.115, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.153, 0.0, 0.0, 0.0, 0.0, 0.0, 0.319, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.174, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.245, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.213, 0.0, 0.0, 0.0, 0.265, 0.101, 0.0, 0.0, 0.0, 0.112, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.043, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.118, 0.204, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.169, 0.297, 0.0, 0.333, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.457, 0.307, 0.164, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.138, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.209, 0.209, 0.268, 0.306, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.086, 0.0, 0.0, 0.0, 0.0, 0.0, 0.329, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.187, 0.26, 0.13, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.141, 0.0, 0.268, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.256, 0.0, 0.307, 0.391, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.268, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.214, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.524, 0.0, 0.0, 0.0, 0.38, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.101, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.196, 0.524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.468, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.062, 0.524, 0.0, 0.065, 0.0, 0.0, 0.0, 0.0, 0.231, 0.0, 0.173, 0.0, 0.126, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.524, 0.144, 0.0, 0.0, 0.524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.437, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.306, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.036, 0.0, 0.0, 0.0, 0.0, 0.0, 0.229, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.403, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.345, 0.198, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.123, 0.0, 0.0, 0.0, 0.524, 0.0, 0.0, 0.167, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.232, 0.0, 0.0, 0.239, 0.0, 0.184, 0.0, 0.0, 0.0, 0.524, 0.0, 0.0, 0.244, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.039, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.146, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.365, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.187, 0.232, 0.0, 0.0, 0.0, 0.0, 0.268, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.247, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.256, 0.167, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.318, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.218, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.268, 0.0, 0.0, 0.0, 0.0, 0.242, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.18, 0.524, 0.0, 0.0, 0.187, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.294, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.147, 0.0, 0.0, 0.0, 0.306, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.583, 0.091, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.28, 0.524, 0.0, 0.0, 0.355, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.412, 0.0, 0.0, 0.0, 0.148, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.172, 0.185, 0.0, 0.0, 0.0, 0.108, 0.355, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.306, 0.0, 0.0, 0.115, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.098, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.196, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.315, 0.0, 0.0, 0.0, 0.304, 0.167, 0.0, 0.0, 0.0, 0.0, 0.394, 0.0, 0.0, 0.0, 0.0, 0.0, 0.125, 0.0, 0.217, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.236, 0.0, 0.0, 0.0, 0.0, 0.0, 0.767, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.239, 0.0, 0.0, 0.247, 0.0, 0.0, 0.0, 0.0, 0.045, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.098, 0.0, 0.0, 0.0, 0.092, 0.237, 0.275, 0.0, 0.2, 0.0, 0.114, 0.0, 0.0, 0.0, 0.0, 0.524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.127, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.089, 0.0, 0.0, 0.0, 0.153, 0.0, 0.0, 0.089, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.062, 0.128, 0.0, 0.0, 0.0, 0.162, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.344, 0.0, 0.0, 0.0, 0.5, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.231, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.219, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.097, 0.091, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.107, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.17, 0.0, 0.0, 0.0, 0.198, 0.365, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.32, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.128, 0.0, 0.0, 0.339, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.26, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.333, 0.0, 0.0, 0.0, 0.0, 0.239, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.306, 0.0, 0.0, 0.0, 0.0, 0.0, 0.302, 0.159, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.273, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.302, 0.0, 0.069, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.18, 0.0, 0.746, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.223, 0.649, 0.0, 0.0, 0.252, 0.351, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.298, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.191, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.286, 0.0, 0.0, 0.0, 0.0, 0.0, 0.159, 0.0, 0.0, 0.0, 0.0, 0.524, 0.0, 0.0, 0.0, 0.0, 0.16, 0.0, 0.0, 0.524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.273, 0.244, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.185, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.767, 0.0, 0.0, 0.6, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.348, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.326, 0.0, 0.0, 0.0, 0.0, 0.161, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.365, 0.0, 0.355, 0.315, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.257, 0.0, 0.0, 0.257, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.437, 0.0, 0.0, 0.0, 0.0, 0.277, 0.0, 0.293, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.106, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.177, 0.0, 0.0, 0.0, 0.714, 0.0, 0.0, 0.359, 0.0, 0.0, 0.0, 0.244, 0.0, 0.0, 0.232, 0.0, 0.0, 0.0, 0.0, 0.0, 0.337, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.351, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.307, 0.0, 0.0, 0.0, 0.0, 0.524, 0.167, 0.349, 0.0, 0.0, 0.524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.222, 0.0, 0.355, 0.0, 0.524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.524, 0.268, 0.0, 0.266, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.306, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.268, 0.076, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.259, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.652, 0.0, 0.0, 0.0, 0.0, 0.152, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.211, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.126, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.276, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.355, 0.714, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.484, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.385, 0.204, 0.0, 0.0, 0.0, 0.0, 0.167, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.714, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.538, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.355, 0.0, 0.524, 0.0, 0.302, 0.223, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.216, 0.0, 0.0, 0.423, 0.423, 0.0, 0.0, 0.0, 0.0, 0.0, 0.406, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.307, 0.0, 0.306, 0.245, 0.0, 0.688, 0.0, 0.0, 0.0, 0.088, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.318, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.182, 0.182, 0.0, 0.306, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.517, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.306, 0.0, 0.0, 0.0, 0.0, 0.302, 0.0, 0.0, 0.247, 0.0, 0.0, 0.0, 0.0, 0.167, 0.0, 0.153, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.524, 0.0, 0.0, 0.0, 0.216, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.239, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.239, 0.0, 0.0, 0.0, 0.0, 0.455, 0.355, 0.0, 0.109, 0.524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.405, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.423, 0.0, 0.0, 0.25, 0.0, 0.0, 0.0, 0.0, 0.237, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.137, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.789, 0.0, 0.0, 0.333, 0.0, 0.0, 0.0, 0.524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.423, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.297, 0.0, 0.0, 0.0, 0.0, 0.0, 0.109, 0.124, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.205, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.226, 0.0, 0.688, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.15, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13, 0.0, 0.0, 0.216, 0.0, 0.0, 0.0, 0.07, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.445, 0.714, 0.0, 0.204, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.15, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.246, 0.0, 0.0, 0.398, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.112, 0.398, 0.0, 0.0, 0.21, 0.0, 0.0, 0.0, 0.0, 0.0, 0.081, 0.0, 0.0, 0.0, 0.0, 0.211, 0.0, 0.0, 0.155, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.189, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.284, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.049, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.065, 0.0, 0.0, 0.0, 0.0, 0.524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.301, 0.0, 0.057, 0.0, 0.0, 0.524, 0.0, 0.0, 0.0, 0.0, 0.135, 0.247, 0.0, 0.0, 0.213, 0.031, 0.0, 0.0, 0.29, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.244, 0.0, 0.0, 0.0, 0.455, 0.0, 0.0, 0.205, 0.0, 0.12, 0.0, 0.0, 0.0, 0.0, 0.0, 0.355, 0.404, 0.0, 0.0, 0.0, 0.0, 0.36, 0.0, 0.0, 0.062, 0.0, 0.307, 0.0, 0.0, 0.0, 0.0, 0.0, 0.608, 0.608, 0.0, 0.0, 0.253, 0.0, 0.118, 0.146, 0.0, 0.268, 0.0, 0.0, 0.0, 0.286, 0.0, 0.0, 0.115, 0.0, 0.0, 0.333, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.237, 0.0, 0.524, 0.0, 0.216, 0.133, 0.524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.065, 0.032, 0.036, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.123, 0.355, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.524, 0.0, 0.0, 0.028, 0.087, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.098, 0.131, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.069, 0.0, 0.0, 0.0, 0.0, 0.0, 0.193, 0.0, 0.0, 0.0, 0.066, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.268, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.136, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.524, 0.149, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.037, 0.0, 0.306, 0.0, 0.0, 0.0, 0.524, 0.423, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.286, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.069, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.306, 0.174, 0.0, 0.0, 0.0, 0.0, 0.115, 0.0, 0.0, 0.0, 0.14, 0.0, 0.0, 0.0, 0.524, 0.137, 0.036, 0.033, 0.077, 0.0, 0.116, 0.311, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.167, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.046, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.062, 0.245, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.326, 0.0, 0.083, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.306, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.464, 0.0, 0.0, 0.0, 0.524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.286, 0.0, 0.0, 0.0, 0.0, 0.516, 0.0, 0.0, 0.0, 0.0, 0.479, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.306, 0.13, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7, 0.0, 0.191, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.367, 0.0, 0.326, 0.0, 0.0, 0.341, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.524, 0.0, 0.0, 0.076, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.212, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12, 0.0, 0.0, 0.0, 0.355, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.394, 0.0, 0.0, 0.0, 0.0, 0.052, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.149, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.216, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.423, 0.0, 0.239, 0.375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.131, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.259, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.518, 0.0, 0.464, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.492, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.149, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.132, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.169, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.173, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.524, 0.345, 0.149, 0.219, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.271, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.333, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.268, 0.0, 0.0, 0.0, 0.386, 0.0, 0.0, 0.0, 0.0, 0.0, 0.595, 0.0, 0.0, 0.0, 0.0, 0.181, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.189, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.18, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.153, 0.0, 0.0, 0.0, 0.0, 0.216, 0.0, 0.216, 0.0, 0.0, 0.0, 0.0, 0.0, 0.259, 0.423, 0.0, 0.0, 0.0, 0.0, 0.239, 0.286, 0.0, 0.0, 0.0, 0.524, 0.0, 0.0, 0.524, 0.0, 0.0, 0.0, 0.0, 0.524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.25, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.253, 0.0, 0.453, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.512, 0.155, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.326, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.492, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.141, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.789, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.096, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.328, 0.0, 0.0, 0.0, 0.0, 0.0, 0.053, 0.159, 0.082, 0.0, 0.0, 0.0, 0.0, 0.0, 0.192, 0.0, 0.0, 0.0, 0.153, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.057, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.789, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.154, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.25, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.369, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.279, 0.63, 0.63, 0.25, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.349, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.175, 0.0, 0.0, 0.0, 0.394, 0.0, 0.0, 0.042, 0.286, 0.0, 0.0, 0.0, 0.155, 0.0, 0.0, 0.0, 0.0, 0.0, 0.253, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.181, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.104, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.232, 0.0, 0.13, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.167, 0.0, 0.524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.196, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.198, 0.0, 0.196, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.512, 0.0, 0.0, 0.0, 0.223, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.423, 0.0, 0.0, 0.0, 0.0, 0.423, 0.0, 0.0, 0.0, 0.209, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.084, 0.0, 0.295, 0.0, 0.0, 0.0, 0.197, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.285, 0.0, 0.0, 0.164, 0.0, 0.196, 0.0, 0.0, 0.0, 0.133, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.524, 0.198, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.286, 0.0, 0.0, 0.0, 0.0, 0.194, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.0, 0.091, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.355, 0.0, 0.0, 0.524, 0.0, 0.524, 0.368, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.173, 0.072, 0.054, 0.0, 0.524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.307, 0.0, 0.0, 0.0, 0.064, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.423, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.091, 0.0, 0.0, 0.0, 0.155, 0.0, 0.112, 0.0, 0.0, 0.0, 0.524, 0.0, 0.524, 0.524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.172, 0.161, 0.0, 0.0, 0.0, 0.0, 0.136, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.286, 0.524, 0.0, 0.0, 0.0, 0.291, 0.0, 0.0, 0.0, 0.0, 0.524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.524, 0.0, 0.0, 0.0, 0.212, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.355, 0.0, 0.0, 0.355, 0.0, 0.0, 0.0, 0.0, 0.306, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.242, 0.0, 0.0, 0.0, 0.18, 0.0, 0.0, 0.0, 0.0, 0.524, 0.0, 0.0, 0.524, 0.0, 0.0, 0.148, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.108, 0.0, 0.0, 0.0, 0.0, 0.169, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.464, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.423, 0.0, 0.0, 0.268, 0.0, 0.524, 0.0, 0.0, 0.0, 0.0, 0.365, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.246, 0.09, 0.0, 0.179, 0.0, 0.184, 0.0, 0.146, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.256, 0.0, 0.0, 0.251, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.253, 0.0, 0.246, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.209, 0.0, 0.0, 0.0, 0.0, 0.136, 0.228, 0.0, 0.0, 0.0, 0.273, 0.312, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.268, 0.524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.154, 0.0, 0.0, 0.178, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.162, 0.0, 0.0, 0.0, 0.071, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.524, 0.0, 0.0, 0.0, 0.345, 0.0, 0.403, 0.524, 0.383, 0.123, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.412, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.265, 0.0, 0.0, 0.524, 0.0, 0.0, 0.31, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.386, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.247, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.355, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.524, 0.688, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.237, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.383, 0.0, 0.0, 0.524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.18, 0.0, 0.095, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.306, 0.0, 0.0, 0.565, 0.0, 0.0, 0.0, 0.0, 0.328, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.319, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.714, 0.524, 0.0, 0.0, 0.0, 0.524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.042, 0.508, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.239, 0.0, 0.0, 0.177, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.293, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.268, 0.0, 0.0, 0.355, 0.0, 0.0, 0.0, 0.394, 0.262, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.177, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.338, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.268, 0.0, 0.282, 0.128, 0.0, 0.0, 0.0, 0.189, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.714, 0.0, 0.0, 0.0, 0.0, 0.304, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13, 0.0, 0.0, 0.0, 0.0, 0.43, 0.0, 0.0, 0.0, 0.0, 0.0, 0.306, 0.051, 0.0, 0.0, 0.524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.789, 0.455, 0.0, 0.0, 0.0, 0.181, 0.187, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.133, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.279, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.099, 0.0, 0.0, 0.0, 0.333, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.623, 0.623, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.133, 0.182, 0.355, 0.0, 0.0, 0.268, 0.0, 0.0, 0.107, 0.268, 0.0, 0.36, 0.0, 0.045, 0.1, 0.0, 0.0, 0.265, 0.0, 0.0, 0.0, 0.106, 0.0, 0.0, 0.0, 0.239, 0.0, 0.0, 0.0, 0.0, 0.0, 0.066, 0.524, 0.0, 0.0, 0.0, 0.324, 0.0, 0.225, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.116, 0.095, 0.0, 0.0, 0.271, 0.218, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.342, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.071, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.216, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.19, 0.0, 0.0, 0.0, 0.0, 0.182, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.124, 0.0, 0.0, 0.167, 0.0, 0.128, 0.0, 0.0, 0.0, 0.306, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.198, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.423, 0.18, 0.0, 0.0, 0.306, 0.0, 0.0, 0.0, 0.306, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.152, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.073, 0.0, 0.154, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.165, 0.071, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.308, 0.0, 0.0, 0.0, 0.314, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.202, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.183, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.175, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.273, 0.104, 0.0, 0.247, 0.0, 0.0, 0.0, 0.0, 0.0, 0.524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.524, 0.0, 0.0, 0.0, 0.168, 0.524, 0.0, 0.0, 0.0, 0.0, 0.058, 0.0, 0.0, 0.429, 0.0, 0.0, 0.0, 0.0, 0.0, 0.19, 0.0, 0.194, 0.0, 0.0, 0.0, 0.0, 0.0, 0.124, 0.0, 0.0, 0.0, 0.381, 0.113, 0.179, 0.0, 0.155, 0.0, 0.0, 0.0, 0.282, 0.0, 0.0, 0.0, 0.0, 0.423, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08, 0.0, 0.0, 0.056, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.132, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.116, 0.163, 0.087, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.111, 0.0, 0.081, 0.524, 0.0, 0.0, 0.244, 0.179, 0.275, 0.0, 0.173, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.059, 0.081, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.058, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.196, 0.524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.392, 0.0, 0.0, 0.147, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13, 0.0, 0.0, 0.0, 0.0, 0.0, 0.125, 0.0, 0.434, 0.153, 0.0, 0.0, 0.0, 0.524, 0.0, 0.299, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.252, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.268, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.162, 0.0, 0.0, 0.0, 0.0, 0.423, 0.524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.238, 0.196, 0.0, 0.0, 0.0, 0.175, 0.0, 0.118, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.155, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.145, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.286, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.235, 0.0, 0.0, 0.0, 0.355, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.204, 0.0, 0.113, 0.0, 0.0, 0.0, 0.423, 0.0, 0.0, 0.0, 0.355, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.18, 0.0, 0.0, 0.0, 0.0, 0.0, 0.268, 0.0, 0.0, 0.0, 0.0, 0.239, 0.102, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.452, 0.0, 0.492, 0.0, 0.0, 0.119, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.524, 0.71, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.165, 0.0, 0.0, 0.0, 0.0, 0.086, 0.063, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.293, 0.0, 0.0, 0.112, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.355, 0.0, 0.0, 0.185, 0.326, 0.0, 0.355, 0.0, 0.0, 0.0, 0.0, 0.253, 0.633, 0.324, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.326, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.398, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.162, 0.0, 0.231, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.423, 0.0, 0.0, 0.0, 0.265, 0.0, 0.0, 0.0, 0.0, 0.0, 0.212, 0.0, 0.0, 0.0, 0.0, 0.092, 0.306, 0.0, 0.0, 0.304, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.102, 0.0, 0.0, 0.032, 0.041, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.072, 0.135, 0.0, 0.0, 0.0, 0.0, 0.0, 0.091, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.049, 0.077, 0.0, 0.0, 0.0, 0.608, 0.0, 0.0, 0.0, 0.0, 0.0, 0.058, 0.0, 0.0, 0.0, 0.0, 0.037, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.164, 0.0, 0.297, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.118, 0.068, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.167, 0.167, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.172, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.42, 0.0, 0.524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.15, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.191, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.073, 0.0, 0.0, 0.0, 0.0, 0.0, 0.071, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.079, 0.0, 0.0, 0.0, 0.0, 0.062, 0.0, 0.0, 0.0, 0.0, 0.171, 0.11, 0.18, 0.0, 0.0, 0.455, 0.293, 0.0, 0.0, 0.0, 0.318, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.155, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.196, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.149, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12, 0.0, 0.308, 0.0, 0.592, 0.0, 0.0, 0.0, 0.554, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.355, 0.0, 0.0, 0.0, 0.0, 0.195, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.071, 0.0, 0.118, 0.0, 0.524, 0.315, 0.0, 0.0, 0.0, 0.294, 0.0, 0.0, 0.351, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.267, 0.0, 0.0, 0.515, 0.241, 0.0, 0.245, 0.0, 0.311, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.26, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.14, 0.0, 0.0, 0.0, 0.355, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.244, 0.0, 0.0, 0.0, 0.0, 0.0, 0.138, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.149, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.138, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.14, 0.174, 0.131, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.192, 0.184, 0.216, 0.0, 0.0, 0.325, 0.396, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.437, 0.0, 0.0, 0.0, 0.307, 0.0, 0.213, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.385, 0.367, 0.0, 0.0, 0.219, 0.131, 0.0, 0.082, 0.175, 0.0, 0.0, 0.0, 0.0, 0.0, 0.211, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.035, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.216, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.524, 0.315, 0.0, 0.0, 0.0, 0.0, 0.0, 0.132, 0.0, 0.087, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.524, 0.0, 0.09, 0.0, 0.0, 0.26, 0.0, 0.0, 0.087, 0.194, 0.278, 0.0, 0.096, 0.0, 0.0, 0.0, 0.216, 0.0, 0.0, 0.171, 0.0, 0.524, 0.0, 0.524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.118, 0.524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.114, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.216, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.524, 0.0, 0.0, 0.196, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.076, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.351, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.524, 0.0, 0.0, 0.0, 0.0, 0.16, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.049, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.325, 0.432, 0.306, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.075, 0.0, 0.688, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.232, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.524, 0.524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.123, 0.0, 0.101, 0.149, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.524, 0.0, 0.0, 0.0, 0.155, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.318, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.238, 0.0, 0.0, 0.082, 0.167, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.086, 0.0, 0.0, 0.152, 0.0, 0.184, 0.0, 0.0, 0.0, 0.0, 0.16, 0.0, 0.0, 0.0, 0.0, 0.0, 0.046, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.815, 0.0, 0.0, 0.0, 0.0, 0.0, 0.109, 0.0, 0.196, 0.0, 0.0, 0.0, 0.0, 0.0, 0.085, 0.0, 0.0, 0.0, 0.367, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.058, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.423, 0.0, 0.0, 0.0, 0.0, 0.155, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.306, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.206, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.184, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.248, 0.0, 0.0, 0.0, 0.0, 0.197, 0.0, 0.412, 0.0, 0.524, 0.0, 0.167, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.166, 0.0, 0.464, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.133, 0.0, 0.0, 0.0, 0.0, 0.156, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.275, 0.0, 0.0, 0.0, 0.0, 0.0, 0.524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.524, 0.198, 0.0, 0.385, 0.474, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.177, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.177, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.423, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.196, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.189, 0.0, 0.0, 0.0, 0.0, 0.0, 0.277, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.15, 0.0, 0.0, 0.0, 0.181, 0.0, 0.0, 0.306, 0.0, 0.242, 0.0, 0.0, 0.0, 0.216, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08, 0.149, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.338, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.315, 0.275, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.674, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.218, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.155, 0.228, 0.0, 0.0, 0.0, 0.0, 0.213, 0.0, 0.108, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.107, 0.0, 0.0, 0.524, 0.0, 0.0, 0.524, 0.688, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.387, 0.231, 0.0, 0.244, 0.0, 0.174, 0.0, 0.0, 0.0, 0.0, 0.387, 0.294, 0.0, 0.0, 0.0, 0.0, 0.0, 0.211, 0.0, 0.0, 0.0, 0.141, 0.0, 0.0, 0.0, 0.0, 0.292, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.195, 0.274, 0.26, 0.0, 0.0, 0.203, 0.0, 0.16, 0.0, 0.319, 0.0, 0.105, 0.311, 0.0, 0.0, 0.0, 0.0, 0.524, 0.0, 0.333, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.107, 0.0, 0.0, 0.0, 0.0, 0.326, 0.0, 0.298, 0.0, 0.0, 0.524, 0.0, 0.216, 0.0, 0.0, 0.0, 0.0, 0.0, 0.524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.182, 0.0, 0.0, 0.0, 0.0, 0.116, 0.16, 0.423, 0.07, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.153, 0.28, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.524, 0.355, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.552, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.146, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.225, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.423, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.302, 0.0, 0.0, 0.0, 0.087, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.226, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.524, 0.0, 0.0, 0.0, 0.0, 0.22, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.306, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.71, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.242, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12, 0.0, 0.0, 0.0, 0.104, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.207, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.26, 0.0, 0.0, 0.0, 0.0, 0.0, 0.274, 0.0, 0.0, 0.204, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.158, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.328, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.524, 0.524, 0.196, 0.0, 0.0, 0.149, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.324, 0.211, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.196, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.111, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.196, 0.0, 0.0, 0.237, 0.333, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.149, 0.0, 0.0, 0.0, 0.0, 0.524, 0.0, 0.0, 0.524, 0.524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.552, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.608, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.071, 0.239, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.284, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.524, 0.149, 0.524, 0.123, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.196, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.222, 0.0, 0.0, 0.0, 0.0, 0.0, 0.524, 0.0, 0.26, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.161, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.234, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.167, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.205, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.423, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.268, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.133, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.143, 0.0, 0.0, 0.0, 0.0, 0.0, 0.25, 0.0, 0.125, 0.0, 0.0, 0.0, 0.222, 0.0, 0.286, 0.222, 0.0, 0.123, 0.0, 0.0, 0.18, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.307, 0.0, 0.0, 0.0, 0.286, 0.0, 0.0, 0.307, 0.383, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.216, 0.306, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.404, 0.191, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.268, 0.0, 0.0, 0.0, 0.0, 0.0, 0.124, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.174, 0.0, 0.0, 0.0, 0.0, 0.524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.508, 0.0, 0.437, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.091, 0.0, 0.0, 0.0, 0.0, 0.306, 0.0, 0.0, 0.0, 0.0, 0.2, 0.286, 0.4, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.423, 0.355, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.163, 0.0, 0.04, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.211, 0.0, 0.0, 0.0, 0.0, 0.412, 0.0, 0.0, 0.412, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.524, 0.0, 0.524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.169, 0.0, 0.0, 0.524, 0.0, 0.12, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.208, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.19, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.266, 0.24, 0.0, 0.481, 0.425, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.111, 0.0, 0.0, 0.0, 0.0, 0.0, 0.209, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.195, 0.524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.355, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.423, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.355, 0.355, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.212, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.099, 0.0, 0.067, 0.149, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.385, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.302, 0.365, 0.434, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.133, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.339, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.37, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.109, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.247, 0.0, 0.0, 0.0, 0.177, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.468, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.18, 0.109, 0.0, 0.0, 0.376, 0.097, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.177, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.129, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.252, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.043, 0.0, 0.0, 0.138, 0.0, 0.151, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.117, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.211, 0.0, 0.0, 0.09, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.113, 0.108, 0.0, 0.0, 0.524, 0.0, 0.285, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.047, 0.0, 0.0, 0.0, 0.0, 0.0, 0.075, 0.0, 0.0, 0.0, 0.0, 0.0, 0.524, 0.0, 0.0, 0.307, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.462, 0.437, 0.0, 0.0, 0.35, 0.458, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.145, 0.0, 0.0, 0.0, 0.209, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.112, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.103, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.143, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.167, 0.0, 0.0, 0.394, 0.119, 0.0, 0.0, 0.0, 0.524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.121, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.155, 0.05, 0.0, 0.0, 0.0, 0.0, 0.099, 0.0, 0.0, 0.0, 0.073, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.145, 0.0, 0.133, 0.0, 0.0, 0.0, 0.0, 0.0, 0.412, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.286, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.165, 0.0, 0.0, 0.0, 0.0, 0.0, 0.124, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.105, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.134, 0.0, 0.0, 0.092, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.122, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.073, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.039, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.524, 0.0, 0.32, 0.0, 0.0, 0.524, 0.0, 0.169, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.156, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.524, 0.0, 0.064, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.248, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.209, 0.0, 0.0, 0.0, 0.0, 0.0, 0.281, 0.0, 0.0, 0.0, 0.0, 0.0, 0.524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.626, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.039, 0.0, 0.0, 0.0, 0.0, 0.0, 0.355, 0.154, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.416, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.098, 0.0, 0.111, 0.0, 0.0, 0.0, 0.0, 0.167, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.217, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.444, 0.231, 0.0, 0.0, 0.0, 0.0, 0.087, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.206, 0.107, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.224, 0.0, 0.0, 0.0, 0.31, 0.116, 0.0, 0.0, 0.0, 0.0, 0.0, 0.183, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.137, 0.0, 0.0, 0.459, 0.087, 0.235, 0.0, 0.524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34, 0.0, 0.0, 0.0, 0.443, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.211, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.296, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.307, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.383, 0.195, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.171, 0.0, 0.042, 0.0, 0.0, 0.114, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.099, 0.0, 0.524, 0.394, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.074, 0.0, 0.209, 0.037, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.145, 0.0, 0.0, 0.0, 0.0, 0.0, 0.231, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.633, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.071, 0.0, 0.0, 0.0, 0.0, 0.14, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.245, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.097, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.346, 0.0, 0.0, 0.0, 0.524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.207, 0.385, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.097, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.085, 0.0, 0.0, 0.0, 0.181, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.16, 0.0, 0.0, 0.0, 0.306, 0.143, 0.0, 0.0, 0.0, 0.0, 0.0, 0.242, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.054, 0.0, 0.0, 0.187, 0.302, 0.0, 0.0, 0.0, 0.0, 0.0, 0.151, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.074, 0.0, 0.167, 0.0, 0.0, 0.0, 0.076, 0.0, 0.0, 0.0, 0.0, 0.104, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.075, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.423, 0.129, 0.0, 0.0, 0.0, 0.074, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.474, 0.074, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11, 0.121, 0.0, 0.0, 0.451, 0.0, 0.213, 0.0, 0.0, 0.0, 0.307, 0.0, 0.0, 0.223, 0.0, 0.327, 0.0, 0.524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.167, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.463, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2, 0.0, 0.0, 0.0, 0.0, 0.524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.135, 0.0, 0.0, 0.118, 0.0, 0.0, 0.0, 0.0, 0.127, 0.103, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.268, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.094, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.188, 0.232, 0.174, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.047, 0.0, 0.524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.163, 0.0, 0.0, 0.0, 0.0, 0.0, 0.118, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.266, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.524, 0.524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.423, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.216, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.358, 0.0, 0.0, 0.0, 0.0, 0.0, 0.322, 0.131, 0.099, 0.0, 0.0, 0.039, 0.0, 0.0, 0.271, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.524, 0.0, 0.0, 0.258, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.18, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.109, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.14, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.239, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.315, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.078, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.085, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.339, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.196, 0.021, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.239, 0.0, 0.0, 0.0, 0.0, 0.2, 0.0, 0.0, 0.0, 0.0, 0.041, 0.191, 0.0, 0.279, 0.0, 0.0, 0.0, 0.0, 0.355, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.259, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.268, 0.0, 0.0, 0.0, 0.0, 0.28, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.174, 0.0, 0.0, 0.0, 0.0, 0.0, 0.108, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.167, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.242, 0.0, 0.0, 0.307, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.041, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.115, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.055, 0.0, 0.098, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.381, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.27, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.423, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.286, 0.0, 0.0, 0.0, 0.208, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.333, 0.135, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.256, 0.256, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.089, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.138, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.172, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.111, 0.0, 0.0, 0.0, 0.0, 0.254, 0.0, 0.0, 0.0, 0.0, 0.0, 0.309, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.394, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.256, 0.524, 0.171, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.218, 0.0, 0.524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.306, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.103, 0.0, 0.0, 0.326, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.145, 0.0, 0.333, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.136, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.496, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.444, 0.63, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.266, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.048, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.094, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.251, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.306, 0.0, 0.524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.136, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.095, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.226, 0.0, 0.0, 0.286, 0.0, 0.434, 0.0, 0.524, 0.0, 0.0, 0.0, 0.0, 0.293, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.065, 0.0, 0.0, 0.0, 0.0, 0.141, 0.0, 0.0, 0.0, 0.116, 0.0, 0.0, 0.0, 0.167, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.034, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.273, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.068, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.263, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.124, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.239, 0.0, 0.065, 0.0, 0.116, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.119, 0.0, 0.0, 0.0, 0.0, 0.0, 0.216, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.524, 0.0, 0.0, 0.091, 0.0, 0.0, 0.223, 0.16, 0.0, 0.0, 0.0, 0.156, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.524, 0.524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.113, 0.0, 0.0, 0.0, 0.0, 0.061, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.075, 0.0, 0.0, 0.0, 0.206, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.167, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.071, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.126, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.167, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.124, 0.0, 0.0, 0.07, 0.217, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.121, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.169, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.032, 0.0, 0.077, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.018, 0.0, 0.0, 0.205, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.363, 0.363, 0.12, 0.149, 0.0, 0.0, 0.0, 0.14, 0.0, 0.0, 0.236, 0.0, 0.191, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.333, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.115, 0.0, 0.0, 0.149, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.424, 0.0, 0.0, 0.0, 0.0, 0.196, 0.0, 0.0, 0.363, 0.285, 0.0, 0.0, 0.0, 0.149, 0.524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.355, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.306, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.252, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.094, 0.0, 0.0, 0.0, 0.216, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.307, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.196, 0.092, 0.167, 0.167, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06, 0.032, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.181, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.467, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.133, 0.0, 0.216, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.194, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.189, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.524, 0.0, 0.0, 0.209, 0.0, 0.0, 0.0, 0.206, 0.0, 0.0, 0.167, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.071, 0.161, 0.0, 0.294, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.311, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.524, 0.0, 0.0, 0.0, 0.437, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.206, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.101, 0.0, 0.0, 0.0, 0.182, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.155, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.058, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.053, 0.0, 0.0, 0.072, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.132, 0.0, 0.0, 0.0, 0.0, 0.0, 0.135, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.051, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.103, 0.0, 0.0, 0.0, 0.0, 0.524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.263, 0.0, 0.0, 0.0, 0.085, 0.206, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.524, 0.0, 0.305, 0.0, 0.0, 0.0, 0.0, 0.072, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.35, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.302, 0.0, 0.18, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.291, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.146, 0.0, 0.084, 0.608, 0.0, 0.0, 0.0, 0.367, 0.508, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.161, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.064, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.268, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.688, 0.0, 0.131, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.109, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.339, 0.0, 0.0, 0.0, 0.524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.246, 0.0, 0.0, 0.0, 0.0, 0.0, 0.169, 0.149, 0.149, 0.0, 0.182, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.216, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.248, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.394, 0.0, 0.0, 0.0, 0.524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.046, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.268, 0.196, 0.367, 0.169, 0.234, 0.104, 0.0, 0.0, 0.0, 0.0, 0.149, 0.0, 0.0, 0.0, 0.0, 0.0, 0.239, 0.0, 0.0, 0.422, 0.0, 0.263, 0.0, 0.0, 0.0, 0.327, 0.0, 0.0, 0.0, 0.0, 0.117, 0.0, 0.0, 0.244, 0.0, 0.0, 0.524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.091, 0.0, 0.0, 0.0, 0.0, 0.0, 0.22, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.077, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.151, 0.0, 0.0, 0.239, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.096, 0.0, 0.0, 0.0, 0.0, 0.0, 0.216, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.104, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.403, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.037, 0.167, 0.0, 0.0, 0.0, 0.0, 0.216, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.182, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.058, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.318, 0.0, 0.0, 0.174, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.18, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.076, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.367, 0.149, 0.0, 0.0, 0.182, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.496, 0.524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.297, 0.286, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.071, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.045, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.053, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.306, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.067, 0.0, 0.0, 0.0, 0.0, 0.0, 0.345, 0.0, 0.0, 0.0, 0.394, 0.0, 0.0, 0.0, 0.0, 0.0, 0.141, 0.412, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.181, 0.394, 0.0, 0.0, 0.0, 0.268, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.524, 0.45, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.524, 0.0, 0.0, 0.0, 0.0, 0.239, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.145, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08, 0.0, 0.0, 0.268, 0.0, 0.079, 0.0, 0.0, 0.0, 0.0, 0.0, 0.268, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.524, 0.0, 0.0, 0.0, 0.524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.063, 0.0, 0.152, 0.072, 0.0, 0.0, 0.0, 0.0, 0.0, 0.121, 0.031, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.278, 0.184, 0.097, 0.089, 0.0, 0.0, 0.259, 0.0, 0.0, 0.0, 0.0, 0.0, 0.195, 0.0, 0.0, 0.524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.524, 0.0, 0.0, 0.0, 0.0, 0.13, 0.0, 0.0, 0.0, 0.0, 0.0, 0.225, 0.0, 0.0, 0.0, 0.0, 0.268, 0.277, 0.0, 0.0, 0.0, 0.0, 0.0, 0.15, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.216, 0.0, 0.589, 0.0, 0.215, 0.0, 0.196, 0.0, 0.091, 0.0, 0.0, 0.0, 0.0, 0.216, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.524, 0.467, 0.0, 0.0, 0.0, 0.0, 0.381, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.492, 0.0, 0.0, 0.0, 0.412, 0.0, 0.0, 0.403, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.099, 0.232, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.106, 0.302, 0.0, 0.0, 0.355, 0.0, 0.0, 0.0, 0.0, 0.0, 0.236, 0.0, 0.0, 0.2, 0.094, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.286, 0.0, 0.231, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13, 0.0, 0.0, 0.0, 0.0, 0.2, 0.245, 0.0, 0.0, 0.423, 0.162, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.355, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.292, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.188, 0.524, 0.524, 0.0, 0.0, 0.284, 0.13, 0.524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.173, 0.0, 0.0, 0.0, 0.26, 0.0, 0.0, 0.113, 0.0, 0.0, 0.0, 0.0, 0.156, 0.0, 0.0, 0.0, 0.13, 0.0, 0.0, 0.0, 0.0, 0.311, 0.0, 0.383, 0.242, 0.443, 0.524, 0.0, 0.0, 0.0, 0.0, 0.144, 0.524, 0.0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "eEIFUO5n_L7F",
        "colab_type": "code",
        "outputId": "dc605dac-7c57-487c-e07a-097f1fcd515a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import itertools\n",
        "from keras.preprocessing import sequence\n",
        "vocabulary_file = 'vocabulary_twitter'\n",
        "padded_context_file = 'Padded_context'\n",
        "padded_answers_file = 'Padded_answers'\n",
        "unknown_token = 'something'\n",
        "\n",
        "vocabulary_size = 10000\n",
        "max_features = vocabulary_size\n",
        "maxlen_input = 50\n",
        "maxlen_output = 50  # cut texts after this number of words\n",
        "\n",
        "all = ' '.join(all)\n",
        "tokenized_all = all.split()\n",
        "tokenized_context = [t.split() for t in context]\n",
        "tokenized_answers = [t.split() for t in answers]\n",
        "\n",
        "word_freq = nltk.FreqDist(itertools.chain(tokenized_all))\n",
        "print (\"Found %d unique words tokens.\" % len(word_freq.items()))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Found 20558 unique words tokens.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "mKy5TunA_PNv",
        "colab_type": "code",
        "outputId": "1637b893-f0ee-4aeb-9f60-b847653e8666",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "vocab = word_freq.most_common(vocabulary_size-1)\n",
        "with open(vocabulary_file, 'wb') as v:\n",
        "  pickle.dump(vocab, v)\n",
        "\n",
        "print(vocab[0:20])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('STA', 50000), ('END', 50000), ('i', 11864), ('is', 11570), ('you', 9721), ('it', 9466), ('the', 9461), ('not', 7981), ('and', 7366), ('that', 6562), ('a', 6493), ('to', 6405), ('have', 4871), ('do', 3927), ('in', 3922), ('of', 3704), ('yeah', 3608), ('are', 3315), ('they', 3195), ('he', 3166)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "SS9Jbs0A_SCl",
        "colab_type": "code",
        "outputId": "04e5c75f-cc4d-40cf-e109-15d830f7952a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "cell_type": "code",
      "source": [
        "vocab = pickle.load(open(vocabulary_file, 'rb'))\n",
        "index_to_word = [x[0] for x in vocab]\n",
        "index_to_word.append(unknown_token)\n",
        "word_to_index = dict([(w,i) for i,w in enumerate(index_to_word)])\n",
        "\n",
        "print (\"Using vocabulary of size %d.\" % vocabulary_size)\n",
        "print (\"The least frequent word in our vocabulary is '%s' and appeared %d times.\" % (vocab[-1][0], vocab[-1][1]))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using vocabulary of size 10000.\n",
            "The least frequent word in our vocabulary is 'smokeslily' and appeared 1 times.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "rsElu_dP_Ua4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "# Replacing all words not in our vocabulary with the unknown token:\n",
        "for i, sent in enumerate(tokenized_answers):\n",
        "  tokenized_answers[i] = [w if w in word_to_index else unknown_token for w in sent]\n",
        "   \n",
        "for i, sent in enumerate(tokenized_context):\n",
        "  tokenized_context[i] = [w if w in word_to_index else unknown_token for w in sent]\n",
        "\n",
        "# Creating the training data:\n",
        "X = np.asarray([[word_to_index[w] for w in sent] for sent in tokenized_context])\n",
        "Y = np.asarray([[word_to_index[w] for w in sent] for sent in tokenized_answers])\n",
        "\n",
        "Q = sequence.pad_sequences(X, maxlen=maxlen_input, padding='post')\n",
        "A = sequence.pad_sequences(Y, maxlen=maxlen_output, padding='post')\n",
        "\n",
        "row, col = Q.shape\n",
        "for i in range(row):\n",
        "  Q[i,:] = Q[i,:]*context_sentiments[i]\n",
        "\n",
        "\n",
        "with open(padded_context_file, 'wb') as q:\n",
        "    pickle.dump(Q, q)\n",
        "    \n",
        "with open(padded_answers_file, 'wb') as a:\n",
        "    pickle.dump(A, a)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yg76ZiVv-1SG",
        "colab_type": "code",
        "outputId": "9b71735d-4e2e-4065-9c69-0e843e94b992",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "print(Q.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(25000, 50)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "V4hG9clF_Xlk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import requests\n",
        "file_url = \"http://nlp.stanford.edu/data/glove.6B.zip\"\n",
        "tr = requests.get(file_url, stream=True)\n",
        "with open(\"glove.6B.zip\", \"wb\") as f:\n",
        "    for chunk in tr.iter_content(chunk_size=1024):\n",
        "        if chunk:\n",
        "            f.write(chunk)\n",
        "            \n",
        "            \n",
        "import zipfile\n",
        "import os\n",
        "def un_zip(file_name):\n",
        "    \"\"\"unzip zip file\"\"\"\n",
        "    zip_file = zipfile.ZipFile(file_name)\n",
        "    if os.path.isdir(file_name + \"_files\"):\n",
        "        pass\n",
        "    else:\n",
        "        os.mkdir(file_name + \"_files\")\n",
        "    for names in zip_file.namelist():\n",
        "        zip_file.extract(names,file_name + \"_files/\")\n",
        "    zip_file.close()\n",
        "        \n",
        "glove = un_zip(\"glove.6B.zip\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "X0zFIatn_bn4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "padded_context_file = 'Padded_context'\n",
        "padded_answers_file = 'Padded_answers'\n",
        "unknown_token = 'something'\n",
        "word_embedding_size = 100\n",
        "sentence_embedding_size = 300\n",
        "dictionary_size = 10000\n",
        "maxlen_input = 50\n",
        "maxlen_output = 50\n",
        "num_subsets = 10\n",
        "Epochs = 50\n",
        "BatchSize = 128 \n",
        "Patience = 0\n",
        "dropout = .2\n",
        "n_test = 100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vPSeHTgw_eeP",
        "colab_type": "code",
        "outputId": "d162cfd1-a75d-4732-b471-3a3b16cef742",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "cell_type": "code",
      "source": [
        "import _pickle\n",
        "import numpy as np\n",
        "\n",
        "embeddings_index = {}\n",
        "f = open('./glove.6B.zip_files/glove.6B.100d.txt')\n",
        "for line in f:\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    coefs = np.asarray(values[1:], dtype='float32')\n",
        "    embeddings_index[word] = coefs\n",
        "f.close()\n",
        "\n",
        "print('Found %s word vectors.' % len(embeddings_index))\n",
        "embedding_matrix = np.zeros((dictionary_size, word_embedding_size))\n",
        "\n",
        "# Loading our vocabulary:\n",
        "vocabulary = _pickle.load(open(vocabulary_file, 'rb'))\n",
        "\n",
        "# Using the Glove embedding:\n",
        "i = 0\n",
        "for word in vocabulary:\n",
        "    embedding_vector = embeddings_index.get(word[0])\n",
        "    \n",
        "    if embedding_vector is not None:\n",
        "        # words not found in embedding index will be all-zeros.\n",
        "        embedding_matrix[i] = embedding_vector\n",
        "    i += 1\n",
        "    \n",
        "print(embedding_matrix)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 400000 word vectors.\n",
            "[[ 0.          0.          0.         ...  0.          0.\n",
            "   0.        ]\n",
            " [ 0.          0.          0.         ...  0.          0.\n",
            "   0.        ]\n",
            " [-0.046539    0.61966002  0.56647003 ... -0.37616    -0.032502\n",
            "   0.80620003]\n",
            " ...\n",
            " [ 0.          0.          0.         ...  0.          0.\n",
            "   0.        ]\n",
            " [ 0.          0.          0.         ...  0.          0.\n",
            "   0.        ]\n",
            " [ 0.          0.          0.         ...  0.          0.\n",
            "   0.        ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "s-pWlk3-_hen",
        "colab_type": "code",
        "outputId": "1f9692bb-985f-43b2-811f-f7d454975576",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 595
        }
      },
      "cell_type": "code",
      "source": [
        "from keras.layers import Input, Embedding, LSTM, Dense, RepeatVector, Bidirectional, Dropout, concatenate\n",
        "from keras.optimizers import Adam, SGD\n",
        "from keras.models import Model\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Activation, Dense\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.preprocessing import sequence\n",
        "import keras.backend as K\n",
        "import os\n",
        "import theano.tensor as T\n",
        "import os\n",
        "import pandas as pd\n",
        "import sys\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "weights_file = 'assignment4_twitter_neg.h5'\n",
        "ad = Adam(lr=0.00005) \n",
        "\n",
        "input_context = Input(shape=(maxlen_input,), name='input_context')\n",
        "input_answer = Input(shape=(maxlen_input,), name='input_answer')\n",
        "LSTM_encoder = LSTM(sentence_embedding_size, init= 'lecun_uniform')\n",
        "LSTM_decoder = LSTM(sentence_embedding_size, init= 'lecun_uniform')\n",
        "if os.path.isfile(weights_file):\n",
        "    Shared_Embedding = Embedding(output_dim=word_embedding_size, input_dim=dictionary_size, input_length=maxlen_input)\n",
        "else:\n",
        "    Shared_Embedding = Embedding(output_dim=word_embedding_size, input_dim=dictionary_size, weights=[embedding_matrix], input_length=maxlen_input)\n",
        "word_embedding_context = Shared_Embedding(input_context)\n",
        "context_embedding = LSTM_encoder(word_embedding_context)\n",
        "\n",
        "word_embedding_answer = Shared_Embedding(input_answer)\n",
        "answer_embedding = LSTM_decoder(word_embedding_answer)\n",
        "\n",
        "merge_layer = concatenate([context_embedding, answer_embedding])\n",
        "out = Dense(int(dictionary_size/2), activation=\"relu\")(merge_layer)\n",
        "out = Dense(dictionary_size, activation=\"softmax\")(out)\n",
        "\n",
        "model = Model(input=[input_context, input_answer], output = [out])\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer=ad)\n",
        "\n",
        "if os.path.isfile(weights_file):\n",
        "    model.load_weights(weights_file)\n",
        "    \n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:21: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(300, kernel_initializer=\"lecun_uniform\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:22: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(300, kernel_initializer=\"lecun_uniform\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:37: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=[<tf.Tenso...)`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_context (InputLayer)      (None, 50)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_answer (InputLayer)       (None, 50)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, 50, 100)      1000000     input_context[0][0]              \n",
            "                                                                 input_answer[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   (None, 300)          481200      embedding_1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lstm_2 (LSTM)                   (None, 300)          481200      embedding_1[1][0]                \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 600)          0           lstm_1[0][0]                     \n",
            "                                                                 lstm_2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 5000)         3005000     concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 10000)        50010000    dense_1[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 54,977,400\n",
            "Trainable params: 54,977,400\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "UmuRmGWd_kmf",
        "colab_type": "code",
        "outputId": "b596bfca-1465-436b-82e5-64da7f69d16f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "cell_type": "code",
      "source": [
        "q = _pickle.load(open(padded_context_file, 'rb'))\n",
        "a = _pickle.load(open(padded_answers_file, 'rb'))\n",
        "n_exem, n_words = a.shape\n",
        "\n",
        "print('Number of exemples = %d'%(n_exem))\n",
        "step = int(np.around(n_exem/num_subsets))\n",
        "round_exem = int(step * num_subsets)\n",
        "print(step, round_exem)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of exemples = 25000\n",
            "2500 25000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "7KpVa5oL_oMD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def print_result(input):\n",
        "  ans_partial = np.zeros((1,maxlen_input))\n",
        "  ans_partial[0,-1] = 0 #index of STA\n",
        "  for k in range(maxlen_input - 1):\n",
        "    ye = model.predict([input, ans_partial])\n",
        "    mp = np.argmax(ye)\n",
        "    ans_partial[0, 0:-1] = ans_partial[0, 1:]\n",
        "    ans_partial[0, -1] = mp\n",
        "  text = ''\n",
        "  for k in ans_partial[0]:\n",
        "    k = k.astype(int)\n",
        "    if k < (dictionary_size-2):\n",
        "      w = vocabulary[k]\n",
        "      text = text + w[0] + ' '\n",
        "  return(text)\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "H11kNtzI_rJ0",
        "colab_type": "code",
        "outputId": "4144b083-6076-47bf-dba0-363c119aa3d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 15401
        }
      },
      "cell_type": "code",
      "source": [
        "x = range(0,Epochs) \n",
        "valid_loss = np.zeros(Epochs)\n",
        "train_loss = np.zeros(Epochs)\n",
        "for m in range(Epochs):\n",
        "  # Loop over training batches due to memory constraints:\n",
        "  for n in range(0,round_exem,step):\n",
        "    q2 = q[n:n+step]\n",
        "    s = q2.shape\n",
        "    count = 0\n",
        "    for i, sent in enumerate(a[n:n+step]):\n",
        "      l = np.where(sent==1)\n",
        "      limit = l[0][0]\n",
        "      count += limit + 1\n",
        "    Q = np.zeros((count,maxlen_input))\n",
        "    A = np.zeros((count,maxlen_input))\n",
        "    Y = np.zeros((count,dictionary_size))\n",
        "    \n",
        "    count = 0\n",
        "    for i, sent in enumerate(a[n:n+step]):\n",
        "      ans_partial = np.zeros((1,maxlen_input))\n",
        "      # Loop over the positions of the current target output (the current output sequence):\n",
        "      l = np.where(sent==1)\n",
        "      limit = l[0][0]\n",
        "      for k in range(1,limit+1):\n",
        "        # Mapping the target output (the next output word) for one-hot codding:\n",
        "        y = np.zeros((1, dictionary_size))\n",
        "        y[0, sent[k]] = 1\n",
        "        # preparing the partial answer to input:\n",
        "        ans_partial[0,-k:] = sent[0:k]\n",
        "        # training the model for one epoch using teacher forcing:\n",
        "        Q[count, :] = q2[i:i+1] \n",
        "        A[count, :] = ans_partial \n",
        "        Y[count, :] = y\n",
        "        count += 1\n",
        "    print('Training epoch: %d, training examples: %d - %d'%(m,n, n + step))\n",
        "    model.fit([Q, A], Y, batch_size=BatchSize, epochs=1)\n",
        "    test_input = q[6:7]\n",
        "    print(print_result(test_input))\n",
        "  model.save_weights(weights_file, overwrite=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training epoch: 0, training examples: 0 - 2500\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Epoch 1/1\n",
            "30123/30123 [==============================] - 91s 3ms/step - loss: 6.8002\n",
            "STA i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i be END END END END END END END END END END \n",
            "Training epoch: 0, training examples: 2500 - 5000\n",
            "Epoch 1/1\n",
            "20594/20594 [==============================] - 57s 3ms/step - loss: 5.0909\n",
            "STA i END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END \n",
            "Training epoch: 0, training examples: 5000 - 7500\n",
            "Epoch 1/1\n",
            "20302/20302 [==============================] - 56s 3ms/step - loss: 4.7837\n",
            "STA yeah END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END \n",
            "Training epoch: 0, training examples: 7500 - 10000\n",
            "Epoch 1/1\n",
            "19285/19285 [==============================] - 53s 3ms/step - loss: 4.7862\n",
            "STA yeah END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END \n",
            "Training epoch: 0, training examples: 10000 - 12500\n",
            "Epoch 1/1\n",
            "21589/21589 [==============================] - 58s 3ms/step - loss: 4.7001\n",
            "STA yeah END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END \n",
            "Training epoch: 0, training examples: 12500 - 15000\n",
            "Epoch 1/1\n",
            "19675/19675 [==============================] - 52s 3ms/step - loss: 4.5906\n",
            "STA i END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END \n",
            "Training epoch: 0, training examples: 15000 - 17500\n",
            "Epoch 1/1\n",
            "23039/23039 [==============================] - 61s 3ms/step - loss: 4.7842\n",
            "STA i END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END \n",
            "Training epoch: 0, training examples: 17500 - 20000\n",
            "Epoch 1/1\n",
            "18116/18116 [==============================] - 49s 3ms/step - loss: 4.4370\n",
            "STA i am END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END \n",
            "Training epoch: 0, training examples: 20000 - 22500\n",
            "Epoch 1/1\n",
            "22546/22546 [==============================] - 60s 3ms/step - loss: 4.8353\n",
            "STA i have END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END \n",
            "Training epoch: 0, training examples: 22500 - 25000\n",
            "Epoch 1/1\n",
            "23311/23311 [==============================] - 63s 3ms/step - loss: 4.7215\n",
            "STA i have got END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END \n",
            "Training epoch: 1, training examples: 0 - 2500\n",
            "Epoch 1/1\n",
            "30123/30123 [==============================] - 81s 3ms/step - loss: 5.1522\n",
            "STA i am END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END \n",
            "Training epoch: 1, training examples: 2500 - 5000\n",
            "Epoch 1/1\n",
            "20594/20594 [==============================] - 55s 3ms/step - loss: 4.5749\n",
            "STA i have got END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END \n",
            "Training epoch: 1, training examples: 5000 - 7500\n",
            "Epoch 1/1\n",
            "20302/20302 [==============================] - 54s 3ms/step - loss: 4.3852\n",
            "STA yeah END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END \n",
            "Training epoch: 1, training examples: 7500 - 10000\n",
            "Epoch 1/1\n",
            "19285/19285 [==============================] - 53s 3ms/step - loss: 4.4070\n",
            "STA yeah END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END \n",
            "Training epoch: 1, training examples: 10000 - 12500\n",
            "Epoch 1/1\n",
            "21589/21589 [==============================] - 59s 3ms/step - loss: 4.3289\n",
            "STA yeah END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END \n",
            "Training epoch: 1, training examples: 12500 - 15000\n",
            "Epoch 1/1\n",
            "19675/19675 [==============================] - 55s 3ms/step - loss: 4.2772\n",
            "STA i am END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END \n",
            "Training epoch: 1, training examples: 15000 - 17500\n",
            "Epoch 1/1\n",
            "23039/23039 [==============================] - 64s 3ms/step - loss: 4.4793\n",
            "STA i will not END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END \n",
            "Training epoch: 1, training examples: 17500 - 20000\n",
            "Epoch 1/1\n",
            "18116/18116 [==============================] - 49s 3ms/step - loss: 4.1273\n",
            "STA i am END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END \n",
            "Training epoch: 1, training examples: 20000 - 22500\n",
            "Epoch 1/1\n",
            "22546/22546 [==============================] - 62s 3ms/step - loss: 4.5232\n",
            "STA i have got END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END \n",
            "Training epoch: 1, training examples: 22500 - 25000\n",
            "Epoch 1/1\n",
            "23311/23311 [==============================] - 66s 3ms/step - loss: 4.4393\n",
            "STA i am END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END \n",
            "Training epoch: 2, training examples: 0 - 2500\n",
            "Epoch 1/1\n",
            "30123/30123 [==============================] - 85s 3ms/step - loss: 4.8690\n",
            "STA i think END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END \n",
            "Training epoch: 2, training examples: 2500 - 5000\n",
            "Epoch 1/1\n",
            "20594/20594 [==============================] - 58s 3ms/step - loss: 4.3680\n",
            "STA i have got a END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END \n",
            "Training epoch: 2, training examples: 5000 - 7500\n",
            "Epoch 1/1\n",
            "20302/20302 [==============================] - 57s 3ms/step - loss: 4.1866\n",
            "STA yeah END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END \n",
            "Training epoch: 2, training examples: 7500 - 10000\n",
            "Epoch 1/1\n",
            "19285/19285 [==============================] - 54s 3ms/step - loss: 4.2209\n",
            "STA i have got a END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END \n",
            "Training epoch: 2, training examples: 10000 - 12500\n",
            "Epoch 1/1\n",
            "21589/21589 [==============================] - 59s 3ms/step - loss: 4.1589\n",
            "STA yeah END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END \n",
            "Training epoch: 2, training examples: 12500 - 15000\n",
            "Epoch 1/1\n",
            "19675/19675 [==============================] - 53s 3ms/step - loss: 4.1160\n",
            "STA i am END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END \n",
            "Training epoch: 2, training examples: 15000 - 17500\n",
            "Epoch 1/1\n",
            "23039/23039 [==============================] - 62s 3ms/step - loss: 4.3201\n",
            "STA i will not END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END \n",
            "Training epoch: 2, training examples: 17500 - 20000\n",
            "Epoch 1/1\n",
            "18116/18116 [==============================] - 48s 3ms/step - loss: 3.9641\n",
            "STA i am END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END \n",
            "Training epoch: 2, training examples: 20000 - 22500\n",
            "Epoch 1/1\n",
            "22546/22546 [==============================] - 63s 3ms/step - loss: 4.3402\n",
            "STA i am not END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END \n",
            "Training epoch: 2, training examples: 22500 - 25000\n",
            "Epoch 1/1\n",
            "23311/23311 [==============================] - 66s 3ms/step - loss: 4.2588\n",
            "STA i am not END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END \n",
            "Training epoch: 3, training examples: 0 - 2500\n",
            "Epoch 1/1\n",
            "30123/30123 [==============================] - 86s 3ms/step - loss: 4.6840\n",
            "STA i think i think i have got a END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END \n",
            "Training epoch: 3, training examples: 2500 - 5000\n",
            "Epoch 1/1\n",
            "20594/20594 [==============================] - 58s 3ms/step - loss: 4.2115\n",
            "STA i am not END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END \n",
            "Training epoch: 3, training examples: 5000 - 7500\n",
            "Epoch 1/1\n",
            "20302/20302 [==============================] - 57s 3ms/step - loss: 4.0375\n",
            "STA yeah END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END \n",
            "Training epoch: 3, training examples: 7500 - 10000\n",
            "Epoch 1/1\n",
            "19285/19285 [==============================] - 54s 3ms/step - loss: 4.0792\n",
            "STA i have got a END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END \n",
            "Training epoch: 3, training examples: 10000 - 12500\n",
            "Epoch 1/1\n",
            "21589/21589 [==============================] - 61s 3ms/step - loss: 4.0217\n",
            "STA yeah END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END \n",
            "Training epoch: 3, training examples: 12500 - 15000\n",
            "Epoch 1/1\n",
            "19675/19675 [==============================] - 56s 3ms/step - loss: 3.9849\n",
            "STA i am not END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END \n",
            "Training epoch: 3, training examples: 15000 - 17500\n",
            "Epoch 1/1\n",
            "23039/23039 [==============================] - 65s 3ms/step - loss: 4.1893\n",
            "STA i am not END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END \n",
            "Training epoch: 3, training examples: 17500 - 20000\n",
            "Epoch 1/1\n",
            "18116/18116 [==============================] - 49s 3ms/step - loss: 3.8330\n",
            "STA i am not END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END \n",
            "Training epoch: 3, training examples: 20000 - 22500\n",
            "Epoch 1/1\n",
            "22546/22546 [==============================] - 60s 3ms/step - loss: 4.2051\n",
            "STA i have got a END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END \n",
            "Training epoch: 3, training examples: 22500 - 25000\n",
            "Epoch 1/1\n",
            "23311/23311 [==============================] - 62s 3ms/step - loss: 4.1243\n",
            "STA i am not END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END \n",
            "Training epoch: 4, training examples: 0 - 2500\n",
            "Epoch 1/1\n",
            "30123/30123 [==============================] - 80s 3ms/step - loss: 4.5278\n",
            "STA i am not END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END \n",
            "Training epoch: 4, training examples: 2500 - 5000\n",
            "Epoch 1/1\n",
            "20594/20594 [==============================] - 53s 3ms/step - loss: 4.0808\n",
            "STA i am not END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END \n",
            "Training epoch: 4, training examples: 5000 - 7500\n",
            "Epoch 1/1\n",
            "20302/20302 [==============================] - 54s 3ms/step - loss: 3.9165\n",
            "STA yeah END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END \n",
            "Training epoch: 4, training examples: 7500 - 10000\n",
            "Epoch 1/1\n",
            "19285/19285 [==============================] - 53s 3ms/step - loss: 3.9596\n",
            "STA yeah END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END \n",
            "Training epoch: 4, training examples: 10000 - 12500\n",
            "Epoch 1/1\n",
            "21589/21589 [==============================] - 57s 3ms/step - loss: 3.9040\n",
            "STA yeah END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END \n",
            "Training epoch: 4, training examples: 12500 - 15000\n",
            "Epoch 1/1\n",
            "19675/19675 [==============================] - 52s 3ms/step - loss: 3.8760\n",
            "STA i am not END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END \n",
            "Training epoch: 4, training examples: 15000 - 17500\n",
            "Epoch 1/1\n",
            "23039/23039 [==============================] - 61s 3ms/step - loss: 4.0766\n",
            "STA i am not END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END \n",
            "Training epoch: 4, training examples: 17500 - 20000\n",
            "Epoch 1/1\n",
            "18116/18116 [==============================] - 50s 3ms/step - loss: 3.7183\n",
            "STA i am not END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END \n",
            "Training epoch: 4, training examples: 20000 - 22500\n",
            "Epoch 1/1\n",
            "22546/22546 [==============================] - 62s 3ms/step - loss: 4.0886\n",
            "STA i do not know END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END \n",
            "Training epoch: 4, training examples: 22500 - 25000\n",
            "Epoch 1/1\n",
            "23311/23311 [==============================] - 65s 3ms/step - loss: 4.0084\n",
            "STA i am not END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END \n",
            "Training epoch: 5, training examples: 0 - 2500\n",
            "Epoch 1/1\n",
            "30123/30123 [==============================] - 82s 3ms/step - loss: 4.3963\n",
            "STA i think it is not END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END \n",
            "Training epoch: 5, training examples: 2500 - 5000\n",
            "Epoch 1/1\n",
            "20594/20594 [==============================] - 56s 3ms/step - loss: 3.9669\n",
            "STA i am not END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END \n",
            "Training epoch: 5, training examples: 5000 - 7500\n",
            "Epoch 1/1\n",
            "20302/20302 [==============================] - 54s 3ms/step - loss: 3.8138\n",
            "STA yeah END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END \n",
            "Training epoch: 5, training examples: 7500 - 10000\n",
            "Epoch 1/1\n",
            "19285/19285 [==============================] - 51s 3ms/step - loss: 3.8533\n",
            "STA i have got a END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END \n",
            "Training epoch: 5, training examples: 10000 - 12500\n",
            "Epoch 1/1\n",
            "21589/21589 [==============================] - 57s 3ms/step - loss: 3.7985\n",
            "STA yeah END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END \n",
            "Training epoch: 5, training examples: 12500 - 15000\n",
            "Epoch 1/1\n",
            "19675/19675 [==============================] - 56s 3ms/step - loss: 3.7733\n",
            "STA i am not END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END \n",
            "Training epoch: 5, training examples: 15000 - 17500\n",
            "Epoch 1/1\n",
            "23039/23039 [==============================] - 65s 3ms/step - loss: 3.9753\n",
            "STA yeah END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END \n",
            "Training epoch: 5, training examples: 17500 - 20000\n",
            "Epoch 1/1\n",
            "18116/18116 [==============================] - 51s 3ms/step - loss: 3.6117\n",
            "STA i am not END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END \n",
            "Training epoch: 5, training examples: 20000 - 22500\n",
            "Epoch 1/1\n",
            "22546/22546 [==============================] - 64s 3ms/step - loss: 3.9851\n",
            "STA i have got a END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END \n",
            "Training epoch: 5, training examples: 22500 - 25000\n",
            "Epoch 1/1\n",
            "23311/23311 [==============================] - 67s 3ms/step - loss: 3.9078\n",
            "STA i am not END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END \n",
            "Training epoch: 6, training examples: 0 - 2500\n",
            "Epoch 1/1\n",
            "30123/30123 [==============================] - 87s 3ms/step - loss: 4.2760\n",
            "STA i think it is not END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END \n",
            "Training epoch: 6, training examples: 2500 - 5000\n",
            "Epoch 1/1\n",
            "20594/20594 [==============================] - 59s 3ms/step - loss: 3.8626\n",
            "STA i am not END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END \n",
            "Training epoch: 6, training examples: 5000 - 7500\n",
            "Epoch 1/1\n",
            "20302/20302 [==============================] - 57s 3ms/step - loss: 3.7202\n",
            "STA yeah END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END \n",
            "Training epoch: 6, training examples: 7500 - 10000\n",
            "Epoch 1/1\n",
            "19285/19285 [==============================] - 52s 3ms/step - loss: 3.7578\n",
            "STA yeah END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END \n",
            "Training epoch: 6, training examples: 10000 - 12500\n",
            "Epoch 1/1\n",
            "21589/21589 [==============================] - 58s 3ms/step - loss: 3.6985\n",
            "STA yeah END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END \n",
            "Training epoch: 6, training examples: 12500 - 15000\n",
            "Epoch 1/1\n",
            "19675/19675 [==============================] - 53s 3ms/step - loss: 3.6711\n",
            "STA i am not END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END \n",
            "Training epoch: 6, training examples: 15000 - 17500\n",
            "Epoch 1/1\n",
            "23039/23039 [==============================] - 62s 3ms/step - loss: 3.8799\n",
            "STA i am not END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END \n",
            "Training epoch: 6, training examples: 17500 - 20000\n",
            "Epoch 1/1\n",
            "18116/18116 [==============================] - 51s 3ms/step - loss: 3.5179\n",
            "STA i am not END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END \n",
            "Training epoch: 6, training examples: 20000 - 22500\n",
            "Epoch 1/1\n",
            "22546/22546 [==============================] - 61s 3ms/step - loss: 3.8853\n",
            "STA i do not know END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END \n",
            "Training epoch: 6, training examples: 22500 - 25000\n",
            "Epoch 1/1\n",
            "23311/23311 [==============================] - 62s 3ms/step - loss: 3.8088\n",
            "STA i am not END it is a END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END \n",
            "Training epoch: 7, training examples: 0 - 2500\n",
            "Epoch 1/1\n",
            "30123/30123 [==============================] - 82s 3ms/step - loss: 4.1580\n",
            "STA i think it is a END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END \n",
            "Training epoch: 7, training examples: 2500 - 5000\n",
            "Epoch 1/1\n",
            "20594/20594 [==============================] - 57s 3ms/step - loss: 3.7570\n",
            "STA i am not END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END \n",
            "Training epoch: 7, training examples: 5000 - 7500\n",
            "Epoch 1/1\n",
            "20302/20302 [==============================] - 57s 3ms/step - loss: 3.6312\n",
            "STA yeah END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END \n",
            "Training epoch: 7, training examples: 7500 - 10000\n",
            "Epoch 1/1\n",
            "19285/19285 [==============================] - 54s 3ms/step - loss: 3.6624\n",
            "STA yeah END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END \n",
            "Training epoch: 7, training examples: 10000 - 12500\n",
            "Epoch 1/1\n",
            "21589/21589 [==============================] - 59s 3ms/step - loss: 3.5972\n",
            "STA yeah END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END \n",
            "Training epoch: 7, training examples: 12500 - 15000\n",
            "Epoch 1/1\n",
            "19675/19675 [==============================] - 55s 3ms/step - loss: 3.5729\n",
            "STA i am not END it END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END \n",
            "Training epoch: 7, training examples: 15000 - 17500\n",
            "Epoch 1/1\n",
            "23039/23039 [==============================] - 64s 3ms/step - loss: 3.7804\n",
            "STA yeah END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END \n",
            "Training epoch: 7, training examples: 17500 - 20000\n",
            "Epoch 1/1\n",
            "18116/18116 [==============================] - 50s 3ms/step - loss: 3.4257\n",
            "STA i am not END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END \n",
            "Training epoch: 7, training examples: 20000 - 22500\n",
            "Epoch 1/1\n",
            "22546/22546 [==============================] - 62s 3ms/step - loss: 3.7864\n",
            "STA i do not know END is the END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END \n",
            "Training epoch: 7, training examples: 22500 - 25000\n",
            "Epoch 1/1\n",
            "23311/23311 [==============================] - 64s 3ms/step - loss: 3.7129\n",
            "STA i do not want to go to the END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END \n",
            "Training epoch: 8, training examples: 0 - 2500\n",
            "Epoch 1/1\n",
            "30123/30123 [==============================] - 81s 3ms/step - loss: 4.0342\n",
            "STA i am not END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END \n",
            "Training epoch: 8, training examples: 2500 - 5000\n",
            "Epoch 1/1\n",
            "20594/20594 [==============================] - 55s 3ms/step - loss: 3.6563\n",
            "STA i am not it END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END \n",
            "Training epoch: 8, training examples: 5000 - 7500\n",
            "Epoch 1/1\n",
            "20302/20302 [==============================] - 55s 3ms/step - loss: 3.5380\n",
            "STA yeah END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END \n",
            "Training epoch: 8, training examples: 7500 - 10000\n",
            "Epoch 1/1\n",
            "19285/19285 [==============================] - 53s 3ms/step - loss: 3.5697\n",
            "STA yeah END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END \n",
            "Training epoch: 8, training examples: 10000 - 12500\n",
            "Epoch 1/1\n",
            "21589/21589 [==============================] - 60s 3ms/step - loss: 3.5013\n",
            "STA yeah END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END \n",
            "Training epoch: 8, training examples: 12500 - 15000\n",
            "Epoch 1/1\n",
            "19675/19675 [==============================] - 56s 3ms/step - loss: 3.4730\n",
            "STA i am not END it END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END \n",
            "Training epoch: 8, training examples: 15000 - 17500\n",
            "Epoch 1/1\n",
            "23039/23039 [==============================] - 65s 3ms/step - loss: 3.6786\n",
            "STA i am not END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END \n",
            "Training epoch: 8, training examples: 17500 - 20000\n",
            "Epoch 1/1\n",
            "18116/18116 [==============================] - 51s 3ms/step - loss: 3.3301\n",
            "STA i am not END it END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END \n",
            "Training epoch: 8, training examples: 20000 - 22500\n",
            "Epoch 1/1\n",
            "22546/22546 [==============================] - 63s 3ms/step - loss: 3.6871\n",
            "STA i do not know END is END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END \n",
            "Training epoch: 8, training examples: 22500 - 25000\n",
            "Epoch 1/1\n",
            "23311/23311 [==============================] - 66s 3ms/step - loss: 3.6146\n",
            "STA i am not END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END \n",
            "Training epoch: 9, training examples: 0 - 2500\n",
            "Epoch 1/1\n",
            "30123/30123 [==============================] - 84s 3ms/step - loss: 3.9070\n",
            "STA i think it is a good END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END \n",
            "Training epoch: 9, training examples: 2500 - 5000\n",
            "Epoch 1/1\n",
            "20594/20594 [==============================] - 58s 3ms/step - loss: 3.5514\n",
            "STA i am not bothered END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END \n",
            "Training epoch: 9, training examples: 5000 - 7500\n",
            "Epoch 1/1\n",
            "20302/20302 [==============================] - 57s 3ms/step - loss: 3.4484\n",
            "STA yeah END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END \n",
            "Training epoch: 9, training examples: 7500 - 10000\n",
            "Epoch 1/1\n",
            "19285/19285 [==============================] - 54s 3ms/step - loss: 3.4766\n",
            "STA i have got a END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END \n",
            "Training epoch: 9, training examples: 10000 - 12500\n",
            "Epoch 1/1\n",
            "21589/21589 [==============================] - 58s 3ms/step - loss: 3.3998\n",
            "STA yeah END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END \n",
            "Training epoch: 9, training examples: 12500 - 15000\n",
            "Epoch 1/1\n",
            "19675/19675 [==============================] - 50s 3ms/step - loss: 3.3778\n",
            "STA i am not END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END \n",
            "Training epoch: 9, training examples: 15000 - 17500\n",
            "Epoch 1/1\n",
            "23039/23039 [==============================] - 60s 3ms/step - loss: 3.5812\n",
            "STA i am not END it END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END \n",
            "Training epoch: 9, training examples: 17500 - 20000\n",
            "Epoch 1/1\n",
            "18116/18116 [==============================] - 47s 3ms/step - loss: 3.2324\n",
            "STA i am going to the solicitor END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END \n",
            "Training epoch: 9, training examples: 20000 - 22500\n",
            "Epoch 1/1\n",
            "22546/22546 [==============================] - 60s 3ms/step - loss: 3.5844\n",
            "STA i do not know END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END \n",
            "Training epoch: 9, training examples: 22500 - 25000\n",
            "Epoch 1/1\n",
            "23311/23311 [==============================] - 63s 3ms/step - loss: 3.5179\n",
            "STA i am not END it END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END \n",
            "Training epoch: 10, training examples: 0 - 2500\n",
            "Epoch 1/1\n",
            "30123/30123 [==============================] - 82s 3ms/step - loss: 3.7781\n",
            "STA i think it is not it END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END \n",
            "Training epoch: 10, training examples: 2500 - 5000\n",
            "Epoch 1/1\n",
            "20594/20594 [==============================] - 58s 3ms/step - loss: 3.4427\n",
            "STA i am not bothered it is END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END \n",
            "Training epoch: 10, training examples: 5000 - 7500\n",
            "Epoch 1/1\n",
            "20302/20302 [==============================] - 56s 3ms/step - loss: 3.3572\n",
            "STA yeah END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END \n",
            "Training epoch: 10, training examples: 7500 - 10000\n",
            "Epoch 1/1\n",
            "19285/19285 [==============================] - 54s 3ms/step - loss: 3.3813\n",
            "STA yeah END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END \n",
            "Training epoch: 10, training examples: 10000 - 12500\n",
            "Epoch 1/1\n",
            "21589/21589 [==============================] - 59s 3ms/step - loss: 3.2987\n",
            "STA yeah END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END \n",
            "Training epoch: 10, training examples: 12500 - 15000\n",
            "Epoch 1/1\n",
            "19675/19675 [==============================] - 53s 3ms/step - loss: 3.2820\n",
            "STA i am not END it END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END \n",
            "Training epoch: 10, training examples: 15000 - 17500\n",
            "Epoch 1/1\n",
            "23039/23039 [==============================] - 64s 3ms/step - loss: 3.4773\n",
            "STA i will not END END END END END END END END END END END END END END END END END letters END END END letters END END END letters END END END END letters END END END END letters END END END END letters END END END END letters \n",
            "Training epoch: 10, training examples: 17500 - 20000\n",
            "Epoch 1/1\n",
            "18116/18116 [==============================] - 51s 3ms/step - loss: 3.1398\n",
            "STA i am not END it END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END \n",
            "Training epoch: 10, training examples: 20000 - 22500\n",
            "Epoch 1/1\n",
            "22546/22546 [==============================] - 64s 3ms/step - loss: 3.4800\n",
            "STA i have not seen it END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END \n",
            "Training epoch: 10, training examples: 22500 - 25000\n",
            "Epoch 1/1\n",
            "23311/23311 [==============================] - 66s 3ms/step - loss: 3.4173\n",
            "STA i am not END it END END END END END END END END END END END END END \n",
            "Training epoch: 11, training examples: 0 - 2500\n",
            "Epoch 1/1\n",
            "30123/30123 [==============================] - 86s 3ms/step - loss: 3.6360\n",
            "STA i think it is a good preacher END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END \n",
            "Training epoch: 11, training examples: 2500 - 5000\n",
            "Epoch 1/1\n",
            "20594/20594 [==============================] - 57s 3ms/step - loss: 3.3348\n",
            "STA i do not know END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END \n",
            "Training epoch: 11, training examples: 5000 - 7500\n",
            "Epoch 1/1\n",
            "20302/20302 [==============================] - 57s 3ms/step - loss: 3.2673\n",
            "STA yeah END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END \n",
            "Training epoch: 11, training examples: 7500 - 10000\n",
            "Epoch 1/1\n",
            "19285/19285 [==============================] - 51s 3ms/step - loss: 3.2856\n",
            "STA yeah END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END \n",
            "Training epoch: 11, training examples: 10000 - 12500\n",
            "Epoch 1/1\n",
            "21589/21589 [==============================] - 57s 3ms/step - loss: 3.2064\n",
            "STA yeah END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END \n",
            "Training epoch: 11, training examples: 12500 - 15000\n",
            "Epoch 1/1\n",
            "19675/19675 [==============================] - 52s 3ms/step - loss: 3.1855\n",
            "STA i am not END it END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END \n",
            "Training epoch: 11, training examples: 15000 - 17500\n",
            "Epoch 1/1\n",
            "23039/23039 [==============================] - 62s 3ms/step - loss: 3.3758\n",
            "STA i am not kidding END END END END END END END END END END END END END END END END letters END END END letters END END END END letters END END END END letters END END END END letters END END END END letters END END END END \n",
            "Training epoch: 11, training examples: 17500 - 20000\n",
            "Epoch 1/1\n",
            "18116/18116 [==============================] - 49s 3ms/step - loss: 3.0469\n",
            "STA i am not END it END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END \n",
            "Training epoch: 11, training examples: 20000 - 22500\n",
            "Epoch 1/1\n",
            "22546/22546 [==============================] - 61s 3ms/step - loss: 3.3695\n",
            "STA i do not know END is END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END \n",
            "Training epoch: 11, training examples: 22500 - 25000\n",
            "Epoch 1/1\n",
            "23311/23311 [==============================] - 63s 3ms/step - loss: 3.3155\n",
            "STA i do not know END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END \n",
            "Training epoch: 12, training examples: 0 - 2500\n",
            "Epoch 1/1\n",
            "30123/30123 [==============================] - 84s 3ms/step - loss: 3.5058\n",
            "STA i am not complaining to to the END END END and and and and and and and and and and and and and and and and and and and \n",
            "Training epoch: 12, training examples: 2500 - 5000\n",
            "Epoch 1/1\n",
            "20594/20594 [==============================] - 57s 3ms/step - loss: 3.2350\n",
            "STA i know END is not it END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END \n",
            "Training epoch: 12, training examples: 5000 - 7500\n",
            "Epoch 1/1\n",
            "20302/20302 [==============================] - 57s 3ms/step - loss: 3.1793\n",
            "STA yeah END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END \n",
            "Training epoch: 12, training examples: 7500 - 10000\n",
            "Epoch 1/1\n",
            "19285/19285 [==============================] - 53s 3ms/step - loss: 3.1928\n",
            "STA yeah END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END \n",
            "Training epoch: 12, training examples: 10000 - 12500\n",
            "Epoch 1/1\n",
            "21589/21589 [==============================] - 59s 3ms/step - loss: 3.1122\n",
            "STA yeah END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END \n",
            "Training epoch: 12, training examples: 12500 - 15000\n",
            "Epoch 1/1\n",
            "19675/19675 [==============================] - 53s 3ms/step - loss: 3.1040\n",
            "STA i am not messing it END END END END END END END END END END END END END END END END END END END END END END END ace END joe END END END END END jack queen END END END END END END END END END jack queen \n",
            "Training epoch: 12, training examples: 15000 - 17500\n",
            "Epoch 1/1\n",
            "23039/23039 [==============================] - 61s 3ms/step - loss: 3.2813\n",
            "STA i am not kidding END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END \n",
            "Training epoch: 12, training examples: 17500 - 20000\n",
            "Epoch 1/1\n",
            "18116/18116 [==============================] - 49s 3ms/step - loss: 2.9658\n",
            "STA i am not spilling it END END END END END END END END END END END END END END END END END END chasing END END END END drums END END END END END END drums END END END END END END chasing END END END END drums END \n",
            "Training epoch: 12, training examples: 20000 - 22500\n",
            "Epoch 1/1\n",
            "22546/22546 [==============================] - 63s 3ms/step - loss: 3.2659\n",
            "STA i know END is a lot of END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END \n",
            "Training epoch: 12, training examples: 22500 - 25000\n",
            "Epoch 1/1\n",
            "23311/23311 [==============================] - 66s 3ms/step - loss: 3.2241\n",
            "STA i am not END it END END END END END END END END END END END END END \n",
            "Training epoch: 13, training examples: 0 - 2500\n",
            "Epoch 1/1\n",
            "30123/30123 [==============================] - 86s 3ms/step - loss: 3.3743\n",
            "STA i think it is a good preacher END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END \n",
            "Training epoch: 13, training examples: 2500 - 5000\n",
            "Epoch 1/1\n",
            "20594/20594 [==============================] - 58s 3ms/step - loss: 3.1415\n",
            "STA i am not kidding END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END \n",
            "Training epoch: 13, training examples: 5000 - 7500\n",
            "Epoch 1/1\n",
            "20302/20302 [==============================] - 57s 3ms/step - loss: 3.0921\n",
            "STA yeah END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END \n",
            "Training epoch: 13, training examples: 7500 - 10000\n",
            "Epoch 1/1\n",
            "19285/19285 [==============================] - 54s 3ms/step - loss: 3.0995\n",
            "STA yeah END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END \n",
            "Training epoch: 13, training examples: 10000 - 12500\n",
            "Epoch 1/1\n",
            "21589/21589 [==============================] - 61s 3ms/step - loss: 3.0266\n",
            "STA yeah END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END \n",
            "Training epoch: 13, training examples: 12500 - 15000\n",
            "Epoch 1/1\n",
            "19675/19675 [==============================] - 55s 3ms/step - loss: 3.0205\n",
            "STA i am not messing it END END END END END END END END END END END END END END END END END END ace END END END END END END END END END END END END END END END END END END END END END END END END END \n",
            "Training epoch: 13, training examples: 15000 - 17500\n",
            "Epoch 1/1\n",
            "23039/23039 [==============================] - 62s 3ms/step - loss: 3.1911\n",
            "STA i am not shuffling END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END \n",
            "Training epoch: 13, training examples: 17500 - 20000\n",
            "Epoch 1/1\n",
            "18116/18116 [==============================] - 48s 3ms/step - loss: 2.8895\n",
            "STA i am not spilling it END END END END END END END END END END END END END chasing END END END END drums END END END END END drums END END END END sand END END END END quickly END END END chasing END END END drums END \n",
            "Training epoch: 13, training examples: 20000 - 22500\n",
            "Epoch 1/1\n",
            "22546/22546 [==============================] - 60s 3ms/step - loss: 3.1667\n",
            "STA i do not know END i have not seen it END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END \n",
            "Training epoch: 13, training examples: 22500 - 25000\n",
            "Epoch 1/1\n",
            "23311/23311 [==============================] - 60s 3ms/step - loss: 3.1345\n",
            "STA i am not going to get the buggy END END END END END END ruth stories ruth stories ruth affection END covers END pink toast milk END END mouth END \n",
            "Training epoch: 14, training examples: 0 - 2500\n",
            "Epoch 1/1\n",
            "30123/30123 [==============================] - 79s 3ms/step - loss: 3.2541\n",
            "STA i think it is not it END is not it END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END \n",
            "Training epoch: 14, training examples: 2500 - 5000\n",
            "Epoch 1/1\n",
            "20594/20594 [==============================] - 57s 3ms/step - loss: 3.0501\n",
            "STA i am not kidding END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END \n",
            "Training epoch: 14, training examples: 5000 - 7500\n",
            "Epoch 1/1\n",
            "20302/20302 [==============================] - 56s 3ms/step - loss: 3.0103\n",
            "STA yeah END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END \n",
            "Training epoch: 14, training examples: 7500 - 10000\n",
            "Epoch 1/1\n",
            "19285/19285 [==============================] - 53s 3ms/step - loss: 3.0284\n",
            "STA yeah END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END \n",
            "Training epoch: 14, training examples: 10000 - 12500\n",
            "Epoch 1/1\n",
            "21589/21589 [==============================] - 61s 3ms/step - loss: 2.9535\n",
            "STA yeah END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END \n",
            "Training epoch: 14, training examples: 12500 - 15000\n",
            "Epoch 1/1\n",
            "19675/19675 [==============================] - 53s 3ms/step - loss: 2.9561\n",
            "STA i am not messing END END END END END END END END ace END joe END END END END ace END joe END END END helen END joe END helen END helen END jack ace flush jack flush ace END ace END leg END jack ace flush END ace \n",
            "Training epoch: 14, training examples: 15000 - 17500\n",
            "Epoch 1/1\n",
            "23039/23039 [==============================] - 64s 3ms/step - loss: 3.1097\n",
            "STA yeah END END END END END END END END END END drums END END END END END drums END END END END drums END END END END drums END END END END drums END END END END drums END END END END drums END END END END drums END \n",
            "Training epoch: 14, training examples: 17500 - 20000\n",
            "Epoch 1/1\n",
            "18116/18116 [==============================] - 51s 3ms/step - loss: 2.8170\n",
            "STA i am going to the bog END END END END END END END drums END END END END drums END END END END drums END END END sand END END END END quickly END END chasing END END END drums END END END drums END END END END drums \n",
            "Training epoch: 14, training examples: 20000 - 22500\n",
            "Epoch 1/1\n",
            "22546/22546 [==============================] - 62s 3ms/step - loss: 3.0785\n",
            "STA i do not know END is END END END END END END END END END END END END END END END drops END END drops END END drops END urgh END urgh END END urgh END END urgh END END joe END drops END END drops END urgh END \n",
            "Training epoch: 14, training examples: 22500 - 25000\n",
            "Epoch 1/1\n",
            "23311/23311 [==============================] - 65s 3ms/step - loss: 3.0476\n",
            "STA i am not END it END END END END END END END \n",
            "Training epoch: 15, training examples: 0 - 2500\n",
            "Epoch 1/1\n",
            "30123/30123 [==============================] - 83s 3ms/step - loss: 3.1414\n",
            "STA i think it is a good job END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END \n",
            "Training epoch: 15, training examples: 2500 - 5000\n",
            "Epoch 1/1\n",
            "20594/20594 [==============================] - 56s 3ms/step - loss: 2.9708\n",
            "STA i do not think she is got a END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END \n",
            "Training epoch: 15, training examples: 5000 - 7500\n",
            "Epoch 1/1\n",
            "20302/20302 [==============================] - 54s 3ms/step - loss: 2.9387\n",
            "STA yeah END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END \n",
            "Training epoch: 15, training examples: 7500 - 10000\n",
            "Epoch 1/1\n",
            "19285/19285 [==============================] - 52s 3ms/step - loss: 2.9545\n",
            "STA i have got my weather END END END END END END END END END END END END END END scott followed annabel END END \n",
            "Training epoch: 15, training examples: 10000 - 12500\n",
            "Epoch 1/1\n",
            "21589/21589 [==============================] - 58s 3ms/step - loss: 2.8817\n",
            "STA yeah END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END \n",
            "Training epoch: 15, training examples: 12500 - 15000\n",
            "Epoch 1/1\n",
            "19675/19675 [==============================] - 55s 3ms/step - loss: 2.8881\n",
            "STA i am not messing it END END END END END END END END END END ace END leg END ace END joe END END END END ace leg END joe END END END joe END END END ace leg END joe END END END joe END helen END jack \n",
            "Training epoch: 15, training examples: 15000 - 17500\n",
            "Epoch 1/1\n",
            "23039/23039 [==============================] - 65s 3ms/step - loss: 3.0413\n",
            "STA i am not shuffling END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END \n",
            "Training epoch: 15, training examples: 17500 - 20000\n",
            "Epoch 1/1\n",
            "18116/18116 [==============================] - 51s 3ms/step - loss: 2.7628\n",
            "STA i am not END it END END END END END END END END drums END END END END drums END END END sand END END END END upyou duck END END END END END drums END END END sand END END END upyou END van END END quickly END \n",
            "Training epoch: 15, training examples: 20000 - 22500\n",
            "Epoch 1/1\n",
            "22546/22546 [==============================] - 63s 3ms/step - loss: 3.0002\n",
            "STA i have not seen it END END END END END END END END END END END END END glass END END END drops END END drops END urgh END urgh END urgh END urgh END END urgh END END urgh END urgh END END urgh END END urgh END \n",
            "Training epoch: 15, training examples: 22500 - 25000\n",
            "Epoch 1/1\n",
            "23311/23311 [==============================] - 66s 3ms/step - loss: 2.9725\n",
            "STA i am not END it END END END END END wiped END END END END END byebye END wiped END END END END byebye END wiped END END END END byebye END therethen END END END byebye END therethen END END END byebye END therethen END END END \n",
            "Training epoch: 16, training examples: 0 - 2500\n",
            "Epoch 1/1\n",
            "30123/30123 [==============================] - 85s 3ms/step - loss: 3.0469\n",
            "STA i do not know END rare opportunity END END END END END END END spiritual amenhallelujah amenhallelujah amenhallelujah amen END amenhallelujah amen END \n",
            "Training epoch: 16, training examples: 2500 - 5000\n",
            "Epoch 1/1\n",
            "20594/20594 [==============================] - 59s 3ms/step - loss: 2.8977\n",
            "STA yeah END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END \n",
            "Training epoch: 16, training examples: 5000 - 7500\n",
            "Epoch 1/1\n",
            "20302/20302 [==============================] - 58s 3ms/step - loss: 2.8659\n",
            "STA yeah END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END \n",
            "Training epoch: 16, training examples: 7500 - 10000\n",
            "Epoch 1/1\n",
            "19285/19285 [==============================] - 55s 3ms/step - loss: 2.8793\n",
            "STA i have got my weather END END END END END END END END END END END scott followed to phone END END END END END END scott followed equals minus b square root \n",
            "Training epoch: 16, training examples: 10000 - 12500\n",
            "Epoch 1/1\n",
            "21589/21589 [==============================] - 58s 3ms/step - loss: 2.8094\n",
            "STA yeah END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END \n",
            "Training epoch: 16, training examples: 12500 - 15000\n",
            "Epoch 1/1\n",
            "19675/19675 [==============================] - 53s 3ms/step - loss: 2.8376\n",
            "STA i am not messing END END END END END END END END joe END END END END ace END joe END END END joe END END END joe END END END joe END END END joe END END END joe END END helen END joe jack END ace flush \n",
            "Training epoch: 16, training examples: 15000 - 17500\n",
            "Epoch 1/1\n",
            "23039/23039 [==============================] - 62s 3ms/step - loss: 2.9741\n",
            "STA i am not shuffling themi END END END END END END END END drums END END END m e t e t e t e t e e nobody r e nobody and END END ryvita END mince pies END END END m e t e t e t \n",
            "Training epoch: 16, training examples: 17500 - 20000\n",
            "Epoch 1/1\n",
            "18116/18116 [==============================] - 48s 3ms/step - loss: 2.7093\n",
            "STA i am not END END END END END END drums END END END drums END END END drums END END END drums END END END drums END END END drums END END END drums END END END drums END END END drums END END END drums END END END \n",
            "Training epoch: 16, training examples: 20000 - 22500\n",
            "Epoch 1/1\n",
            "22546/22546 [==============================] - 61s 3ms/step - loss: 2.9325\n",
            "STA i know END is the colonel END END END END END END END drops END END drops END discs drops END urgh END urgh END urgh END urgh END END urgh END END urgh END urgh END END son END END erthe drops END husband END drops END drops \n",
            "Training epoch: 16, training examples: 22500 - 25000\n",
            "Epoch 1/1\n",
            "23311/23311 [==============================] - 62s 3ms/step - loss: 2.9033\n",
            "STA i am going to pu END am going to get the END stories END END END END \n",
            "Training epoch: 17, training examples: 0 - 2500\n",
            "Epoch 1/1\n",
            "30123/30123 [==============================] - 83s 3ms/step - loss: 2.9546\n",
            "STA i think it is a good way END is not it END END END END END END END END END END END jo END END jo END END jo END END jo END END moderator END END END END END jo END END moderator END END END END END \n",
            "Training epoch: 17, training examples: 2500 - 5000\n",
            "Epoch 1/1\n",
            "20594/20594 [==============================] - 57s 3ms/step - loss: 2.8355\n",
            "STA i am not kidding END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END \n",
            "Training epoch: 17, training examples: 5000 - 7500\n",
            "Epoch 1/1\n",
            "20302/20302 [==============================] - 55s 3ms/step - loss: 2.8033\n",
            "STA yeah END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END \n",
            "Training epoch: 17, training examples: 7500 - 10000\n",
            "Epoch 1/1\n",
            "19285/19285 [==============================] - 51s 3ms/step - loss: 2.8101\n",
            "STA i have got my weather END END END END END scott followed to phone END END END END END END END scott \n",
            "Training epoch: 17, training examples: 10000 - 12500\n",
            "Epoch 1/1\n",
            "21589/21589 [==============================] - 59s 3ms/step - loss: 2.7491\n",
            "STA yeah END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END \n",
            "Training epoch: 17, training examples: 12500 - 15000\n",
            "Epoch 1/1\n",
            "19675/19675 [==============================] - 55s 3ms/step - loss: 2.7733\n",
            "STA i am not messing END END END END END END END ace END flush END END flush END flush END ace END flush END flush END flush END ace END flush END flush END flush END ace END flush END flush END flush END ace END flush END flush \n",
            "Training epoch: 17, training examples: 15000 - 17500\n",
            "Epoch 1/1\n",
            "23039/23039 [==============================] - 64s 3ms/step - loss: 2.9147\n",
            "STA i am not kidding END END END END END END END END m e t e t e t e e e nobody r e nobody and END END ryvita END END c blank r END END END m e t e t e t e r e e \n",
            "Training epoch: 17, training examples: 17500 - 20000\n",
            "Epoch 1/1\n",
            "18116/18116 [==============================] - 51s 3ms/step - loss: 2.6563\n",
            "STA i am not END END END END END END END drums END END END END drums END END END drums END END END drums END END END drums END END END drums END END END drums END END END drums END END END drums END END END drums END \n",
            "Training epoch: 17, training examples: 20000 - 22500\n",
            "Epoch 1/1\n",
            "22546/22546 [==============================] - 64s 3ms/step - loss: 2.8630\n",
            "STA i have got a lot of END END END END END END END END drops END END husband END drops END husband nurses automatically nurses END paul END running \n",
            "Training epoch: 17, training examples: 22500 - 25000\n",
            "Epoch 1/1\n",
            "23311/23311 [==============================] - 66s 3ms/step - loss: 2.8367\n",
            "STA i do not know END END END END END wiped END END END wiped END END END becky boo END END \n",
            "Training epoch: 18, training examples: 0 - 2500\n",
            "Epoch 1/1\n",
            "30123/30123 [==============================] - 83s 3ms/step - loss: 2.8719\n",
            "STA i think it is a good way END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END \n",
            "Training epoch: 18, training examples: 2500 - 5000\n",
            "Epoch 1/1\n",
            "20594/20594 [==============================] - 55s 3ms/step - loss: 2.7781\n",
            "STA i am not kidding END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END \n",
            "Training epoch: 18, training examples: 5000 - 7500\n",
            "Epoch 1/1\n",
            "20302/20302 [==============================] - 55s 3ms/step - loss: 2.7509\n",
            "STA yeah END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END \n",
            "Training epoch: 18, training examples: 7500 - 10000\n",
            "Epoch 1/1\n",
            "19285/19285 [==============================] - 52s 3ms/step - loss: 2.7602\n",
            "STA i have got my weather END END END END scott followed to phone END END END END END END scott square root b square \n",
            "Training epoch: 18, training examples: 10000 - 12500\n",
            "Epoch 1/1\n",
            "21589/21589 [==============================] - 60s 3ms/step - loss: 2.6923\n",
            "STA yeah END END END END END END END END END END END END END END END END END END END END END END END END END END END END END street ahead END END END inches END END END air END END END END avenue END END avenue END \n",
            "Training epoch: 18, training examples: 12500 - 15000\n",
            "Epoch 1/1\n",
            "19675/19675 [==============================] - 55s 3ms/step - loss: 2.7243\n",
            "STA i am not hati END END END END END END ace END leg END ace END joe END END END ace END joe END boy END END king flush END END ace END leg END ace END joe END boy END END king flush END flush END ace END \n",
            "Training epoch: 18, training examples: 15000 - 17500\n",
            "Epoch 1/1\n",
            "23039/23039 [==============================] - 64s 3ms/step - loss: 2.8548\n",
            "STA i am not END themi END END END END END blank r END blank r END blank r END blank r END blank r END blank r END blank r END blank r END blank r END blank r END blank r END blank r END blank r END \n",
            "Training epoch: 18, training examples: 17500 - 20000\n",
            "Epoch 1/1\n",
            "18116/18116 [==============================] - 51s 3ms/step - loss: 2.6055\n",
            "STA i am going to vera END END END END END END drums END END END drums END END END drums END END END drums END END END drums END END END drums END END END drums END END END drums END END END drums END END END drums END \n",
            "Training epoch: 18, training examples: 20000 - 22500\n",
            "Epoch 1/1\n",
            "22546/22546 [==============================] - 64s 3ms/step - loss: 2.8012\n",
            "STA i know END is the colonel END END END END END END husband END drops END husband END drops END husband tiles END education END tiles END tiles END END \n",
            "Training epoch: 18, training examples: 22500 - 25000\n",
            "Epoch 1/1\n",
            "23311/23311 [==============================] - 65s 3ms/step - loss: 2.7738\n",
            "STA i am not going to pu END i am gonna have to go home END END END END is a treatment END nurses \n",
            "Training epoch: 19, training examples: 0 - 2500\n",
            "Epoch 1/1\n",
            "30123/30123 [==============================] - 85s 3ms/step - loss: 2.7917\n",
            "STA i think it is a good way END is not it END END END END END END END END END presentations spiritual spiritual amenhallelujah amenhallelujah amenhallelujah \n",
            "Training epoch: 19, training examples: 2500 - 5000\n",
            "Epoch 1/1\n",
            "20594/20594 [==============================] - 58s 3ms/step - loss: 2.7222\n",
            "STA i am not surebut END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END \n",
            "Training epoch: 19, training examples: 5000 - 7500\n",
            "Epoch 1/1\n",
            "20302/20302 [==============================] - 57s 3ms/step - loss: 2.6944\n",
            "STA yeah END END easter END END END and vouchers and and fiveone and threefour and \n",
            "Training epoch: 19, training examples: 7500 - 10000\n",
            "Epoch 1/1\n",
            "19285/19285 [==============================] - 54s 3ms/step - loss: 2.6994\n",
            "STA i have got to doit END END END END END scott followed to phone mrs to be END b square to and and and and and and and and and and and and \n",
            "Training epoch: 19, training examples: 10000 - 12500\n",
            "Epoch 1/1\n",
            "21589/21589 [==============================] - 60s 3ms/step - loss: 2.6402\n",
            "STA yeah END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END \n",
            "Training epoch: 19, training examples: 12500 - 15000\n",
            "Epoch 1/1\n",
            "19675/19675 [==============================] - 52s 3ms/step - loss: 2.6778\n",
            "STA i am not hati END END END END END END ace END leg END street ahead END END ace END jack flush ace END leg END ace leg END jack flush ace END ace END leg END jack flush ace END ace END leg END street ahead END END \n",
            "Training epoch: 19, training examples: 15000 - 17500\n",
            "Epoch 1/1\n",
            "23039/23039 [==============================] - 60s 3ms/step - loss: 2.8030\n",
            "STA yeah END mince pies END END END END END m e t e t e t e t e e nobody r e nobody and END END END END END END END END END END END END drums END END END m e t e t e t e \n",
            "Training epoch: 19, training examples: 17500 - 20000\n",
            "Epoch 1/1\n",
            "18116/18116 [==============================] - 47s 3ms/step - loss: 2.5551\n",
            "STA i am driving a double decker END END END END END END drums END END END drums END END END drums END END END drums END END END drums END END END drums END END END drums END END END drums END END END drums END END END drums \n",
            "Training epoch: 19, training examples: 20000 - 22500\n",
            "Epoch 1/1\n",
            "22546/22546 [==============================] - 62s 3ms/step - loss: 2.7479\n",
            "STA i do not know END is END settled END END END END END and i will take them up and i said i will geti it up END i am going to get the nurse END END END drops END summer END drops END urgh END urgh END \n",
            "Training epoch: 19, training examples: 22500 - 25000\n",
            "Epoch 1/1\n",
            "23311/23311 [==============================] - 64s 3ms/step - loss: 2.7147\n",
            "STA i am not END it END END END END therethen END END ta ra dorothy END END ta ruth ruth ruth ruth hill ruth hill END ruth hill END coat nowi age \n",
            "Training epoch: 20, training examples: 0 - 2500\n",
            "Epoch 1/1\n",
            " 6656/30123 [=====>........................] - ETA: 1:03 - loss: 2.8186"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-f37f390b9631>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mcount\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Training epoch: %d, training examples: %d - %d'\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mQ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBatchSize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m     \u001b[0mtest_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprint_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "ixfIVGjk_y1D",
        "colab_type": "code",
        "outputId": "2c5207e4-a38f-4fe1-cc70-8f8a8e5d95f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3637
        }
      },
      "cell_type": "code",
      "source": [
        "y_pred = list()\n",
        "y_test = list()\n",
        "y_pred_labels = list()\n",
        "y_test_labels = list()\n",
        "for i in range(100,200):\n",
        "  print('input: %s'%context[i].replace('STA','').replace('END',''))\n",
        "  in_vs = analyzer.polarity_scores(context[i])\n",
        "  y_test.append(in_vs['neg'])\n",
        "  y_test_labels.append(max(in_vs, key=in_vs.get))\n",
        "  \n",
        "  output = print_result(q[i:i+1])\n",
        "  output = output.replace('STA','')\n",
        "  output = re.split('END',output)[0]\n",
        "  out_vs = analyzer.polarity_scores(output)\n",
        "  y_pred.append(out_vs['neg'])\n",
        "  y_pred_labels.append(max(in_vs, key=out_vs.get))\n",
        "  print('output: %s'%output)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "input:  fivepound coin underneathtenlovely \n",
            "output:  i do not know \n",
            "input:  thank you very much \n",
            "output:  i do not know \n",
            "input:  i will do that \n",
            "output:  i do not know \n",
            "input:  weller only in the eveningbut we have got a \n",
            "output:  i do not know \n",
            "input:  rightgood bye \n",
            "output:  i do not know \n",
            "input:  no \n",
            "output:  i do not know \n",
            "input:  was born in brockly  \n",
            "output:  i do not know \n",
            "input:  i was not born \n",
            "output:  i do not know \n",
            "input:  that is alright \n",
            "output:  i do not know \n",
            "input:  i see \n",
            "output:  i do not know \n",
            "input:  mm \n",
            "output:  i do not know \n",
            "input:  i have been trying to learn itbut i have not got very far \n",
            "output:  i do not know \n",
            "input:  i am almost sorry that \n",
            "output:  i do not know \n",
            "input:  yeah me nephew he lives up by erm clan derris  \n",
            "output:  i do not know \n",
            "input:  mm \n",
            "output:  i do not know \n",
            "input:  i seeyes \n",
            "output:  i do not know \n",
            "input:  and they are living there and they do not speak welsh \n",
            "output:  i do not know \n",
            "input:  you know theywhen they first went up there to livethey erhad quite a problemand the trouble waswasthe two boys they were born in australia you see and they came hereand one was four and the other \n",
            "output:  i think i have got a i think i have got a i think i have got a i think i have got a i think i have got a i think i have got a i think i have got a \n",
            "input:  of course they had a problem had not they \n",
            "output:  i think it is a great divide \n",
            "input:  so it was quiteand er  then theytheywell they were not learning very well at all  \n",
            "output:  i think it is a great difficulty in the united reform of faith in the world council churches \n",
            "input:  they always seemed backwardthey found that they took them to different specialist and the truth isthey have both left school now and got jobsbut they were erdyslexia \n",
            "output:  i do not know \n",
            "input:  they found out both of them \n",
            "output:  i do not know \n",
            "input:  but they got jobsquite good jobsand the fella who it is employing themhe is one himselfso he employs that sort of people you see \n",
            "output:  i do not know \n",
            "input:  but they get on now \n",
            "output:  i do not know \n",
            "input:  but theythey passed the driving test first time and you know erthey could not find out what it \n",
            "output:  i do not know \n",
            "input:  pardon \n",
            "output:  i do not know \n",
            "input:  yesyeah \n",
            "output:  i do not know \n",
            "input:  yeahthat is veryyou know it willit quite embarrassed in school and that and erm for them \n",
            "output:  i think it is a great difficulty in the united kingdom unfortunately \n",
            "input:  but eras i say they have grown now and got these jobs and they are quite happy \n",
            "output:  i do not know \n",
            "input:  but surprising the people that you do not realiseyou knowit troubles the parents and as i say they took them to a number of specialists and given different things \n",
            "output:  i do not know \n",
            "input:  could not find out \n",
            "output:  i do not know \n",
            "input:  why and then of course this all came out  \n",
            "output:  i do not know \n",
            "input:  alrightgoodbye then \n",
            "output:  i do not know \n",
            "input:  oh it is not very valuable is it \n",
            "output:  i do not think you are not the of the of the ministry of the church \n",
            "input:  thank yougoodbye \n",
            "output:  i do not know \n",
            "input:  it is all supposed to be anonymous anyway \n",
            "output:  i do not know \n",
            "input:  yesoh yesyes \n",
            "output:  i do not know \n",
            "input:  it does notit does not really matterright \n",
            "output:  i do not know \n",
            "input:  yeah  that is a nice erslotwere you looking to go out in the garden \n",
            "output:  i do not know \n",
            "input:  erhelp yourself  \n",
            "output:  i do not know \n",
            "input:  oh  rightthat will do me i thinkthank you \n",
            "output:  i do not know \n",
            "input:  getting into those things is er  a major task  innit \n",
            "output:  i do not know \n",
            "input:  these plastic bags and various \n",
            "output:  i do not know \n",
            "input:  yeserwe put that on as awe bought it as a do it yourself job \n",
            "output:  i do not know \n",
            "input:  how long agoi mean how long has it been there \n",
            "output:  i do not know \n",
            "input:  ahhave to get a pair of scissors  \n",
            "output:  i do not know \n",
            "input:  well largely because we could not afford a house in the area where we both grew up \n",
            "output:  i do not know \n",
            "input:  the south east london \n",
            "output:  i do not know \n",
            "input:  at least i was born in kent but er brought up in south east london \n",
            "output:  i do not know \n",
            "input:  ermborn in welling and er and thenthen we moved to lewisham \n",
            "output:  i do not know \n",
            "input:  ermthat was immediately after the waryou knowthe first war \n",
            "output:  i think it is a good way \n",
            "input:  wellin a wayalthough her parents were scotch \n",
            "output:  i do not know \n",
            "input:  her mother is family from st andrews and her father from dundee \n",
            "output:  i do not know \n",
            "input:  ermoh he came to london to get work \n",
            "output:  i do not know \n",
            "input:  yeah  \n",
            "output:  i do not know \n",
            "input:  well oneone of my sons is married to ergir girl whose family live in buckley \n",
            "output:  i do not know \n",
            "input:  and er  originally whenwhen we first sought to retiringretiringwe were attracted to the dalesbut we could not afford that \n",
            "output:  i do not know \n",
            "input:  mm \n",
            "output:  i do not know \n",
            "input:  they had but it was ermmuch less satisfactory as a u r c one \n",
            "output:  i do not know \n",
            "input:  but they have changed nowthey are more or less on the same basis as the u r c \n",
            "output:  i do not know \n",
            "input:  but erm  it did not look a very attractive proposition at the time \n",
            "output:  i think it is a great divide \n",
            "input:  for one thingif we had taken one of their houses and i had died firstmy wife would of been left without a home \n",
            "output:  i think i will have a look at the light of the third world of the culture of death \n",
            "input:  except for going to the eryou knowthey have got that place in worthing erm  \n",
            "output:  i do not know \n",
            "input:  erm \n",
            "output:  i do not know \n",
            "input:  levers house \n",
            "output:  i do not know \n",
            "input:  but we wereneither of us very keen on that \n",
            "output:  i do not know \n",
            "input:  ermi am not really surewe did not go into it very deeply \n",
            "output:  i do not know \n",
            "input:  fortunately ruth had some money from her father which covered buying this house \n",
            "output:  i do not know \n",
            "input:  erm  at that time property was fairly cheap in bradley \n",
            "output:  i do not know \n",
            "input:  we got this for seven and a half thousand \n",
            "output:  i do not know \n",
            "input:  i think it cost more than that now \n",
            "output:  i do not know \n",
            "input:  mind you it is only a paper profit because you can not rely on it \n",
            "output:  i do not know \n",
            "input:  londoneast londoneast ham  actually i was brought up till i was about seven  er in the same areabut erm  in a place called beckton \n",
            "output:  i do not know \n",
            "input:  that is rightyeahjust overnot far over the water from er the woolwich  \n",
            "output:  i do not know \n",
            "input:  mmmm  and i often tell people that erthose who do not come from london do not realise  the difference between north and south \n",
            "output:  i do not know \n",
            "input:  south london they are two different worlds are not they \n",
            "output:  i do not know \n",
            "input:  yes \n",
            "output:  i do not know \n",
            "input:  oh yeah  yesit is amazing how a big delight it isdespite all the bridges \n",
            "output:  i do not know \n",
            "input:  wellas near as possible becauseermi mean i was appointed toto africa while i was still in college \n",
            "output:  i do not know \n",
            "input:  but then there was delay because of war conditions \n",
            "output:  i think it is a good way \n",
            "input:  so  so it was nearly a year before we actually got away \n",
            "output:  i do not know \n",
            "input:  in the  i took aa \n",
            "output:  i do not know \n",
            "input:  oh yeah \n",
            "output:  i do not know \n",
            "input:  mm \n",
            "output:  i do not know \n",
            "input:  oh did you \n",
            "output:  i do not know \n",
            "input:  the war was over by then \n",
            "output:  i do not think i will try \n",
            "input:  oh \n",
            "output:  i do not know \n",
            "input:  oh \n",
            "output:  i do not know \n",
            "input:  mm  what vessel did you go on then \n",
            "output:  i do not know \n",
            "input:  oh \n",
            "output:  i do not know \n",
            "input:  oh really \n",
            "output:  i do not know \n",
            "input:  mmwe rted out in convoy in liverpool \n",
            "output:  i do not know \n",
            "input:  and we were in con convoy for about a weekthen we suddenly found ourselves alone \n",
            "output:  i think it is a great pleasure to knowto the of the of the advocate of the of the of the of the of the of the of the of the of the of \n",
            "input:  and we had a whole month at sea without seeing land \n",
            "output:  i do not know \n",
            "input:  very \n",
            "output:  i do not know \n",
            "input:  mmyes  \n",
            "output:  i do not know \n",
            "input:  goodness only knowsi think  \n",
            "output:  i do not know \n",
            "input:  i think we went pretty well across the atlantic erm  \n",
            "output:  i do not know \n",
            "input:  right  quite a long way west \n",
            "output:  i do not know \n",
            "input:  we did not have any trouble from u-boatsbut we picked up some boats \n",
            "output:  i do not know \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "dRHcwKCdJlGx",
        "colab_type": "code",
        "outputId": "b26f1239-3d5f-4aef-be94-85e3d13dc3f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        }
      },
      "cell_type": "code",
      "source": [
        "for l in range(len(y_test_labels)):\n",
        "  if y_test_labels[l] != 'neg':\n",
        "     y_test_labels[l]= 'not_neg'\n",
        "print(y_test_labels)\n",
        "for l in range(len(y_pred_labels)):\n",
        "  if y_pred_labels[l] != 'neg':\n",
        "     y_pred_labels[l]= 'not_neg'\n",
        "print(y_pred_labels)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['not_neg', 'not_neg', 'not_neg', 'not_neg', 'not_neg', 'neg', 'not_neg', 'not_neg', 'not_neg', 'not_neg', 'not_neg', 'not_neg', 'not_neg', 'not_neg', 'not_neg', 'not_neg', 'not_neg', 'not_neg', 'not_neg', 'not_neg', 'not_neg', 'not_neg', 'not_neg', 'not_neg', 'not_neg', 'not_neg', 'not_neg', 'not_neg', 'not_neg', 'not_neg', 'not_neg', 'not_neg', 'not_neg', 'not_neg', 'not_neg', 'not_neg', 'not_neg', 'not_neg', 'not_neg', 'not_neg', 'not_neg', 'not_neg', 'not_neg', 'not_neg', 'not_neg', 'not_neg', 'not_neg', 'not_neg', 'not_neg', 'not_neg', 'not_neg', 'not_neg', 'not_neg', 'not_neg', 'not_neg', 'not_neg', 'not_neg', 'not_neg', 'not_neg', 'not_neg', 'not_neg', 'not_neg', 'not_neg', 'not_neg', 'not_neg', 'not_neg', 'not_neg', 'not_neg', 'not_neg', 'not_neg', 'not_neg', 'not_neg', 'not_neg', 'not_neg', 'not_neg', 'not_neg', 'not_neg', 'not_neg', 'not_neg', 'not_neg', 'not_neg', 'not_neg', 'not_neg', 'not_neg', 'not_neg', 'not_neg', 'not_neg', 'not_neg', 'not_neg', 'not_neg', 'not_neg', 'not_neg', 'not_neg', 'not_neg', 'not_neg', 'not_neg', 'not_neg', 'not_neg', 'not_neg', 'not_neg']\n",
            "['not_neg', 'not_neg', 'not_neg', 'not_neg', 'not_neg', 'not_neg', 'not_neg', 'not_neg', 'not_neg', 'not_neg', 'not_neg', 'not_neg', 'not_neg', 'not_neg', 'not_neg', 'not_neg', 'not_neg', 'not_neg', 'not_neg', 'not_neg', 'not_neg', 'not_neg', 'not_neg', 'not_neg', 'not_neg', 'not_neg', 'not_neg', 'not_neg', 'not_neg', 'not_neg', 'not_neg', 'not_neg', 'not_neg', 'not_neg', 'not_neg', 'not_neg', 'not_neg', 'not_neg', 'not_neg', 'not_neg', 'not_neg', 'not_neg', 'not_neg', 'not_neg', 'not_neg', 'not_neg', 'not_neg', 'not_neg', 'not_neg', 'not_neg', 'not_neg', 'not_neg', 'not_neg', 'not_neg', 'not_neg', 'not_neg', 'not_neg', 'not_neg', 'not_neg', 'not_neg', 'not_neg', 'not_neg', 'not_neg', 'not_neg', 'not_neg', 'not_neg', 'not_neg', 'not_neg', 'not_neg', 'not_neg', 'not_neg', 'not_neg', 'not_neg', 'not_neg', 'not_neg', 'not_neg', 'not_neg', 'not_neg', 'not_neg', 'not_neg', 'not_neg', 'not_neg', 'not_neg', 'not_neg', 'not_neg', 'not_neg', 'not_neg', 'not_neg', 'not_neg', 'not_neg', 'not_neg', 'not_neg', 'not_neg', 'not_neg', 'not_neg', 'not_neg', 'not_neg', 'not_neg', 'not_neg', 'not_neg']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "p7hfPcD7o_8A",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn import svm, datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.utils.multiclass import unique_labels\n",
        "\n",
        "def plot_confusion_matrix(y_true, y_pred, \n",
        "                          normalize=False,\n",
        "                          title=None,\n",
        "                          cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    if not title:\n",
        "        if normalize:\n",
        "            title = 'Normalized confusion matrix'\n",
        "        else:\n",
        "            title = 'Confusion matrix, without normalization'\n",
        "\n",
        "    # Compute confusion matrix\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    # Only use the labels that appear in the data\n",
        "    classes = unique_labels(y_true, y_pred)\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    print(cm)\n",
        "\n",
        "    fig, ax = plt.subplots()\n",
        "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    ax.figure.colorbar(im, ax=ax)\n",
        "    # We want to show all ticks...\n",
        "    ax.set(xticks=np.arange(cm.shape[1]),\n",
        "           yticks=np.arange(cm.shape[0]),\n",
        "           # ... and label them with the respective list entries\n",
        "           xticklabels=classes, yticklabels=classes,\n",
        "           title=title,\n",
        "           ylabel='True label',\n",
        "           xlabel='Predicted label')\n",
        "\n",
        "    # Rotate the tick labels and set their alignment.\n",
        "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
        "             rotation_mode=\"anchor\")\n",
        "\n",
        "    # Loop over data dimensions and create text annotations.\n",
        "    fmt = '.2f' if normalize else 'd'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i in range(cm.shape[0]):\n",
        "        for j in range(cm.shape[1]):\n",
        "            ax.text(j, i, format(cm[i, j], fmt),\n",
        "                    ha=\"center\", va=\"center\",\n",
        "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "    fig.tight_layout()\n",
        "    return ax"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cQWywjtEodyN",
        "colab_type": "code",
        "outputId": "73194086-1d3c-4806-8ba2-0596aacfb965",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        }
      },
      "cell_type": "code",
      "source": [
        "plot_confusion_matrix(y_test_labels, y_pred_labels, normalize=False,\n",
        "                      title='Normalized confusion matrix')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion matrix, without normalization\n",
            "[[ 0  1]\n",
            " [ 0 99]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAbEAAAGACAYAAAAj9ly5AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n8gAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 576x396 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "3BRG0CnU3R0S",
        "colab_type": "code",
        "outputId": "615a17e2-f6d5-4cc0-a867-7f17130ce8fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        }
      },
      "cell_type": "code",
      "source": [
        "print(y_pred)\n",
        "print(y_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.271, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.206, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "[0.0, 0.0, 0.0, 0.0, 0.0, 0.524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.168, 0.0, 0.0, 0.0, 0.0, 0.076, 0.231, 0.113, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.141, 0.0, 0.0, 0.0, 0.0, 0.0, 0.235, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.281, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.209, 0.141, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.48, 0.0, 0.0, 0.0, 0.0, 0.0, 0.358, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.118, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "hwirtqLWy67i",
        "colab_type": "code",
        "outputId": "f18cb6ab-1c32-4e10-ea47-e67244d7d292",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "from sklearn import metrics\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.metrics import mean_squared_error\n",
        "mean_squared_error(y_test, y_pred)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.00933586"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "metadata": {
        "id": "Gx7S33zsLR7o",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
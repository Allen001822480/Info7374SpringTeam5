{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Final_dcgan_1.0.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Allen001822480/Info7374SpringTeam5/blob/Final_Project/Final_dcgan_1_0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "_B94XN4rVCxE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pickle\n",
        "text = np.load('text.npy')\n",
        "image = np.load('image128.npy')\n",
        "with open('word_index.pickle','rb') as v:\n",
        "  word_index = pickle.load(v)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-6yqC7UTsheo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def scale_image(image):\n",
        "  image = (image/ 255) * 2 - 1\n",
        "  return image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IKugpMti-h1w",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "image = scale_image(image)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fMj0Ni-rSmP5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import requests\n",
        "file_url = \"http://nlp.stanford.edu/data/glove.6B.zip\"\n",
        "tr = requests.get(file_url, stream=True)\n",
        "with open(\"glove.6B.zip\", \"wb\") as f:\n",
        "    for chunk in tr.iter_content(chunk_size=1024):\n",
        "        if chunk:\n",
        "            f.write(chunk)\n",
        "            \n",
        "            \n",
        "import zipfile\n",
        "import os\n",
        "def un_zip(file_name):\n",
        "    \"\"\"unzip zip file\"\"\"\n",
        "    zip_file = zipfile.ZipFile(file_name)\n",
        "    if os.path.isdir(file_name + \"_files\"):\n",
        "        pass\n",
        "    else:\n",
        "        os.mkdir(file_name + \"_files\")\n",
        "    for names in zip_file.namelist():\n",
        "        zip_file.extract(names,file_name + \"_files/\")\n",
        "    zip_file.close()\n",
        "        \n",
        "glove = un_zip(\"glove.6B.zip\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Mvji4_lvStnv",
        "colab_type": "code",
        "outputId": "ce254619-35f8-4e3c-d502-5b43be19a544",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "embeddings_index = {}\n",
        "f = open('./glove.6B.zip_files/glove.6B.100d.txt')\n",
        "for line in f:\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    coefs = np.asarray(values[1:], dtype='float32')\n",
        "    embeddings_index[word] = coefs\n",
        "f.close()\n",
        "\n",
        "print('Found %s word vectors.' % len(embeddings_index))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 400000 word vectors.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Hs43WhoISxAR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "maxlen = 20\n",
        "max_words = 5000\n",
        "embedding_dim = 100\n",
        "noise_dim = 10\n",
        "embeddings_index = {}\n",
        "embedding_matrix = np.zeros((max_words, embedding_dim))\n",
        "for word, i in word_index.items():\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if i < max_words:\n",
        "        if embedding_vector is not None:\n",
        "            # Words not found in embedding index will be all-zeros.\n",
        "            embedding_matrix[i] = embedding_vector"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7eDXg80KXP-M",
        "colab_type": "code",
        "outputId": "c9fa0567-1e37-4cdd-8e95-98f45dbeb85d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 978
        }
      },
      "cell_type": "code",
      "source": [
        "from keras.layers import Input, Dense, Reshape, Flatten, Dropout, Embedding, LSTM, concatenate\n",
        "from keras.layers import BatchNormalization, Activation, ZeroPadding2D\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
        "from keras.models import Sequential, Model\n",
        "from keras.optimizers import Adam, SGD\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#generator\n",
        "noise_input = Input(shape=(noise_dim,))\n",
        "noise_layer = Dense(embedding_dim)(noise_input)\n",
        "sentence = Input(shape=(maxlen,))\n",
        "sentence_layer = Embedding(output_dim=embedding_dim, input_dim=max_words, weights=[embedding_matrix], input_length=maxlen)(sentence)\n",
        "sentence_layer = LSTM(embedding_dim)(sentence_layer)\n",
        "merged_layer = concatenate([noise_layer, sentence_layer])\n",
        "generator_layer = Dense(128 * 16 * 16, activation=\"relu\")(merged_layer)\n",
        "generator_layer = Reshape((16, 16, -1))(generator_layer)\n",
        "generator_layer = UpSampling2D()(generator_layer)\n",
        "generator_layer = Conv2D(128, kernel_size=3, padding=\"same\")(generator_layer)\n",
        "generator_layer = BatchNormalization(momentum=0.8)(generator_layer)\n",
        "generator_layer = Activation(\"relu\")(generator_layer)\n",
        "generator_layer = UpSampling2D()(generator_layer)\n",
        "generator_layer = Conv2D(64, kernel_size=3, padding=\"same\")(generator_layer)\n",
        "generator_layer = BatchNormalization(momentum=0.8)(generator_layer)\n",
        "generator_layer = Activation(\"relu\")(generator_layer)\n",
        "generator_layer = UpSampling2D()(generator_layer)\n",
        "generator_layer = Conv2D(32, kernel_size=3, padding=\"same\")(generator_layer)\n",
        "generator_layer = BatchNormalization(momentum=0.8)(generator_layer)\n",
        "generator_layer = Activation(\"relu\")(generator_layer)\n",
        "generator_layer = Conv2D(3, kernel_size=3, padding=\"same\")(generator_layer)\n",
        "generator_output = Activation(\"tanh\")(generator_layer)\n",
        "generator = Model([noise_input,sentence], generator_output)\n",
        "generator.summary() "
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            (None, 20)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_1 (InputLayer)            (None, 10)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, 20, 100)      500000      input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 100)          1100        input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   (None, 100)          80400       embedding_1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 200)          0           dense_1[0][0]                    \n",
            "                                                                 lstm_1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 32768)        6586368     concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "reshape_1 (Reshape)             (None, 16, 16, 128)  0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_1 (UpSampling2D)  (None, 32, 32, 128)  0           reshape_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 32, 32, 128)  147584      up_sampling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 32, 32, 128)  512         conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 32, 32, 128)  0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_2 (UpSampling2D)  (None, 64, 64, 128)  0           activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 64, 64, 64)   73792       up_sampling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 64, 64, 64)   256         conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 64, 64, 64)   0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_3 (UpSampling2D)  (None, 128, 128, 64) 0           activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 128, 128, 32) 18464       up_sampling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 128, 128, 32) 128         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 128, 128, 32) 0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 128, 128, 3)  867         activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 128, 128, 3)  0           conv2d_4[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 7,409,471\n",
            "Trainable params: 7,409,023\n",
            "Non-trainable params: 448\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "MfFDitkiVY-T",
        "colab_type": "code",
        "outputId": "5d31bd53-83d2-4f88-df99-6e0c485fa438",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 994
        }
      },
      "cell_type": "code",
      "source": [
        "image_input = Input(shape=(128,128,3))\n",
        "image_layer = Conv2D(16, kernel_size=3, strides=2, padding=\"same\")(image_input)\n",
        "image_layer = LeakyReLU(alpha=0.2)(image_input)\n",
        "image_layer = Dropout(0.25)(image_input)\n",
        "image_layer = Conv2D(32, kernel_size=3, strides=2, padding=\"same\")(image_input)\n",
        "image_layer = ZeroPadding2D(padding=((0,1),(0,1)))(image_layer)\n",
        "image_layer = BatchNormalization(momentum=0.8)(image_layer)\n",
        "image_layer = LeakyReLU(alpha=0.2)(image_layer)\n",
        "image_layer = Dropout(0.25)(image_layer)\n",
        "image_layer = Conv2D(64, kernel_size=3, strides=2, padding=\"same\")(image_layer)\n",
        "image_layer = BatchNormalization(momentum=0.8)(image_layer)\n",
        "image_layer = LeakyReLU(alpha=0.2)(image_layer)\n",
        "image_layer = Dropout(0.25)(image_layer)\n",
        "image_layer = Conv2D(128, kernel_size=3, strides=1, padding=\"same\")(image_layer)\n",
        "image_layer = BatchNormalization(momentum=0.8)(image_layer)\n",
        "image_layer = LeakyReLU(alpha=0.2)(image_layer)\n",
        "image_layer = Dropout(0.25)(image_layer)\n",
        "image_layer = Flatten()(image_layer)\n",
        "image_layer = Dense(100)(image_layer)\n",
        "text_input = Input(shape=(maxlen,))\n",
        "text_embedd = Embedding(output_dim=embedding_dim, input_dim=max_words, weights=[embedding_matrix], input_length=maxlen)(text_input)\n",
        "text_rnn = LSTM(embedding_dim)(text_embedd)\n",
        "merged = concatenate([image_layer,text_rnn])\n",
        "discriminator_layer = Activation('tanh')(merged)\n",
        "discriminator_layer = Dense(1)(discriminator_layer)\n",
        "validity = Activation('sigmoid')(discriminator_layer)\n",
        "discriminator = Model([image_input,text_input],validity)\n",
        "discriminator.summary()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_3 (InputLayer)            (None, 128, 128, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 64, 64, 32)   896         input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_1 (ZeroPadding2D (None, 65, 65, 32)   0           conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 65, 65, 32)   128         zero_padding2d_1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_2 (LeakyReLU)       (None, 65, 65, 32)   0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 65, 65, 32)   0           leaky_re_lu_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 33, 33, 64)   18496       dropout_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 33, 33, 64)   256         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_3 (LeakyReLU)       (None, 33, 33, 64)   0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_3 (Dropout)             (None, 33, 33, 64)   0           leaky_re_lu_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 33, 33, 128)  73856       dropout_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 33, 33, 128)  512         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_4 (LeakyReLU)       (None, 33, 33, 128)  0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_4 (Dropout)             (None, 33, 33, 128)  0           leaky_re_lu_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "input_4 (InputLayer)            (None, 20)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 139392)       0           dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "embedding_2 (Embedding)         (None, 20, 100)      500000      input_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 100)          13939300    flatten_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "lstm_2 (LSTM)                   (None, 100)          80400       embedding_2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 200)          0           dense_3[0][0]                    \n",
            "                                                                 lstm_2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 200)          0           concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense_4 (Dense)                 (None, 1)            201         activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 1)            0           dense_4[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 14,614,045\n",
            "Trainable params: 14,613,597\n",
            "Non-trainable params: 448\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "mkIFxCSWXsSb",
        "colab_type": "code",
        "outputId": "250422c8-6365-47f2-9fda-854dcecf87f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 941
        }
      },
      "cell_type": "code",
      "source": [
        "optimizer = Adam(lr=0.0005)\n",
        "generator.compile(loss='mean_squared_error', optimizer=optimizer)\n",
        "discriminator.compile(loss='binary_crossentropy',optimizer=optimizer)\n",
        "model_output = discriminator([generator.output,sentence])\n",
        "combined_model = Model([noise_input,sentence],model_output)\n",
        "discriminator.trainable = False\n",
        "combined_model.compile(loss='binary_crossentropy',optimizer=optimizer)\n",
        "combined_model.summary()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            (None, 20)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_1 (InputLayer)            (None, 10)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, 20, 100)      500000      input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 100)          1100        input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   (None, 100)          80400       embedding_1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 200)          0           dense_1[0][0]                    \n",
            "                                                                 lstm_1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 32768)        6586368     concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "reshape_1 (Reshape)             (None, 16, 16, 128)  0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_1 (UpSampling2D)  (None, 32, 32, 128)  0           reshape_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 32, 32, 128)  147584      up_sampling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 32, 32, 128)  512         conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 32, 32, 128)  0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_2 (UpSampling2D)  (None, 64, 64, 128)  0           activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 64, 64, 64)   73792       up_sampling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 64, 64, 64)   256         conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 64, 64, 64)   0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_3 (UpSampling2D)  (None, 128, 128, 64) 0           activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 128, 128, 32) 18464       up_sampling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 128, 128, 32) 128         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 128, 128, 32) 0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 128, 128, 3)  867         activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 128, 128, 3)  0           conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "model_2 (Model)                 (None, 1)            14614045    activation_4[0][0]               \n",
            "                                                                 input_2[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 22,023,516\n",
            "Trainable params: 7,409,023\n",
            "Non-trainable params: 14,614,493\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "zzMn0dFj-e3u",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "epoch = 5\n",
        "batch_size = 16\n",
        "snapshot_interval = 100\n",
        "snapshot_dir_path = './dcgan/snapshot/dcgan_01/'\n",
        "generator_model_path = './dcgan/dcgan_01_generator.h5'\n",
        "discriminator_model_path = './dcgan/dcgan_01_discriminator.h5'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Z2nPpbrMJVUO",
        "colab_type": "code",
        "outputId": "6e56d6e4-dd33-4f3c-ef26-e728f8d2d989",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "cell_type": "code",
      "source": [
        "print(text.shape)\n",
        "print(image.shape)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(81890, 20)\n",
            "(8189, 128, 128, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "l3Xqpeg8Mva1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os,math\n",
        "from PIL import Image\n",
        "\n",
        "if not os.path.isdir(snapshot_dir_path):\n",
        "  os.makedirs(snapshot_dir_path)\n",
        "  \n",
        "def combine_normalized_images(generated_images):\n",
        "  num = generated_images.shape[0]\n",
        "  width = int(math.sqrt(num))\n",
        "  height = int(math.ceil(float(num) / width))\n",
        "  shape = generated_images.shape[1:]\n",
        "  image = np.zeros((height * shape[0], width * shape[1], shape[2]),\n",
        "                     dtype=generated_images.dtype)\n",
        "  for index, img in enumerate(generated_images):\n",
        "    i = int(index / width)\n",
        "    j = index % width\n",
        "    image[i * shape[0]:(i + 1) * shape[0], j * shape[1]:(j + 1) * shape[1], :] = img\n",
        "  return image\n",
        "def img_from_normalized_img(normalized_img):\n",
        "  image = normalized_img * 127.5 + 127.5\n",
        "  return Image.fromarray(image.astype(np.uint8))\n",
        "def save_snapshots(generated_images, snapshot_dir_path, epoch, batch_index):\n",
        "  image = combine_normalized_images(generated_images)\n",
        "  img_from_normalized_img(image).save(os.path.join(snapshot_dir_path, str(epoch) + \"-\" + str(batch_index) + \".png\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "87-XhaS6SGn4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "if os.path.isfile(generator_model_path):\n",
        "    generator.load_weights(generator_model_path)\n",
        "if os.path.isfile(discriminator_model_path):\n",
        "    discriminator.load_weights(discriminator_model_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dNyDDmKoYjy1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "shutil.rmtree('./dcgan')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DaEsvGQ2Bpfv",
        "colab_type": "code",
        "outputId": "3556eefb-5876-48e4-feda-ff493a2d8d80",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 44850
        }
      },
      "cell_type": "code",
      "source": [
        "for i in range(epoch):\n",
        "  batch_count = int(image.shape[0]/batch_size)\n",
        "  for batch_index in range(batch_count):\n",
        "    text_batch_real = text[batch_index * batch_size*10:(batch_index + 1) * batch_size*10,:]\n",
        "    image_batch_real = image[batch_index * batch_size:(batch_index + 1) * batch_size,:,:,:]\n",
        "    image_batch_real = np.tile(image_batch_real,(10,1,1,1))\n",
        "    index1 = np.random.randint(low=0, high=text.shape[0], size=batch_size*10)\n",
        "    text_batch_wrong = text[index1,:]\n",
        "    index2 = np.random.randint(low=0, high=image.shape[0], size=batch_size)\n",
        "    image_batch_wrong = image[index2,:,:,:]\n",
        "    image_batch_wrong = np.tile(image_batch_wrong,(10,1,1,1))\n",
        "    noise = np.zeros((batch_size*10, noise_dim))\n",
        "    for index in range(batch_size*10):\n",
        "      noise[index, :] = np.random.uniform(-1, 1, noise_dim)\n",
        "    generated_images = generator.predict([noise,text_batch_real], verbose=0)\n",
        "    if (epoch * batch_size + batch_index) % snapshot_interval == 0 and snapshot_dir_path is not None:\n",
        "      save_snapshots(generated_images, snapshot_dir_path=snapshot_dir_path, epoch=i, batch_index=batch_index)\n",
        "    #train the discriminator\n",
        "    discriminator.trainable = True\n",
        "    d_loss = discriminator.train_on_batch([np.concatenate((image_batch_real, generated_images,image_batch_wrong)),\n",
        "                                                            np.concatenate((text_batch_real, text_batch_real, text_batch_wrong))],\n",
        "                                                           np.array([1] * batch_size*10 + [0] * batch_size*10 + [0] * batch_size*10))\n",
        "    print(\"Epoch %d batch %d d_loss : %f\" % (i, batch_index, d_loss))\n",
        "    #train the generator\n",
        "    discriminator.trainable = False\n",
        "    g_loss = combined_model.train_on_batch([noise,text_batch_real], np.array([1] * batch_size*10))\n",
        "    print(\"Epoch %d batch %d g_loss : %f\" % (i, batch_index, g_loss))\n",
        "  generator.save_weights(generator_model_path, overwrite=True)\n",
        "  discriminator.save_weights(discriminator_model_path, overwrite=True)\n",
        "\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0 batch 0 d_loss : 0.503644\n",
            "Epoch 0 batch 0 g_loss : 0.669500\n",
            "Epoch 0 batch 1 d_loss : 0.489570\n",
            "Epoch 0 batch 1 g_loss : 0.656913\n",
            "Epoch 0 batch 2 d_loss : 0.516297\n",
            "Epoch 0 batch 2 g_loss : 0.646272\n",
            "Epoch 0 batch 3 d_loss : 0.489053\n",
            "Epoch 0 batch 3 g_loss : 0.642689\n",
            "Epoch 0 batch 4 d_loss : 0.514349\n",
            "Epoch 0 batch 4 g_loss : 0.637693\n",
            "Epoch 0 batch 5 d_loss : 0.497098\n",
            "Epoch 0 batch 5 g_loss : 0.627027\n",
            "Epoch 0 batch 6 d_loss : 0.545087\n",
            "Epoch 0 batch 6 g_loss : 0.615305\n",
            "Epoch 0 batch 7 d_loss : 0.546942\n",
            "Epoch 0 batch 7 g_loss : 0.614898\n",
            "Epoch 0 batch 8 d_loss : 0.505830\n",
            "Epoch 0 batch 8 g_loss : 0.615127\n",
            "Epoch 0 batch 9 d_loss : 0.474159\n",
            "Epoch 0 batch 9 g_loss : 0.617155\n",
            "Epoch 0 batch 10 d_loss : 0.465588\n",
            "Epoch 0 batch 10 g_loss : 0.627655\n",
            "Epoch 0 batch 11 d_loss : 0.514962\n",
            "Epoch 0 batch 11 g_loss : 0.639376\n",
            "Epoch 0 batch 12 d_loss : 0.506115\n",
            "Epoch 0 batch 12 g_loss : 0.652597\n",
            "Epoch 0 batch 13 d_loss : 0.453092\n",
            "Epoch 0 batch 13 g_loss : 0.668559\n",
            "Epoch 0 batch 14 d_loss : 0.472950\n",
            "Epoch 0 batch 14 g_loss : 0.686578\n",
            "Epoch 0 batch 15 d_loss : 0.443778\n",
            "Epoch 0 batch 15 g_loss : 0.708114\n",
            "Epoch 0 batch 16 d_loss : 0.472175\n",
            "Epoch 0 batch 16 g_loss : 0.739129\n",
            "Epoch 0 batch 17 d_loss : 0.468472\n",
            "Epoch 0 batch 17 g_loss : 0.761027\n",
            "Epoch 0 batch 18 d_loss : 0.501712\n",
            "Epoch 0 batch 18 g_loss : 0.774879\n",
            "Epoch 0 batch 19 d_loss : 0.477901\n",
            "Epoch 0 batch 19 g_loss : 0.786891\n",
            "Epoch 0 batch 20 d_loss : 0.447677\n",
            "Epoch 0 batch 20 g_loss : 0.790645\n",
            "Epoch 0 batch 21 d_loss : 0.473299\n",
            "Epoch 0 batch 21 g_loss : 0.791027\n",
            "Epoch 0 batch 22 d_loss : 0.486171\n",
            "Epoch 0 batch 22 g_loss : 0.706453\n",
            "Epoch 0 batch 23 d_loss : 0.454511\n",
            "Epoch 0 batch 23 g_loss : 0.696738\n",
            "Epoch 0 batch 24 d_loss : 0.453775\n",
            "Epoch 0 batch 24 g_loss : 0.698499\n",
            "Epoch 0 batch 25 d_loss : 0.464409\n",
            "Epoch 0 batch 25 g_loss : 0.688144\n",
            "Epoch 0 batch 26 d_loss : 0.442571\n",
            "Epoch 0 batch 26 g_loss : 0.681495\n",
            "Epoch 0 batch 27 d_loss : 0.447451\n",
            "Epoch 0 batch 27 g_loss : 0.670139\n",
            "Epoch 0 batch 28 d_loss : 0.490988\n",
            "Epoch 0 batch 28 g_loss : 0.665938\n",
            "Epoch 0 batch 29 d_loss : 0.441008\n",
            "Epoch 0 batch 29 g_loss : 0.651277\n",
            "Epoch 0 batch 30 d_loss : 0.449033\n",
            "Epoch 0 batch 30 g_loss : 0.657558\n",
            "Epoch 0 batch 31 d_loss : 0.470906\n",
            "Epoch 0 batch 31 g_loss : 0.651035\n",
            "Epoch 0 batch 32 d_loss : 0.473949\n",
            "Epoch 0 batch 32 g_loss : 0.633669\n",
            "Epoch 0 batch 33 d_loss : 0.461920\n",
            "Epoch 0 batch 33 g_loss : 0.624844\n",
            "Epoch 0 batch 34 d_loss : 0.464733\n",
            "Epoch 0 batch 34 g_loss : 0.615956\n",
            "Epoch 0 batch 35 d_loss : 0.461754\n",
            "Epoch 0 batch 35 g_loss : 0.620048\n",
            "Epoch 0 batch 36 d_loss : 0.429254\n",
            "Epoch 0 batch 36 g_loss : 0.610819\n",
            "Epoch 0 batch 37 d_loss : 0.523893\n",
            "Epoch 0 batch 37 g_loss : 0.608516\n",
            "Epoch 0 batch 38 d_loss : 0.528461\n",
            "Epoch 0 batch 38 g_loss : 0.598088\n",
            "Epoch 0 batch 39 d_loss : 0.500858\n",
            "Epoch 0 batch 39 g_loss : 0.671033\n",
            "Epoch 0 batch 40 d_loss : 0.494060\n",
            "Epoch 0 batch 40 g_loss : 0.662745\n",
            "Epoch 0 batch 41 d_loss : 0.546045\n",
            "Epoch 0 batch 41 g_loss : 0.657057\n",
            "Epoch 0 batch 42 d_loss : 0.507007\n",
            "Epoch 0 batch 42 g_loss : 0.647076\n",
            "Epoch 0 batch 43 d_loss : 0.533250\n",
            "Epoch 0 batch 43 g_loss : 0.640513\n",
            "Epoch 0 batch 44 d_loss : 0.497510\n",
            "Epoch 0 batch 44 g_loss : 0.633360\n",
            "Epoch 0 batch 45 d_loss : 0.509137\n",
            "Epoch 0 batch 45 g_loss : 0.626725\n",
            "Epoch 0 batch 46 d_loss : 0.488876\n",
            "Epoch 0 batch 46 g_loss : 0.615181\n",
            "Epoch 0 batch 47 d_loss : 0.513502\n",
            "Epoch 0 batch 47 g_loss : 0.613604\n",
            "Epoch 0 batch 48 d_loss : 0.516079\n",
            "Epoch 0 batch 48 g_loss : 0.611897\n",
            "Epoch 0 batch 49 d_loss : 0.482852\n",
            "Epoch 0 batch 49 g_loss : 0.621831\n",
            "Epoch 0 batch 50 d_loss : 0.471828\n",
            "Epoch 0 batch 50 g_loss : 0.619038\n",
            "Epoch 0 batch 51 d_loss : 0.460552\n",
            "Epoch 0 batch 51 g_loss : 0.621511\n",
            "Epoch 0 batch 52 d_loss : 0.470940\n",
            "Epoch 0 batch 52 g_loss : 0.626638\n",
            "Epoch 0 batch 53 d_loss : 0.465367\n",
            "Epoch 0 batch 53 g_loss : 0.633000\n",
            "Epoch 0 batch 54 d_loss : 0.492326\n",
            "Epoch 0 batch 54 g_loss : 0.635811\n",
            "Epoch 0 batch 55 d_loss : 0.482985\n",
            "Epoch 0 batch 55 g_loss : 0.643434\n",
            "Epoch 0 batch 56 d_loss : 0.502935\n",
            "Epoch 0 batch 56 g_loss : 0.646101\n",
            "Epoch 0 batch 57 d_loss : 0.473075\n",
            "Epoch 0 batch 57 g_loss : 0.653771\n",
            "Epoch 0 batch 58 d_loss : 0.474348\n",
            "Epoch 0 batch 58 g_loss : 0.665347\n",
            "Epoch 0 batch 59 d_loss : 0.462984\n",
            "Epoch 0 batch 59 g_loss : 0.665193\n",
            "Epoch 0 batch 60 d_loss : 0.466434\n",
            "Epoch 0 batch 60 g_loss : 0.671558\n",
            "Epoch 0 batch 61 d_loss : 0.465826\n",
            "Epoch 0 batch 61 g_loss : 0.678264\n",
            "Epoch 0 batch 62 d_loss : 0.454675\n",
            "Epoch 0 batch 62 g_loss : 0.681755\n",
            "Epoch 0 batch 63 d_loss : 0.464124\n",
            "Epoch 0 batch 63 g_loss : 0.688483\n",
            "Epoch 0 batch 64 d_loss : 0.450716\n",
            "Epoch 0 batch 64 g_loss : 0.689960\n",
            "Epoch 0 batch 65 d_loss : 0.467754\n",
            "Epoch 0 batch 65 g_loss : 0.692130\n",
            "Epoch 0 batch 66 d_loss : 0.464660\n",
            "Epoch 0 batch 66 g_loss : 0.691844\n",
            "Epoch 0 batch 67 d_loss : 0.451558\n",
            "Epoch 0 batch 67 g_loss : 0.691816\n",
            "Epoch 0 batch 68 d_loss : 0.444446\n",
            "Epoch 0 batch 68 g_loss : 0.689843\n",
            "Epoch 0 batch 69 d_loss : 0.445891\n",
            "Epoch 0 batch 69 g_loss : 0.685460\n",
            "Epoch 0 batch 70 d_loss : 0.448867\n",
            "Epoch 0 batch 70 g_loss : 0.681921\n",
            "Epoch 0 batch 71 d_loss : 0.455890\n",
            "Epoch 0 batch 71 g_loss : 0.678536\n",
            "Epoch 0 batch 72 d_loss : 0.449164\n",
            "Epoch 0 batch 72 g_loss : 0.676404\n",
            "Epoch 0 batch 73 d_loss : 0.453773\n",
            "Epoch 0 batch 73 g_loss : 0.671250\n",
            "Epoch 0 batch 74 d_loss : 0.457280\n",
            "Epoch 0 batch 74 g_loss : 0.668971\n",
            "Epoch 0 batch 75 d_loss : 0.436057\n",
            "Epoch 0 batch 75 g_loss : 0.665415\n",
            "Epoch 0 batch 76 d_loss : 0.443160\n",
            "Epoch 0 batch 76 g_loss : 0.660121\n",
            "Epoch 0 batch 77 d_loss : 0.453982\n",
            "Epoch 0 batch 77 g_loss : 0.653844\n",
            "Epoch 0 batch 78 d_loss : 0.443063\n",
            "Epoch 0 batch 78 g_loss : 0.652494\n",
            "Epoch 0 batch 79 d_loss : 0.452988\n",
            "Epoch 0 batch 79 g_loss : 0.646173\n",
            "Epoch 0 batch 80 d_loss : 0.446912\n",
            "Epoch 0 batch 80 g_loss : 0.637753\n",
            "Epoch 0 batch 81 d_loss : 0.439549\n",
            "Epoch 0 batch 81 g_loss : 0.635911\n",
            "Epoch 0 batch 82 d_loss : 0.460636\n",
            "Epoch 0 batch 82 g_loss : 0.635065\n",
            "Epoch 0 batch 83 d_loss : 0.444484\n",
            "Epoch 0 batch 83 g_loss : 0.628208\n",
            "Epoch 0 batch 84 d_loss : 0.459708\n",
            "Epoch 0 batch 84 g_loss : 0.622376\n",
            "Epoch 0 batch 85 d_loss : 0.458437\n",
            "Epoch 0 batch 85 g_loss : 0.624098\n",
            "Epoch 0 batch 86 d_loss : 0.439305\n",
            "Epoch 0 batch 86 g_loss : 0.616036\n",
            "Epoch 0 batch 87 d_loss : 0.454008\n",
            "Epoch 0 batch 87 g_loss : 0.610536\n",
            "Epoch 0 batch 88 d_loss : 0.448577\n",
            "Epoch 0 batch 88 g_loss : 0.615294\n",
            "Epoch 0 batch 89 d_loss : 0.437204\n",
            "Epoch 0 batch 89 g_loss : 0.614086\n",
            "Epoch 0 batch 90 d_loss : 0.458721\n",
            "Epoch 0 batch 90 g_loss : 0.612224\n",
            "Epoch 0 batch 91 d_loss : 0.436601\n",
            "Epoch 0 batch 91 g_loss : 0.614906\n",
            "Epoch 0 batch 92 d_loss : 0.451662\n",
            "Epoch 0 batch 92 g_loss : 0.624267\n",
            "Epoch 0 batch 93 d_loss : 0.468390\n",
            "Epoch 0 batch 93 g_loss : 0.631193\n",
            "Epoch 0 batch 94 d_loss : 0.447612\n",
            "Epoch 0 batch 94 g_loss : 0.638717\n",
            "Epoch 0 batch 95 d_loss : 0.456005\n",
            "Epoch 0 batch 95 g_loss : 0.645218\n",
            "Epoch 0 batch 96 d_loss : 0.462748\n",
            "Epoch 0 batch 96 g_loss : 0.639449\n",
            "Epoch 0 batch 97 d_loss : 0.445662\n",
            "Epoch 0 batch 97 g_loss : 0.642816\n",
            "Epoch 0 batch 98 d_loss : 0.444786\n",
            "Epoch 0 batch 98 g_loss : 0.641871\n",
            "Epoch 0 batch 99 d_loss : 0.485601\n",
            "Epoch 0 batch 99 g_loss : 0.672443\n",
            "Epoch 0 batch 100 d_loss : 0.500674\n",
            "Epoch 0 batch 100 g_loss : 0.659179\n",
            "Epoch 0 batch 101 d_loss : 0.505740\n",
            "Epoch 0 batch 101 g_loss : 0.663066\n",
            "Epoch 0 batch 102 d_loss : 0.480457\n",
            "Epoch 0 batch 102 g_loss : 0.648903\n",
            "Epoch 0 batch 103 d_loss : 0.501787\n",
            "Epoch 0 batch 103 g_loss : 0.648750\n",
            "Epoch 0 batch 104 d_loss : 0.499384\n",
            "Epoch 0 batch 104 g_loss : 0.646893\n",
            "Epoch 0 batch 105 d_loss : 0.489757\n",
            "Epoch 0 batch 105 g_loss : 0.633279\n",
            "Epoch 0 batch 106 d_loss : 0.432684\n",
            "Epoch 0 batch 106 g_loss : 0.627061\n",
            "Epoch 0 batch 107 d_loss : 0.439553\n",
            "Epoch 0 batch 107 g_loss : 0.616370\n",
            "Epoch 0 batch 108 d_loss : 0.471584\n",
            "Epoch 0 batch 108 g_loss : 0.622518\n",
            "Epoch 0 batch 109 d_loss : 0.443543\n",
            "Epoch 0 batch 109 g_loss : 0.634926\n",
            "Epoch 0 batch 110 d_loss : 0.430498\n",
            "Epoch 0 batch 110 g_loss : 0.634152\n",
            "Epoch 0 batch 111 d_loss : 0.440485\n",
            "Epoch 0 batch 111 g_loss : 0.641396\n",
            "Epoch 0 batch 112 d_loss : 0.449300\n",
            "Epoch 0 batch 112 g_loss : 0.672753\n",
            "Epoch 0 batch 113 d_loss : 0.427851\n",
            "Epoch 0 batch 113 g_loss : 0.685845\n",
            "Epoch 0 batch 114 d_loss : 0.455111\n",
            "Epoch 0 batch 114 g_loss : 0.713826\n",
            "Epoch 0 batch 115 d_loss : 0.477082\n",
            "Epoch 0 batch 115 g_loss : 0.701618\n",
            "Epoch 0 batch 116 d_loss : 0.454641\n",
            "Epoch 0 batch 116 g_loss : 0.677500\n",
            "Epoch 0 batch 117 d_loss : 0.449504\n",
            "Epoch 0 batch 117 g_loss : 0.688175\n",
            "Epoch 0 batch 118 d_loss : 0.445354\n",
            "Epoch 0 batch 118 g_loss : 0.659735\n",
            "Epoch 0 batch 119 d_loss : 0.451653\n",
            "Epoch 0 batch 119 g_loss : 0.589542\n",
            "Epoch 0 batch 120 d_loss : 0.455370\n",
            "Epoch 0 batch 120 g_loss : 0.595261\n",
            "Epoch 0 batch 121 d_loss : 0.435911\n",
            "Epoch 0 batch 121 g_loss : 0.579884\n",
            "Epoch 0 batch 122 d_loss : 0.446665\n",
            "Epoch 0 batch 122 g_loss : 0.536869\n",
            "Epoch 0 batch 123 d_loss : 0.373012\n",
            "Epoch 0 batch 123 g_loss : 0.485800\n",
            "Epoch 0 batch 124 d_loss : 0.407820\n",
            "Epoch 0 batch 124 g_loss : 0.578470\n",
            "Epoch 0 batch 125 d_loss : 0.404281\n",
            "Epoch 0 batch 125 g_loss : 0.720164\n",
            "Epoch 0 batch 126 d_loss : 0.368185\n",
            "Epoch 0 batch 126 g_loss : 0.517568\n",
            "Epoch 0 batch 127 d_loss : 0.324760\n",
            "Epoch 0 batch 127 g_loss : 0.424302\n",
            "Epoch 0 batch 128 d_loss : 0.341564\n",
            "Epoch 0 batch 128 g_loss : 0.398739\n",
            "Epoch 0 batch 129 d_loss : 0.390134\n",
            "Epoch 0 batch 129 g_loss : 0.463316\n",
            "Epoch 0 batch 130 d_loss : 0.410751\n",
            "Epoch 0 batch 130 g_loss : 0.522857\n",
            "Epoch 0 batch 131 d_loss : 0.432983\n",
            "Epoch 0 batch 131 g_loss : 0.585361\n",
            "Epoch 0 batch 132 d_loss : 0.398501\n",
            "Epoch 0 batch 132 g_loss : 0.505238\n",
            "Epoch 0 batch 133 d_loss : 0.426012\n",
            "Epoch 0 batch 133 g_loss : 0.509846\n",
            "Epoch 0 batch 134 d_loss : 0.379450\n",
            "Epoch 0 batch 134 g_loss : 0.442852\n",
            "Epoch 0 batch 135 d_loss : 0.365734\n",
            "Epoch 0 batch 135 g_loss : 0.463196\n",
            "Epoch 0 batch 136 d_loss : 0.512032\n",
            "Epoch 0 batch 136 g_loss : 0.743708\n",
            "Epoch 0 batch 137 d_loss : 0.669099\n",
            "Epoch 0 batch 137 g_loss : 0.989330\n",
            "Epoch 0 batch 138 d_loss : 0.574105\n",
            "Epoch 0 batch 138 g_loss : 0.522038\n",
            "Epoch 0 batch 139 d_loss : 0.558539\n",
            "Epoch 0 batch 139 g_loss : 0.387958\n",
            "Epoch 0 batch 140 d_loss : 0.530316\n",
            "Epoch 0 batch 140 g_loss : 0.323946\n",
            "Epoch 0 batch 141 d_loss : 0.545296\n",
            "Epoch 0 batch 141 g_loss : 0.350802\n",
            "Epoch 0 batch 142 d_loss : 0.520127\n",
            "Epoch 0 batch 142 g_loss : 0.331545\n",
            "Epoch 0 batch 143 d_loss : 0.502101\n",
            "Epoch 0 batch 143 g_loss : 0.350059\n",
            "Epoch 0 batch 144 d_loss : 0.506273\n",
            "Epoch 0 batch 144 g_loss : 0.368228\n",
            "Epoch 0 batch 145 d_loss : 0.502793\n",
            "Epoch 0 batch 145 g_loss : 0.370942\n",
            "Epoch 0 batch 146 d_loss : 0.485553\n",
            "Epoch 0 batch 146 g_loss : 0.420208\n",
            "Epoch 0 batch 147 d_loss : 0.451197\n",
            "Epoch 0 batch 147 g_loss : 0.444264\n",
            "Epoch 0 batch 148 d_loss : 0.454679\n",
            "Epoch 0 batch 148 g_loss : 0.508486\n",
            "Epoch 0 batch 149 d_loss : 0.478844\n",
            "Epoch 0 batch 149 g_loss : 0.577750\n",
            "Epoch 0 batch 150 d_loss : 0.473130\n",
            "Epoch 0 batch 150 g_loss : 0.610979\n",
            "Epoch 0 batch 151 d_loss : 0.484262\n",
            "Epoch 0 batch 151 g_loss : 0.655847\n",
            "Epoch 0 batch 152 d_loss : 0.461812\n",
            "Epoch 0 batch 152 g_loss : 0.676696\n",
            "Epoch 0 batch 153 d_loss : 0.480221\n",
            "Epoch 0 batch 153 g_loss : 0.688287\n",
            "Epoch 0 batch 154 d_loss : 0.523281\n",
            "Epoch 0 batch 154 g_loss : 0.726573\n",
            "Epoch 0 batch 155 d_loss : 0.566068\n",
            "Epoch 0 batch 155 g_loss : 0.710754\n",
            "Epoch 0 batch 156 d_loss : 0.518655\n",
            "Epoch 0 batch 156 g_loss : 0.725034\n",
            "Epoch 0 batch 157 d_loss : 0.547057\n",
            "Epoch 0 batch 157 g_loss : 0.707024\n",
            "Epoch 0 batch 158 d_loss : 0.522156\n",
            "Epoch 0 batch 158 g_loss : 0.684376\n",
            "Epoch 0 batch 159 d_loss : 0.497357\n",
            "Epoch 0 batch 159 g_loss : 0.714308\n",
            "Epoch 0 batch 160 d_loss : 0.476782\n",
            "Epoch 0 batch 160 g_loss : 0.718539\n",
            "Epoch 0 batch 161 d_loss : 0.509012\n",
            "Epoch 0 batch 161 g_loss : 0.703684\n",
            "Epoch 0 batch 162 d_loss : 0.491713\n",
            "Epoch 0 batch 162 g_loss : 0.678241\n",
            "Epoch 0 batch 163 d_loss : 0.480442\n",
            "Epoch 0 batch 163 g_loss : 0.656906\n",
            "Epoch 0 batch 164 d_loss : 0.471062\n",
            "Epoch 0 batch 164 g_loss : 0.616904\n",
            "Epoch 0 batch 165 d_loss : 0.421586\n",
            "Epoch 0 batch 165 g_loss : 0.603347\n",
            "Epoch 0 batch 166 d_loss : 0.436231\n",
            "Epoch 0 batch 166 g_loss : 0.589624\n",
            "Epoch 0 batch 167 d_loss : 0.419258\n",
            "Epoch 0 batch 167 g_loss : 0.557537\n",
            "Epoch 0 batch 168 d_loss : 0.413858\n",
            "Epoch 0 batch 168 g_loss : 0.542827\n",
            "Epoch 0 batch 169 d_loss : 0.421161\n",
            "Epoch 0 batch 169 g_loss : 0.556518\n",
            "Epoch 0 batch 170 d_loss : 0.434337\n",
            "Epoch 0 batch 170 g_loss : 0.538844\n",
            "Epoch 0 batch 171 d_loss : 0.424779\n",
            "Epoch 0 batch 171 g_loss : 0.537848\n",
            "Epoch 0 batch 172 d_loss : 0.421598\n",
            "Epoch 0 batch 172 g_loss : 0.534997\n",
            "Epoch 0 batch 173 d_loss : 0.415686\n",
            "Epoch 0 batch 173 g_loss : 0.545990\n",
            "Epoch 0 batch 174 d_loss : 0.416812\n",
            "Epoch 0 batch 174 g_loss : 0.542375\n",
            "Epoch 0 batch 175 d_loss : 0.415236\n",
            "Epoch 0 batch 175 g_loss : 0.554933\n",
            "Epoch 0 batch 176 d_loss : 0.428323\n",
            "Epoch 0 batch 176 g_loss : 0.565605\n",
            "Epoch 0 batch 177 d_loss : 0.402189\n",
            "Epoch 0 batch 177 g_loss : 0.576338\n",
            "Epoch 0 batch 178 d_loss : 0.425301\n",
            "Epoch 0 batch 178 g_loss : 0.586466\n",
            "Epoch 0 batch 179 d_loss : 0.456193\n",
            "Epoch 0 batch 179 g_loss : 0.582204\n",
            "Epoch 0 batch 180 d_loss : 0.445769\n",
            "Epoch 0 batch 180 g_loss : 0.587926\n",
            "Epoch 0 batch 181 d_loss : 0.437182\n",
            "Epoch 0 batch 181 g_loss : 0.578546\n",
            "Epoch 0 batch 182 d_loss : 0.430421\n",
            "Epoch 0 batch 182 g_loss : 0.581925\n",
            "Epoch 0 batch 183 d_loss : 0.399559\n",
            "Epoch 0 batch 183 g_loss : 0.588725\n",
            "Epoch 0 batch 184 d_loss : 0.426540\n",
            "Epoch 0 batch 184 g_loss : 0.600706\n",
            "Epoch 0 batch 185 d_loss : 0.400805\n",
            "Epoch 0 batch 185 g_loss : 0.591000\n",
            "Epoch 0 batch 186 d_loss : 0.395098\n",
            "Epoch 0 batch 186 g_loss : 0.594442\n",
            "Epoch 0 batch 187 d_loss : 0.394630\n",
            "Epoch 0 batch 187 g_loss : 0.590171\n",
            "Epoch 0 batch 188 d_loss : 0.386991\n",
            "Epoch 0 batch 188 g_loss : 0.597505\n",
            "Epoch 0 batch 189 d_loss : 0.488705\n",
            "Epoch 0 batch 189 g_loss : 0.674159\n",
            "Epoch 0 batch 190 d_loss : 0.473437\n",
            "Epoch 0 batch 190 g_loss : 0.670269\n",
            "Epoch 0 batch 191 d_loss : 0.535056\n",
            "Epoch 0 batch 191 g_loss : 0.709499\n",
            "Epoch 0 batch 192 d_loss : 0.483741\n",
            "Epoch 0 batch 192 g_loss : 0.669456\n",
            "Epoch 0 batch 193 d_loss : 0.482097\n",
            "Epoch 0 batch 193 g_loss : 0.615347\n",
            "Epoch 0 batch 194 d_loss : 0.472541\n",
            "Epoch 0 batch 194 g_loss : 0.587865\n",
            "Epoch 0 batch 195 d_loss : 0.500671\n",
            "Epoch 0 batch 195 g_loss : 0.573031\n",
            "Epoch 0 batch 196 d_loss : 0.447593\n",
            "Epoch 0 batch 196 g_loss : 0.558686\n",
            "Epoch 0 batch 197 d_loss : 0.461185\n",
            "Epoch 0 batch 197 g_loss : 0.544086\n",
            "Epoch 0 batch 198 d_loss : 0.454548\n",
            "Epoch 0 batch 198 g_loss : 0.531321\n",
            "Epoch 0 batch 199 d_loss : 0.412606\n",
            "Epoch 0 batch 199 g_loss : 0.522054\n",
            "Epoch 0 batch 200 d_loss : 0.412699\n",
            "Epoch 0 batch 200 g_loss : 0.537760\n",
            "Epoch 0 batch 201 d_loss : 0.396314\n",
            "Epoch 0 batch 201 g_loss : 0.522923\n",
            "Epoch 0 batch 202 d_loss : 0.389086\n",
            "Epoch 0 batch 202 g_loss : 0.524827\n",
            "Epoch 0 batch 203 d_loss : 0.435557\n",
            "Epoch 0 batch 203 g_loss : 0.553440\n",
            "Epoch 0 batch 204 d_loss : 0.363785\n",
            "Epoch 0 batch 204 g_loss : 0.518851\n",
            "Epoch 0 batch 205 d_loss : 0.430716\n",
            "Epoch 0 batch 205 g_loss : 0.542616\n",
            "Epoch 0 batch 206 d_loss : 0.406088\n",
            "Epoch 0 batch 206 g_loss : 0.564762\n",
            "Epoch 0 batch 207 d_loss : 0.451003\n",
            "Epoch 0 batch 207 g_loss : 0.575834\n",
            "Epoch 0 batch 208 d_loss : 0.451670\n",
            "Epoch 0 batch 208 g_loss : 0.562380\n",
            "Epoch 0 batch 209 d_loss : 0.457790\n",
            "Epoch 0 batch 209 g_loss : 0.569017\n",
            "Epoch 0 batch 210 d_loss : 0.434231\n",
            "Epoch 0 batch 210 g_loss : 0.658423\n",
            "Epoch 0 batch 211 d_loss : 0.531550\n",
            "Epoch 0 batch 211 g_loss : 0.728194\n",
            "Epoch 0 batch 212 d_loss : 0.522862\n",
            "Epoch 0 batch 212 g_loss : 0.739067\n",
            "Epoch 0 batch 213 d_loss : 0.499492\n",
            "Epoch 0 batch 213 g_loss : 0.696856\n",
            "Epoch 0 batch 214 d_loss : 0.487548\n",
            "Epoch 0 batch 214 g_loss : 0.693428\n",
            "Epoch 0 batch 215 d_loss : 0.513830\n",
            "Epoch 0 batch 215 g_loss : 0.643475\n",
            "Epoch 0 batch 216 d_loss : 0.436107\n",
            "Epoch 0 batch 216 g_loss : 0.566833\n",
            "Epoch 0 batch 217 d_loss : 0.481892\n",
            "Epoch 0 batch 217 g_loss : 0.550019\n",
            "Epoch 0 batch 218 d_loss : 0.487813\n",
            "Epoch 0 batch 218 g_loss : 0.548030\n",
            "Epoch 0 batch 219 d_loss : 0.482971\n",
            "Epoch 0 batch 219 g_loss : 0.548494\n",
            "Epoch 0 batch 220 d_loss : 0.479289\n",
            "Epoch 0 batch 220 g_loss : 0.538961\n",
            "Epoch 0 batch 221 d_loss : 0.464294\n",
            "Epoch 0 batch 221 g_loss : 0.544533\n",
            "Epoch 0 batch 222 d_loss : 0.470089\n",
            "Epoch 0 batch 222 g_loss : 0.555558\n",
            "Epoch 0 batch 223 d_loss : 0.484938\n",
            "Epoch 0 batch 223 g_loss : 0.569579\n",
            "Epoch 0 batch 224 d_loss : 0.444319\n",
            "Epoch 0 batch 224 g_loss : 0.579377\n",
            "Epoch 0 batch 225 d_loss : 0.441401\n",
            "Epoch 0 batch 225 g_loss : 0.579208\n",
            "Epoch 0 batch 226 d_loss : 0.443683\n",
            "Epoch 0 batch 226 g_loss : 0.588524\n",
            "Epoch 0 batch 227 d_loss : 0.482575\n",
            "Epoch 0 batch 227 g_loss : 0.589909\n",
            "Epoch 0 batch 228 d_loss : 0.464138\n",
            "Epoch 0 batch 228 g_loss : 0.593556\n",
            "Epoch 0 batch 229 d_loss : 0.558255\n",
            "Epoch 0 batch 229 g_loss : 0.610283\n",
            "Epoch 0 batch 230 d_loss : 0.486848\n",
            "Epoch 0 batch 230 g_loss : 0.609464\n",
            "Epoch 0 batch 231 d_loss : 0.492024\n",
            "Epoch 0 batch 231 g_loss : 0.609886\n",
            "Epoch 0 batch 232 d_loss : 0.503584\n",
            "Epoch 0 batch 232 g_loss : 0.614642\n",
            "Epoch 0 batch 233 d_loss : 0.461156\n",
            "Epoch 0 batch 233 g_loss : 0.607793\n",
            "Epoch 0 batch 234 d_loss : 0.437808\n",
            "Epoch 0 batch 234 g_loss : 0.599513\n",
            "Epoch 0 batch 235 d_loss : 0.448779\n",
            "Epoch 0 batch 235 g_loss : 0.612603\n",
            "Epoch 0 batch 236 d_loss : 0.425930\n",
            "Epoch 0 batch 236 g_loss : 0.634239\n",
            "Epoch 0 batch 237 d_loss : 0.436964\n",
            "Epoch 0 batch 237 g_loss : 0.620512\n",
            "Epoch 0 batch 238 d_loss : 0.430840\n",
            "Epoch 0 batch 238 g_loss : 0.618977\n",
            "Epoch 0 batch 239 d_loss : 0.459738\n",
            "Epoch 0 batch 239 g_loss : 0.612772\n",
            "Epoch 0 batch 240 d_loss : 0.456456\n",
            "Epoch 0 batch 240 g_loss : 0.608119\n",
            "Epoch 0 batch 241 d_loss : 0.459389\n",
            "Epoch 0 batch 241 g_loss : 0.613067\n",
            "Epoch 0 batch 242 d_loss : 0.465922\n",
            "Epoch 0 batch 242 g_loss : 0.610401\n",
            "Epoch 0 batch 243 d_loss : 0.462060\n",
            "Epoch 0 batch 243 g_loss : 0.606420\n",
            "Epoch 0 batch 244 d_loss : 0.453123\n",
            "Epoch 0 batch 244 g_loss : 0.608718\n",
            "Epoch 0 batch 245 d_loss : 0.474554\n",
            "Epoch 0 batch 245 g_loss : 0.630554\n",
            "Epoch 0 batch 246 d_loss : 0.454494\n",
            "Epoch 0 batch 246 g_loss : 0.611152\n",
            "Epoch 0 batch 247 d_loss : 0.471177\n",
            "Epoch 0 batch 247 g_loss : 0.600113\n",
            "Epoch 0 batch 248 d_loss : 0.465872\n",
            "Epoch 0 batch 248 g_loss : 0.590483\n",
            "Epoch 0 batch 249 d_loss : 0.445591\n",
            "Epoch 0 batch 249 g_loss : 0.584138\n",
            "Epoch 0 batch 250 d_loss : 0.467726\n",
            "Epoch 0 batch 250 g_loss : 0.575546\n",
            "Epoch 0 batch 251 d_loss : 0.479482\n",
            "Epoch 0 batch 251 g_loss : 0.574692\n",
            "Epoch 0 batch 252 d_loss : 0.475006\n",
            "Epoch 0 batch 252 g_loss : 0.569412\n",
            "Epoch 0 batch 253 d_loss : 0.467124\n",
            "Epoch 0 batch 253 g_loss : 0.577505\n",
            "Epoch 0 batch 254 d_loss : 0.476108\n",
            "Epoch 0 batch 254 g_loss : 0.584489\n",
            "Epoch 0 batch 255 d_loss : 0.456871\n",
            "Epoch 0 batch 255 g_loss : 0.594432\n",
            "Epoch 0 batch 256 d_loss : 0.428200\n",
            "Epoch 0 batch 256 g_loss : 0.617006\n",
            "Epoch 0 batch 257 d_loss : 0.435443\n",
            "Epoch 0 batch 257 g_loss : 0.626715\n",
            "Epoch 0 batch 258 d_loss : 0.455210\n",
            "Epoch 0 batch 258 g_loss : 0.633422\n",
            "Epoch 0 batch 259 d_loss : 0.453726\n",
            "Epoch 0 batch 259 g_loss : 0.648926\n",
            "Epoch 0 batch 260 d_loss : 0.455523\n",
            "Epoch 0 batch 260 g_loss : 0.647990\n",
            "Epoch 0 batch 261 d_loss : 0.441871\n",
            "Epoch 0 batch 261 g_loss : 0.647370\n",
            "Epoch 0 batch 262 d_loss : 0.452691\n",
            "Epoch 0 batch 262 g_loss : 0.640802\n",
            "Epoch 0 batch 263 d_loss : 0.452147\n",
            "Epoch 0 batch 263 g_loss : 0.639750\n",
            "Epoch 0 batch 264 d_loss : 0.444232\n",
            "Epoch 0 batch 264 g_loss : 0.630644\n",
            "Epoch 0 batch 265 d_loss : 0.455041\n",
            "Epoch 0 batch 265 g_loss : 0.618474\n",
            "Epoch 0 batch 266 d_loss : 0.456114\n",
            "Epoch 0 batch 266 g_loss : 0.593674\n",
            "Epoch 0 batch 267 d_loss : 0.469961\n",
            "Epoch 0 batch 267 g_loss : 0.607661\n",
            "Epoch 0 batch 268 d_loss : 0.449472\n",
            "Epoch 0 batch 268 g_loss : 0.583534\n",
            "Epoch 0 batch 269 d_loss : 0.423903\n",
            "Epoch 0 batch 269 g_loss : 0.575007\n",
            "Epoch 0 batch 270 d_loss : 0.470689\n",
            "Epoch 0 batch 270 g_loss : 0.594164\n",
            "Epoch 0 batch 271 d_loss : 0.460085\n",
            "Epoch 0 batch 271 g_loss : 0.642832\n",
            "Epoch 0 batch 272 d_loss : 0.464172\n",
            "Epoch 0 batch 272 g_loss : 0.597496\n",
            "Epoch 0 batch 273 d_loss : 0.457263\n",
            "Epoch 0 batch 273 g_loss : 0.610205\n",
            "Epoch 0 batch 274 d_loss : 0.469424\n",
            "Epoch 0 batch 274 g_loss : 0.601850\n",
            "Epoch 0 batch 275 d_loss : 0.476936\n",
            "Epoch 0 batch 275 g_loss : 0.568604\n",
            "Epoch 0 batch 276 d_loss : 0.459275\n",
            "Epoch 0 batch 276 g_loss : 0.593354\n",
            "Epoch 0 batch 277 d_loss : 0.463981\n",
            "Epoch 0 batch 277 g_loss : 0.601525\n",
            "Epoch 0 batch 278 d_loss : 0.482661\n",
            "Epoch 0 batch 278 g_loss : 0.623564\n",
            "Epoch 0 batch 279 d_loss : 0.451259\n",
            "Epoch 0 batch 279 g_loss : 0.604700\n",
            "Epoch 0 batch 280 d_loss : 0.461483\n",
            "Epoch 0 batch 280 g_loss : 0.656403\n",
            "Epoch 0 batch 281 d_loss : 0.458767\n",
            "Epoch 0 batch 281 g_loss : 0.657004\n",
            "Epoch 0 batch 282 d_loss : 0.450698\n",
            "Epoch 0 batch 282 g_loss : 0.629158\n",
            "Epoch 0 batch 283 d_loss : 0.450014\n",
            "Epoch 0 batch 283 g_loss : 0.614437\n",
            "Epoch 0 batch 284 d_loss : 0.453095\n",
            "Epoch 0 batch 284 g_loss : 0.611512\n",
            "Epoch 0 batch 285 d_loss : 0.493589\n",
            "Epoch 0 batch 285 g_loss : 0.645037\n",
            "Epoch 0 batch 286 d_loss : 0.494171\n",
            "Epoch 0 batch 286 g_loss : 0.599343\n",
            "Epoch 0 batch 287 d_loss : 0.482320\n",
            "Epoch 0 batch 287 g_loss : 0.551065\n",
            "Epoch 0 batch 288 d_loss : 0.468815\n",
            "Epoch 0 batch 288 g_loss : 0.542487\n",
            "Epoch 0 batch 289 d_loss : 0.458667\n",
            "Epoch 0 batch 289 g_loss : 0.504691\n",
            "Epoch 0 batch 290 d_loss : 0.463868\n",
            "Epoch 0 batch 290 g_loss : 0.545677\n",
            "Epoch 0 batch 291 d_loss : 0.478843\n",
            "Epoch 0 batch 291 g_loss : 0.591746\n",
            "Epoch 0 batch 292 d_loss : 0.458702\n",
            "Epoch 0 batch 292 g_loss : 0.649200\n",
            "Epoch 0 batch 293 d_loss : 0.441125\n",
            "Epoch 0 batch 293 g_loss : 0.703252\n",
            "Epoch 0 batch 294 d_loss : 0.446271\n",
            "Epoch 0 batch 294 g_loss : 0.727855\n",
            "Epoch 0 batch 295 d_loss : 0.451068\n",
            "Epoch 0 batch 295 g_loss : 0.727313\n",
            "Epoch 0 batch 296 d_loss : 0.443726\n",
            "Epoch 0 batch 296 g_loss : 0.716014\n",
            "Epoch 0 batch 297 d_loss : 0.453505\n",
            "Epoch 0 batch 297 g_loss : 0.692418\n",
            "Epoch 0 batch 298 d_loss : 0.477789\n",
            "Epoch 0 batch 298 g_loss : 0.721600\n",
            "Epoch 0 batch 299 d_loss : 0.463795\n",
            "Epoch 0 batch 299 g_loss : 0.664596\n",
            "Epoch 0 batch 300 d_loss : 0.504201\n",
            "Epoch 0 batch 300 g_loss : 0.633201\n",
            "Epoch 0 batch 301 d_loss : 0.493274\n",
            "Epoch 0 batch 301 g_loss : 0.602406\n",
            "Epoch 0 batch 302 d_loss : 0.473287\n",
            "Epoch 0 batch 302 g_loss : 0.573957\n",
            "Epoch 0 batch 303 d_loss : 0.467994\n",
            "Epoch 0 batch 303 g_loss : 0.576801\n",
            "Epoch 0 batch 304 d_loss : 0.475142\n",
            "Epoch 0 batch 304 g_loss : 0.559013\n",
            "Epoch 0 batch 305 d_loss : 0.531087\n",
            "Epoch 0 batch 305 g_loss : 0.569410\n",
            "Epoch 0 batch 306 d_loss : 0.508468\n",
            "Epoch 0 batch 306 g_loss : 0.611666\n",
            "Epoch 0 batch 307 d_loss : 0.534901\n",
            "Epoch 0 batch 307 g_loss : 0.611721\n",
            "Epoch 0 batch 308 d_loss : 0.525117\n",
            "Epoch 0 batch 308 g_loss : 0.609142\n",
            "Epoch 0 batch 309 d_loss : 0.470524\n",
            "Epoch 0 batch 309 g_loss : 0.592303\n",
            "Epoch 0 batch 310 d_loss : 0.440457\n",
            "Epoch 0 batch 310 g_loss : 0.586234\n",
            "Epoch 0 batch 311 d_loss : 0.439140\n",
            "Epoch 0 batch 311 g_loss : 0.599010\n",
            "Epoch 0 batch 312 d_loss : 0.442808\n",
            "Epoch 0 batch 312 g_loss : 0.608448\n",
            "Epoch 0 batch 313 d_loss : 0.433402\n",
            "Epoch 0 batch 313 g_loss : 0.625884\n",
            "Epoch 0 batch 314 d_loss : 0.426920\n",
            "Epoch 0 batch 314 g_loss : 0.640784\n",
            "Epoch 0 batch 315 d_loss : 0.433957\n",
            "Epoch 0 batch 315 g_loss : 0.653665\n",
            "Epoch 0 batch 316 d_loss : 0.435825\n",
            "Epoch 0 batch 316 g_loss : 0.662241\n",
            "Epoch 0 batch 317 d_loss : 0.463279\n",
            "Epoch 0 batch 317 g_loss : 0.670586\n",
            "Epoch 0 batch 318 d_loss : 0.469135\n",
            "Epoch 0 batch 318 g_loss : 0.663417\n",
            "Epoch 0 batch 319 d_loss : 0.470316\n",
            "Epoch 0 batch 319 g_loss : 0.669052\n",
            "Epoch 0 batch 320 d_loss : 0.492463\n",
            "Epoch 0 batch 320 g_loss : 0.661539\n",
            "Epoch 0 batch 321 d_loss : 0.481718\n",
            "Epoch 0 batch 321 g_loss : 0.662733\n",
            "Epoch 0 batch 322 d_loss : 0.442928\n",
            "Epoch 0 batch 322 g_loss : 0.660494\n",
            "Epoch 0 batch 323 d_loss : 0.434865\n",
            "Epoch 0 batch 323 g_loss : 0.652671\n",
            "Epoch 0 batch 324 d_loss : 0.452107\n",
            "Epoch 0 batch 324 g_loss : 0.648517\n",
            "Epoch 0 batch 325 d_loss : 0.472622\n",
            "Epoch 0 batch 325 g_loss : 0.640513\n",
            "Epoch 0 batch 326 d_loss : 0.468536\n",
            "Epoch 0 batch 326 g_loss : 0.645159\n",
            "Epoch 0 batch 327 d_loss : 0.461557\n",
            "Epoch 0 batch 327 g_loss : 0.638513\n",
            "Epoch 0 batch 328 d_loss : 0.545417\n",
            "Epoch 0 batch 328 g_loss : 0.633333\n",
            "Epoch 0 batch 329 d_loss : 0.540650\n",
            "Epoch 0 batch 329 g_loss : 0.618084\n",
            "Epoch 0 batch 330 d_loss : 0.509557\n",
            "Epoch 0 batch 330 g_loss : 0.599519\n",
            "Epoch 0 batch 331 d_loss : 0.521942\n",
            "Epoch 0 batch 331 g_loss : 0.588168\n",
            "Epoch 0 batch 332 d_loss : 0.515233\n",
            "Epoch 0 batch 332 g_loss : 0.575346\n",
            "Epoch 0 batch 333 d_loss : 0.497703\n",
            "Epoch 0 batch 333 g_loss : 0.568394\n",
            "Epoch 0 batch 334 d_loss : 0.495156\n",
            "Epoch 0 batch 334 g_loss : 0.566560\n",
            "Epoch 0 batch 335 d_loss : 0.504867\n",
            "Epoch 0 batch 335 g_loss : 0.562906\n",
            "Epoch 0 batch 336 d_loss : 0.497332\n",
            "Epoch 0 batch 336 g_loss : 0.565866\n",
            "Epoch 0 batch 337 d_loss : 0.474649\n",
            "Epoch 0 batch 337 g_loss : 0.573232\n",
            "Epoch 0 batch 338 d_loss : 0.520722\n",
            "Epoch 0 batch 338 g_loss : 0.581372\n",
            "Epoch 0 batch 339 d_loss : 0.451081\n",
            "Epoch 0 batch 339 g_loss : 0.594881\n",
            "Epoch 0 batch 340 d_loss : 0.469292\n",
            "Epoch 0 batch 340 g_loss : 0.606515\n",
            "Epoch 0 batch 341 d_loss : 0.480067\n",
            "Epoch 0 batch 341 g_loss : 0.619444\n",
            "Epoch 0 batch 342 d_loss : 0.472559\n",
            "Epoch 0 batch 342 g_loss : 0.633246\n",
            "Epoch 0 batch 343 d_loss : 0.483795\n",
            "Epoch 0 batch 343 g_loss : 0.644019\n",
            "Epoch 0 batch 344 d_loss : 0.467423\n",
            "Epoch 0 batch 344 g_loss : 0.654030\n",
            "Epoch 0 batch 345 d_loss : 0.447079\n",
            "Epoch 0 batch 345 g_loss : 0.663357\n",
            "Epoch 0 batch 346 d_loss : 0.463219\n",
            "Epoch 0 batch 346 g_loss : 0.673192\n",
            "Epoch 0 batch 347 d_loss : 0.442092\n",
            "Epoch 0 batch 347 g_loss : 0.680954\n",
            "Epoch 0 batch 348 d_loss : 0.460271\n",
            "Epoch 0 batch 348 g_loss : 0.689403\n",
            "Epoch 0 batch 349 d_loss : 0.466047\n",
            "Epoch 0 batch 349 g_loss : 0.692011\n",
            "Epoch 0 batch 350 d_loss : 0.467767\n",
            "Epoch 0 batch 350 g_loss : 0.692245\n",
            "Epoch 0 batch 351 d_loss : 0.478603\n",
            "Epoch 0 batch 351 g_loss : 0.690034\n",
            "Epoch 0 batch 352 d_loss : 0.500447\n",
            "Epoch 0 batch 352 g_loss : 0.683567\n",
            "Epoch 0 batch 353 d_loss : 0.491101\n",
            "Epoch 0 batch 353 g_loss : 0.682060\n",
            "Epoch 0 batch 354 d_loss : 0.480410\n",
            "Epoch 0 batch 354 g_loss : 0.674899\n",
            "Epoch 0 batch 355 d_loss : 0.457253\n",
            "Epoch 0 batch 355 g_loss : 0.670812\n",
            "Epoch 0 batch 356 d_loss : 0.461788\n",
            "Epoch 0 batch 356 g_loss : 0.667375\n",
            "Epoch 0 batch 357 d_loss : 0.456084\n",
            "Epoch 0 batch 357 g_loss : 0.681347\n",
            "Epoch 0 batch 358 d_loss : 0.456474\n",
            "Epoch 0 batch 358 g_loss : 0.705759\n",
            "Epoch 0 batch 359 d_loss : 0.446435\n",
            "Epoch 0 batch 359 g_loss : 0.712407\n",
            "Epoch 0 batch 360 d_loss : 0.447449\n",
            "Epoch 0 batch 360 g_loss : 0.730465\n",
            "Epoch 0 batch 361 d_loss : 0.459171\n",
            "Epoch 0 batch 361 g_loss : 0.726127\n",
            "Epoch 0 batch 362 d_loss : 0.446512\n",
            "Epoch 0 batch 362 g_loss : 0.729036\n",
            "Epoch 0 batch 363 d_loss : 0.461841\n",
            "Epoch 0 batch 363 g_loss : 0.728505\n",
            "Epoch 0 batch 364 d_loss : 0.452969\n",
            "Epoch 0 batch 364 g_loss : 0.724428\n",
            "Epoch 0 batch 365 d_loss : 0.469406\n",
            "Epoch 0 batch 365 g_loss : 0.721578\n",
            "Epoch 0 batch 366 d_loss : 0.474027\n",
            "Epoch 0 batch 366 g_loss : 0.718779\n",
            "Epoch 0 batch 367 d_loss : 0.462250\n",
            "Epoch 0 batch 367 g_loss : 0.718330\n",
            "Epoch 0 batch 368 d_loss : 0.479967\n",
            "Epoch 0 batch 368 g_loss : 0.715292\n",
            "Epoch 0 batch 369 d_loss : 0.466415\n",
            "Epoch 0 batch 369 g_loss : 0.623450\n",
            "Epoch 0 batch 370 d_loss : 0.467534\n",
            "Epoch 0 batch 370 g_loss : 0.623841\n",
            "Epoch 0 batch 371 d_loss : 0.457725\n",
            "Epoch 0 batch 371 g_loss : 0.627044\n",
            "Epoch 0 batch 372 d_loss : 0.484540\n",
            "Epoch 0 batch 372 g_loss : 0.634032\n",
            "Epoch 0 batch 373 d_loss : 0.480951\n",
            "Epoch 0 batch 373 g_loss : 0.635962\n",
            "Epoch 0 batch 374 d_loss : 0.489672\n",
            "Epoch 0 batch 374 g_loss : 0.639376\n",
            "Epoch 0 batch 375 d_loss : 0.454014\n",
            "Epoch 0 batch 375 g_loss : 0.640572\n",
            "Epoch 0 batch 376 d_loss : 0.464211\n",
            "Epoch 0 batch 376 g_loss : 0.646953\n",
            "Epoch 0 batch 377 d_loss : 0.460320\n",
            "Epoch 0 batch 377 g_loss : 0.651979\n",
            "Epoch 0 batch 378 d_loss : 0.437625\n",
            "Epoch 0 batch 378 g_loss : 0.663002\n",
            "Epoch 0 batch 379 d_loss : 0.457238\n",
            "Epoch 0 batch 379 g_loss : 0.668757\n",
            "Epoch 0 batch 380 d_loss : 0.450567\n",
            "Epoch 0 batch 380 g_loss : 0.672869\n",
            "Epoch 0 batch 381 d_loss : 0.454421\n",
            "Epoch 0 batch 381 g_loss : 0.668455\n",
            "Epoch 0 batch 382 d_loss : 0.463100\n",
            "Epoch 0 batch 382 g_loss : 0.668590\n",
            "Epoch 0 batch 383 d_loss : 0.464177\n",
            "Epoch 0 batch 383 g_loss : 0.667409\n",
            "Epoch 0 batch 384 d_loss : 0.449099\n",
            "Epoch 0 batch 384 g_loss : 0.669080\n",
            "Epoch 0 batch 385 d_loss : 0.460645\n",
            "Epoch 0 batch 385 g_loss : 0.664933\n",
            "Epoch 0 batch 386 d_loss : 0.470072\n",
            "Epoch 0 batch 386 g_loss : 0.661754\n",
            "Epoch 0 batch 387 d_loss : 0.487344\n",
            "Epoch 0 batch 387 g_loss : 0.650847\n",
            "Epoch 0 batch 388 d_loss : 0.476943\n",
            "Epoch 0 batch 388 g_loss : 0.642033\n",
            "Epoch 0 batch 389 d_loss : 0.478066\n",
            "Epoch 0 batch 389 g_loss : 0.630982\n",
            "Epoch 0 batch 390 d_loss : 0.447303\n",
            "Epoch 0 batch 390 g_loss : 0.628655\n",
            "Epoch 0 batch 391 d_loss : 0.443564\n",
            "Epoch 0 batch 391 g_loss : 0.629505\n",
            "Epoch 0 batch 392 d_loss : 0.449690\n",
            "Epoch 0 batch 392 g_loss : 0.629175\n",
            "Epoch 0 batch 393 d_loss : 0.458500\n",
            "Epoch 0 batch 393 g_loss : 0.627949\n",
            "Epoch 0 batch 394 d_loss : 0.478436\n",
            "Epoch 0 batch 394 g_loss : 0.628244\n",
            "Epoch 0 batch 395 d_loss : 0.472526\n",
            "Epoch 0 batch 395 g_loss : 0.632151\n",
            "Epoch 0 batch 396 d_loss : 0.474010\n",
            "Epoch 0 batch 396 g_loss : 0.629491\n",
            "Epoch 0 batch 397 d_loss : 0.451469\n",
            "Epoch 0 batch 397 g_loss : 0.631445\n",
            "Epoch 0 batch 398 d_loss : 0.452104\n",
            "Epoch 0 batch 398 g_loss : 0.634002\n",
            "Epoch 0 batch 399 d_loss : 0.460986\n",
            "Epoch 0 batch 399 g_loss : 0.639047\n",
            "Epoch 0 batch 400 d_loss : 0.448842\n",
            "Epoch 0 batch 400 g_loss : 0.644959\n",
            "Epoch 0 batch 401 d_loss : 0.449906\n",
            "Epoch 0 batch 401 g_loss : 0.656043\n",
            "Epoch 0 batch 402 d_loss : 0.450557\n",
            "Epoch 0 batch 402 g_loss : 0.685321\n",
            "Epoch 0 batch 403 d_loss : 0.446790\n",
            "Epoch 0 batch 403 g_loss : 0.714490\n",
            "Epoch 0 batch 404 d_loss : 0.434981\n",
            "Epoch 0 batch 404 g_loss : 0.716315\n",
            "Epoch 0 batch 405 d_loss : 0.514944\n",
            "Epoch 0 batch 405 g_loss : 0.655521\n",
            "Epoch 0 batch 406 d_loss : 0.503076\n",
            "Epoch 0 batch 406 g_loss : 0.633083\n",
            "Epoch 0 batch 407 d_loss : 0.520474\n",
            "Epoch 0 batch 407 g_loss : 0.623244\n",
            "Epoch 0 batch 408 d_loss : 0.467168\n",
            "Epoch 0 batch 408 g_loss : 0.601510\n",
            "Epoch 0 batch 409 d_loss : 0.428029\n",
            "Epoch 0 batch 409 g_loss : 0.594754\n",
            "Epoch 0 batch 410 d_loss : 0.463437\n",
            "Epoch 0 batch 410 g_loss : 0.586666\n",
            "Epoch 0 batch 411 d_loss : 0.439167\n",
            "Epoch 0 batch 411 g_loss : 0.590269\n",
            "Epoch 0 batch 412 d_loss : 0.462602\n",
            "Epoch 0 batch 412 g_loss : 0.590335\n",
            "Epoch 0 batch 413 d_loss : 0.452400\n",
            "Epoch 0 batch 413 g_loss : 0.595463\n",
            "Epoch 0 batch 414 d_loss : 0.439290\n",
            "Epoch 0 batch 414 g_loss : 0.600962\n",
            "Epoch 0 batch 415 d_loss : 0.443430\n",
            "Epoch 0 batch 415 g_loss : 0.602155\n",
            "Epoch 0 batch 416 d_loss : 0.457526\n",
            "Epoch 0 batch 416 g_loss : 0.603575\n",
            "Epoch 0 batch 417 d_loss : 0.468943\n",
            "Epoch 0 batch 417 g_loss : 0.606324\n",
            "Epoch 0 batch 418 d_loss : 0.441592\n",
            "Epoch 0 batch 418 g_loss : 0.601682\n",
            "Epoch 0 batch 419 d_loss : 0.419958\n",
            "Epoch 0 batch 419 g_loss : 0.603923\n",
            "Epoch 0 batch 420 d_loss : 0.442493\n",
            "Epoch 0 batch 420 g_loss : 0.613709\n",
            "Epoch 0 batch 421 d_loss : 0.454131\n",
            "Epoch 0 batch 421 g_loss : 0.651526\n",
            "Epoch 0 batch 422 d_loss : 0.446510\n",
            "Epoch 0 batch 422 g_loss : 0.657832\n",
            "Epoch 0 batch 423 d_loss : 0.482296\n",
            "Epoch 0 batch 423 g_loss : 0.653059\n",
            "Epoch 0 batch 424 d_loss : 0.464867\n",
            "Epoch 0 batch 424 g_loss : 0.634255\n",
            "Epoch 0 batch 425 d_loss : 0.472678\n",
            "Epoch 0 batch 425 g_loss : 0.630362\n",
            "Epoch 0 batch 426 d_loss : 0.495057\n",
            "Epoch 0 batch 426 g_loss : 0.618903\n",
            "Epoch 0 batch 427 d_loss : 0.483240\n",
            "Epoch 0 batch 427 g_loss : 0.601959\n",
            "Epoch 0 batch 428 d_loss : 0.460533\n",
            "Epoch 0 batch 428 g_loss : 0.560208\n",
            "Epoch 0 batch 429 d_loss : 0.460983\n",
            "Epoch 0 batch 429 g_loss : 0.546332\n",
            "Epoch 0 batch 430 d_loss : 0.508784\n",
            "Epoch 0 batch 430 g_loss : 0.529643\n",
            "Epoch 0 batch 431 d_loss : 0.506837\n",
            "Epoch 0 batch 431 g_loss : 0.520659\n",
            "Epoch 0 batch 432 d_loss : 0.481785\n",
            "Epoch 0 batch 432 g_loss : 0.519215\n",
            "Epoch 0 batch 433 d_loss : 0.470782\n",
            "Epoch 0 batch 433 g_loss : 0.502762\n",
            "Epoch 0 batch 434 d_loss : 0.469647\n",
            "Epoch 0 batch 434 g_loss : 0.503779\n",
            "Epoch 0 batch 435 d_loss : 0.440077\n",
            "Epoch 0 batch 435 g_loss : 0.510095\n",
            "Epoch 0 batch 436 d_loss : 0.426564\n",
            "Epoch 0 batch 436 g_loss : 0.528222\n",
            "Epoch 0 batch 437 d_loss : 0.417500\n",
            "Epoch 0 batch 437 g_loss : 0.535732\n",
            "Epoch 0 batch 438 d_loss : 0.463654\n",
            "Epoch 0 batch 438 g_loss : 0.563573\n",
            "Epoch 0 batch 439 d_loss : 0.442857\n",
            "Epoch 0 batch 439 g_loss : 0.581679\n",
            "Epoch 0 batch 440 d_loss : 0.431154\n",
            "Epoch 0 batch 440 g_loss : 0.583937\n",
            "Epoch 0 batch 441 d_loss : 0.417351\n",
            "Epoch 0 batch 441 g_loss : 0.596268\n",
            "Epoch 0 batch 442 d_loss : 0.445514\n",
            "Epoch 0 batch 442 g_loss : 0.598917\n",
            "Epoch 0 batch 443 d_loss : 0.421075\n",
            "Epoch 0 batch 443 g_loss : 0.587980\n",
            "Epoch 0 batch 444 d_loss : 0.428268\n",
            "Epoch 0 batch 444 g_loss : 0.595317\n",
            "Epoch 0 batch 445 d_loss : 0.430133\n",
            "Epoch 0 batch 445 g_loss : 0.606940\n",
            "Epoch 0 batch 446 d_loss : 0.432763\n",
            "Epoch 0 batch 446 g_loss : 0.606070\n",
            "Epoch 0 batch 447 d_loss : 0.475781\n",
            "Epoch 0 batch 447 g_loss : 0.589602\n",
            "Epoch 0 batch 448 d_loss : 0.488007\n",
            "Epoch 0 batch 448 g_loss : 0.557281\n",
            "Epoch 0 batch 449 d_loss : 0.442748\n",
            "Epoch 0 batch 449 g_loss : 0.554479\n",
            "Epoch 0 batch 450 d_loss : 0.439153\n",
            "Epoch 0 batch 450 g_loss : 0.583530\n",
            "Epoch 0 batch 451 d_loss : 0.447997\n",
            "Epoch 0 batch 451 g_loss : 0.571046\n",
            "Epoch 0 batch 452 d_loss : 0.455899\n",
            "Epoch 0 batch 452 g_loss : 0.564556\n",
            "Epoch 0 batch 453 d_loss : 0.479212\n",
            "Epoch 0 batch 453 g_loss : 0.566631\n",
            "Epoch 0 batch 454 d_loss : 0.438946\n",
            "Epoch 0 batch 454 g_loss : 0.534163\n",
            "Epoch 0 batch 455 d_loss : 0.449416\n",
            "Epoch 0 batch 455 g_loss : 0.532710\n",
            "Epoch 0 batch 456 d_loss : 0.419609\n",
            "Epoch 0 batch 456 g_loss : 0.501113\n",
            "Epoch 0 batch 457 d_loss : 0.395611\n",
            "Epoch 0 batch 457 g_loss : 0.477935\n",
            "Epoch 0 batch 458 d_loss : 0.407562\n",
            "Epoch 0 batch 458 g_loss : 0.492493\n",
            "Epoch 0 batch 459 d_loss : 0.412842\n",
            "Epoch 0 batch 459 g_loss : 0.512420\n",
            "Epoch 0 batch 460 d_loss : 0.418376\n",
            "Epoch 0 batch 460 g_loss : 0.559686\n",
            "Epoch 0 batch 461 d_loss : 0.398198\n",
            "Epoch 0 batch 461 g_loss : 0.566108\n",
            "Epoch 0 batch 462 d_loss : 0.386374\n",
            "Epoch 0 batch 462 g_loss : 0.536494\n",
            "Epoch 0 batch 463 d_loss : 0.403240\n",
            "Epoch 0 batch 463 g_loss : 0.552194\n",
            "Epoch 0 batch 464 d_loss : 0.372882\n",
            "Epoch 0 batch 464 g_loss : 0.534365\n",
            "Epoch 0 batch 465 d_loss : 0.429630\n",
            "Epoch 0 batch 465 g_loss : 0.518937\n",
            "Epoch 0 batch 466 d_loss : 0.472295\n",
            "Epoch 0 batch 466 g_loss : 0.562790\n",
            "Epoch 0 batch 467 d_loss : 0.479099\n",
            "Epoch 0 batch 467 g_loss : 0.569845\n",
            "Epoch 0 batch 468 d_loss : 0.482007\n",
            "Epoch 0 batch 468 g_loss : 0.481180\n",
            "Epoch 0 batch 469 d_loss : 0.510313\n",
            "Epoch 0 batch 469 g_loss : 0.405714\n",
            "Epoch 0 batch 470 d_loss : 0.444542\n",
            "Epoch 0 batch 470 g_loss : 0.363650\n",
            "Epoch 0 batch 471 d_loss : 0.497538\n",
            "Epoch 0 batch 471 g_loss : 0.378093\n",
            "Epoch 0 batch 472 d_loss : 0.482969\n",
            "Epoch 0 batch 472 g_loss : 0.402745\n",
            "Epoch 0 batch 473 d_loss : 0.471231\n",
            "Epoch 0 batch 473 g_loss : 0.437857\n",
            "Epoch 0 batch 474 d_loss : 0.490746\n",
            "Epoch 0 batch 474 g_loss : 0.488170\n",
            "Epoch 0 batch 475 d_loss : 0.459483\n",
            "Epoch 0 batch 475 g_loss : 0.530834\n",
            "Epoch 0 batch 476 d_loss : 0.487262\n",
            "Epoch 0 batch 476 g_loss : 0.561008\n",
            "Epoch 0 batch 477 d_loss : 0.490811\n",
            "Epoch 0 batch 477 g_loss : 0.581643\n",
            "Epoch 0 batch 478 d_loss : 0.487572\n",
            "Epoch 0 batch 478 g_loss : 0.577143\n",
            "Epoch 0 batch 479 d_loss : 0.500581\n",
            "Epoch 0 batch 479 g_loss : 0.582739\n",
            "Epoch 0 batch 480 d_loss : 0.439427\n",
            "Epoch 0 batch 480 g_loss : 0.583889\n",
            "Epoch 0 batch 481 d_loss : 0.454851\n",
            "Epoch 0 batch 481 g_loss : 0.570590\n",
            "Epoch 0 batch 482 d_loss : 0.441739\n",
            "Epoch 0 batch 482 g_loss : 0.573659\n",
            "Epoch 0 batch 483 d_loss : 0.431805\n",
            "Epoch 0 batch 483 g_loss : 0.566385\n",
            "Epoch 0 batch 484 d_loss : 0.471785\n",
            "Epoch 0 batch 484 g_loss : 0.536007\n",
            "Epoch 0 batch 485 d_loss : 0.455670\n",
            "Epoch 0 batch 485 g_loss : 0.521361\n",
            "Epoch 0 batch 486 d_loss : 0.450463\n",
            "Epoch 0 batch 486 g_loss : 0.516750\n",
            "Epoch 0 batch 487 d_loss : 0.441479\n",
            "Epoch 0 batch 487 g_loss : 0.513657\n",
            "Epoch 0 batch 488 d_loss : 0.469789\n",
            "Epoch 0 batch 488 g_loss : 0.521773\n",
            "Epoch 0 batch 489 d_loss : 0.479707\n",
            "Epoch 0 batch 489 g_loss : 0.532130\n",
            "Epoch 0 batch 490 d_loss : 0.482760\n",
            "Epoch 0 batch 490 g_loss : 0.569502\n",
            "Epoch 0 batch 491 d_loss : 0.474643\n",
            "Epoch 0 batch 491 g_loss : 0.568444\n",
            "Epoch 0 batch 492 d_loss : 0.465521\n",
            "Epoch 0 batch 492 g_loss : 0.579765\n",
            "Epoch 0 batch 493 d_loss : 0.436103\n",
            "Epoch 0 batch 493 g_loss : 0.587588\n",
            "Epoch 0 batch 494 d_loss : 0.473063\n",
            "Epoch 0 batch 494 g_loss : 0.592584\n",
            "Epoch 0 batch 495 d_loss : 0.468174\n",
            "Epoch 0 batch 495 g_loss : 0.597246\n",
            "Epoch 0 batch 496 d_loss : 0.455829\n",
            "Epoch 0 batch 496 g_loss : 0.595838\n",
            "Epoch 0 batch 497 d_loss : 0.536599\n",
            "Epoch 0 batch 497 g_loss : 0.599449\n",
            "Epoch 0 batch 498 d_loss : 0.465027\n",
            "Epoch 0 batch 498 g_loss : 0.584954\n",
            "Epoch 0 batch 499 d_loss : 0.443087\n",
            "Epoch 0 batch 499 g_loss : 0.576130\n",
            "Epoch 0 batch 500 d_loss : 0.424041\n",
            "Epoch 0 batch 500 g_loss : 0.528279\n",
            "Epoch 0 batch 501 d_loss : 0.449855\n",
            "Epoch 0 batch 501 g_loss : 0.523643\n",
            "Epoch 0 batch 502 d_loss : 0.460561\n",
            "Epoch 0 batch 502 g_loss : 0.510247\n",
            "Epoch 0 batch 503 d_loss : 0.450267\n",
            "Epoch 0 batch 503 g_loss : 0.541936\n",
            "Epoch 0 batch 504 d_loss : 0.470319\n",
            "Epoch 0 batch 504 g_loss : 0.517847\n",
            "Epoch 0 batch 505 d_loss : 0.452480\n",
            "Epoch 0 batch 505 g_loss : 0.495878\n",
            "Epoch 0 batch 506 d_loss : 0.465550\n",
            "Epoch 0 batch 506 g_loss : 0.471959\n",
            "Epoch 0 batch 507 d_loss : 0.530545\n",
            "Epoch 0 batch 507 g_loss : 0.485591\n",
            "Epoch 0 batch 508 d_loss : 0.476403\n",
            "Epoch 0 batch 508 g_loss : 0.480041\n",
            "Epoch 0 batch 509 d_loss : 0.478463\n",
            "Epoch 0 batch 509 g_loss : 0.473280\n",
            "Epoch 0 batch 510 d_loss : 0.486202\n",
            "Epoch 0 batch 510 g_loss : 0.470083\n",
            "Epoch 1 batch 0 d_loss : 0.488961\n",
            "Epoch 1 batch 0 g_loss : 0.456350\n",
            "Epoch 1 batch 1 d_loss : 0.461693\n",
            "Epoch 1 batch 1 g_loss : 0.455561\n",
            "Epoch 1 batch 2 d_loss : 0.455052\n",
            "Epoch 1 batch 2 g_loss : 0.453995\n",
            "Epoch 1 batch 3 d_loss : 0.461250\n",
            "Epoch 1 batch 3 g_loss : 0.452452\n",
            "Epoch 1 batch 4 d_loss : 0.453673\n",
            "Epoch 1 batch 4 g_loss : 0.459469\n",
            "Epoch 1 batch 5 d_loss : 0.472619\n",
            "Epoch 1 batch 5 g_loss : 0.463264\n",
            "Epoch 1 batch 6 d_loss : 0.461373\n",
            "Epoch 1 batch 6 g_loss : 0.468042\n",
            "Epoch 1 batch 7 d_loss : 0.444015\n",
            "Epoch 1 batch 7 g_loss : 0.469884\n",
            "Epoch 1 batch 8 d_loss : 0.460641\n",
            "Epoch 1 batch 8 g_loss : 0.476239\n",
            "Epoch 1 batch 9 d_loss : 0.465206\n",
            "Epoch 1 batch 9 g_loss : 0.479021\n",
            "Epoch 1 batch 10 d_loss : 0.452265\n",
            "Epoch 1 batch 10 g_loss : 0.479517\n",
            "Epoch 1 batch 11 d_loss : 0.460284\n",
            "Epoch 1 batch 11 g_loss : 0.478237\n",
            "Epoch 1 batch 12 d_loss : 0.443850\n",
            "Epoch 1 batch 12 g_loss : 0.475764\n",
            "Epoch 1 batch 13 d_loss : 0.450141\n",
            "Epoch 1 batch 13 g_loss : 0.472652\n",
            "Epoch 1 batch 14 d_loss : 0.465248\n",
            "Epoch 1 batch 14 g_loss : 0.466778\n",
            "Epoch 1 batch 15 d_loss : 0.450088\n",
            "Epoch 1 batch 15 g_loss : 0.467633\n",
            "Epoch 1 batch 16 d_loss : 0.431498\n",
            "Epoch 1 batch 16 g_loss : 0.471757\n",
            "Epoch 1 batch 17 d_loss : 0.435663\n",
            "Epoch 1 batch 17 g_loss : 0.463263\n",
            "Epoch 1 batch 18 d_loss : 0.464152\n",
            "Epoch 1 batch 18 g_loss : 0.459553\n",
            "Epoch 1 batch 19 d_loss : 0.464482\n",
            "Epoch 1 batch 19 g_loss : 0.451026\n",
            "Epoch 1 batch 20 d_loss : 0.461544\n",
            "Epoch 1 batch 20 g_loss : 0.448655\n",
            "Epoch 1 batch 21 d_loss : 0.467849\n",
            "Epoch 1 batch 21 g_loss : 0.444536\n",
            "Epoch 1 batch 22 d_loss : 0.470809\n",
            "Epoch 1 batch 22 g_loss : 0.443993\n",
            "Epoch 1 batch 23 d_loss : 0.457696\n",
            "Epoch 1 batch 23 g_loss : 0.443585\n",
            "Epoch 1 batch 24 d_loss : 0.464989\n",
            "Epoch 1 batch 24 g_loss : 0.444915\n",
            "Epoch 1 batch 25 d_loss : 0.458849\n",
            "Epoch 1 batch 25 g_loss : 0.447801\n",
            "Epoch 1 batch 26 d_loss : 0.454179\n",
            "Epoch 1 batch 26 g_loss : 0.450788\n",
            "Epoch 1 batch 27 d_loss : 0.452920\n",
            "Epoch 1 batch 27 g_loss : 0.449971\n",
            "Epoch 1 batch 28 d_loss : 0.451102\n",
            "Epoch 1 batch 28 g_loss : 0.453730\n",
            "Epoch 1 batch 29 d_loss : 0.429257\n",
            "Epoch 1 batch 29 g_loss : 0.453336\n",
            "Epoch 1 batch 30 d_loss : 0.429492\n",
            "Epoch 1 batch 30 g_loss : 0.450189\n",
            "Epoch 1 batch 31 d_loss : 0.440870\n",
            "Epoch 1 batch 31 g_loss : 0.457532\n",
            "Epoch 1 batch 32 d_loss : 0.413159\n",
            "Epoch 1 batch 32 g_loss : 0.451132\n",
            "Epoch 1 batch 33 d_loss : 0.456799\n",
            "Epoch 1 batch 33 g_loss : 0.459211\n",
            "Epoch 1 batch 34 d_loss : 0.428360\n",
            "Epoch 1 batch 34 g_loss : 0.451871\n",
            "Epoch 1 batch 35 d_loss : 0.454642\n",
            "Epoch 1 batch 35 g_loss : 0.460087\n",
            "Epoch 1 batch 36 d_loss : 0.428492\n",
            "Epoch 1 batch 36 g_loss : 0.454520\n",
            "Epoch 1 batch 37 d_loss : 0.542735\n",
            "Epoch 1 batch 37 g_loss : 0.448559\n",
            "Epoch 1 batch 38 d_loss : 0.533169\n",
            "Epoch 1 batch 38 g_loss : 0.451565\n",
            "Epoch 1 batch 39 d_loss : 0.530637\n",
            "Epoch 1 batch 39 g_loss : 0.441237\n",
            "Epoch 1 batch 40 d_loss : 0.519292\n",
            "Epoch 1 batch 40 g_loss : 0.438030\n",
            "Epoch 1 batch 41 d_loss : 0.499809\n",
            "Epoch 1 batch 41 g_loss : 0.432633\n",
            "Epoch 1 batch 42 d_loss : 0.497090\n",
            "Epoch 1 batch 42 g_loss : 0.428129\n",
            "Epoch 1 batch 43 d_loss : 0.487684\n",
            "Epoch 1 batch 43 g_loss : 0.425397\n",
            "Epoch 1 batch 44 d_loss : 0.498471\n",
            "Epoch 1 batch 44 g_loss : 0.422106\n",
            "Epoch 1 batch 45 d_loss : 0.494328\n",
            "Epoch 1 batch 45 g_loss : 0.423569\n",
            "Epoch 1 batch 46 d_loss : 0.489626\n",
            "Epoch 1 batch 46 g_loss : 0.425370\n",
            "Epoch 1 batch 47 d_loss : 0.474335\n",
            "Epoch 1 batch 47 g_loss : 0.432182\n",
            "Epoch 1 batch 48 d_loss : 0.480317\n",
            "Epoch 1 batch 48 g_loss : 0.434275\n",
            "Epoch 1 batch 49 d_loss : 0.473455\n",
            "Epoch 1 batch 49 g_loss : 0.446905\n",
            "Epoch 1 batch 50 d_loss : 0.461364\n",
            "Epoch 1 batch 50 g_loss : 0.451007\n",
            "Epoch 1 batch 51 d_loss : 0.464776\n",
            "Epoch 1 batch 51 g_loss : 0.456724\n",
            "Epoch 1 batch 52 d_loss : 0.462226\n",
            "Epoch 1 batch 52 g_loss : 0.462986\n",
            "Epoch 1 batch 53 d_loss : 0.472578\n",
            "Epoch 1 batch 53 g_loss : 0.469570\n",
            "Epoch 1 batch 54 d_loss : 0.489826\n",
            "Epoch 1 batch 54 g_loss : 0.471514\n",
            "Epoch 1 batch 55 d_loss : 0.476858\n",
            "Epoch 1 batch 55 g_loss : 0.471156\n",
            "Epoch 1 batch 56 d_loss : 0.473754\n",
            "Epoch 1 batch 56 g_loss : 0.468784\n",
            "Epoch 1 batch 57 d_loss : 0.485982\n",
            "Epoch 1 batch 57 g_loss : 0.468497\n",
            "Epoch 1 batch 58 d_loss : 0.480134\n",
            "Epoch 1 batch 58 g_loss : 0.464163\n",
            "Epoch 1 batch 59 d_loss : 0.465334\n",
            "Epoch 1 batch 59 g_loss : 0.463211\n",
            "Epoch 1 batch 60 d_loss : 0.455168\n",
            "Epoch 1 batch 60 g_loss : 0.462258\n",
            "Epoch 1 batch 61 d_loss : 0.438742\n",
            "Epoch 1 batch 61 g_loss : 0.457059\n",
            "Epoch 1 batch 62 d_loss : 0.446385\n",
            "Epoch 1 batch 62 g_loss : 0.454004\n",
            "Epoch 1 batch 63 d_loss : 0.439210\n",
            "Epoch 1 batch 63 g_loss : 0.458858\n",
            "Epoch 1 batch 64 d_loss : 0.459036\n",
            "Epoch 1 batch 64 g_loss : 0.458040\n",
            "Epoch 1 batch 65 d_loss : 0.454730\n",
            "Epoch 1 batch 65 g_loss : 0.460489\n",
            "Epoch 1 batch 66 d_loss : 0.435423\n",
            "Epoch 1 batch 66 g_loss : 0.460466\n",
            "Epoch 1 batch 67 d_loss : 0.438330\n",
            "Epoch 1 batch 67 g_loss : 0.464341\n",
            "Epoch 1 batch 68 d_loss : 0.445265\n",
            "Epoch 1 batch 68 g_loss : 0.464222\n",
            "Epoch 1 batch 69 d_loss : 0.433553\n",
            "Epoch 1 batch 69 g_loss : 0.468653\n",
            "Epoch 1 batch 70 d_loss : 0.438008\n",
            "Epoch 1 batch 70 g_loss : 0.471309\n",
            "Epoch 1 batch 71 d_loss : 0.455286\n",
            "Epoch 1 batch 71 g_loss : 0.473330\n",
            "Epoch 1 batch 72 d_loss : 0.463670\n",
            "Epoch 1 batch 72 g_loss : 0.477000\n",
            "Epoch 1 batch 73 d_loss : 0.460902\n",
            "Epoch 1 batch 73 g_loss : 0.477098\n",
            "Epoch 1 batch 74 d_loss : 0.458129\n",
            "Epoch 1 batch 74 g_loss : 0.477696\n",
            "Epoch 1 batch 75 d_loss : 0.454146\n",
            "Epoch 1 batch 75 g_loss : 0.476841\n",
            "Epoch 1 batch 76 d_loss : 0.460248\n",
            "Epoch 1 batch 76 g_loss : 0.475257\n",
            "Epoch 1 batch 77 d_loss : 0.451585\n",
            "Epoch 1 batch 77 g_loss : 0.475164\n",
            "Epoch 1 batch 78 d_loss : 0.453620\n",
            "Epoch 1 batch 78 g_loss : 0.477378\n",
            "Epoch 1 batch 79 d_loss : 0.467894\n",
            "Epoch 1 batch 79 g_loss : 0.476210\n",
            "Epoch 1 batch 80 d_loss : 0.458794\n",
            "Epoch 1 batch 80 g_loss : 0.475491\n",
            "Epoch 1 batch 81 d_loss : 0.450940\n",
            "Epoch 1 batch 81 g_loss : 0.476576\n",
            "Epoch 1 batch 82 d_loss : 0.476184\n",
            "Epoch 1 batch 82 g_loss : 0.473019\n",
            "Epoch 1 batch 83 d_loss : 0.440337\n",
            "Epoch 1 batch 83 g_loss : 0.471670\n",
            "Epoch 1 batch 84 d_loss : 0.461462\n",
            "Epoch 1 batch 84 g_loss : 0.473381\n",
            "Epoch 1 batch 85 d_loss : 0.454501\n",
            "Epoch 1 batch 85 g_loss : 0.472178\n",
            "Epoch 1 batch 86 d_loss : 0.461029\n",
            "Epoch 1 batch 86 g_loss : 0.467935\n",
            "Epoch 1 batch 87 d_loss : 0.465960\n",
            "Epoch 1 batch 87 g_loss : 0.467766\n",
            "Epoch 1 batch 88 d_loss : 0.464899\n",
            "Epoch 1 batch 88 g_loss : 0.466331\n",
            "Epoch 1 batch 89 d_loss : 0.455317\n",
            "Epoch 1 batch 89 g_loss : 0.461354\n",
            "Epoch 1 batch 90 d_loss : 0.467564\n",
            "Epoch 1 batch 90 g_loss : 0.459801\n",
            "Epoch 1 batch 91 d_loss : 0.465671\n",
            "Epoch 1 batch 91 g_loss : 0.457711\n",
            "Epoch 1 batch 92 d_loss : 0.461809\n",
            "Epoch 1 batch 92 g_loss : 0.457914\n",
            "Epoch 1 batch 93 d_loss : 0.478352\n",
            "Epoch 1 batch 93 g_loss : 0.459351\n",
            "Epoch 1 batch 94 d_loss : 0.446590\n",
            "Epoch 1 batch 94 g_loss : 0.459348\n",
            "Epoch 1 batch 95 d_loss : 0.437259\n",
            "Epoch 1 batch 95 g_loss : 0.460894\n",
            "Epoch 1 batch 96 d_loss : 0.457683\n",
            "Epoch 1 batch 96 g_loss : 0.457174\n",
            "Epoch 1 batch 97 d_loss : 0.456426\n",
            "Epoch 1 batch 97 g_loss : 0.462351\n",
            "Epoch 1 batch 98 d_loss : 0.444671\n",
            "Epoch 1 batch 98 g_loss : 0.462968\n",
            "Epoch 1 batch 99 d_loss : 0.472753\n",
            "Epoch 1 batch 99 g_loss : 0.478479\n",
            "Epoch 1 batch 100 d_loss : 0.473761\n",
            "Epoch 1 batch 100 g_loss : 0.475565\n",
            "Epoch 1 batch 101 d_loss : 0.492563\n",
            "Epoch 1 batch 101 g_loss : 0.480016\n",
            "Epoch 1 batch 102 d_loss : 0.473979\n",
            "Epoch 1 batch 102 g_loss : 0.475582\n",
            "Epoch 1 batch 103 d_loss : 0.485534\n",
            "Epoch 1 batch 103 g_loss : 0.478865\n",
            "Epoch 1 batch 104 d_loss : 0.481606\n",
            "Epoch 1 batch 104 g_loss : 0.479218\n",
            "Epoch 1 batch 105 d_loss : 0.475869\n",
            "Epoch 1 batch 105 g_loss : 0.484402\n",
            "Epoch 1 batch 106 d_loss : 0.446246\n",
            "Epoch 1 batch 106 g_loss : 0.469033\n",
            "Epoch 1 batch 107 d_loss : 0.454179\n",
            "Epoch 1 batch 107 g_loss : 0.473786\n",
            "Epoch 1 batch 108 d_loss : 0.475670\n",
            "Epoch 1 batch 108 g_loss : 0.477836\n",
            "Epoch 1 batch 109 d_loss : 0.452215\n",
            "Epoch 1 batch 109 g_loss : 0.485387\n",
            "Epoch 1 batch 110 d_loss : 0.458789\n",
            "Epoch 1 batch 110 g_loss : 0.482015\n",
            "Epoch 1 batch 111 d_loss : 0.455768\n",
            "Epoch 1 batch 111 g_loss : 0.482980\n",
            "Epoch 1 batch 112 d_loss : 0.425746\n",
            "Epoch 1 batch 112 g_loss : 0.490228\n",
            "Epoch 1 batch 113 d_loss : 0.461341\n",
            "Epoch 1 batch 113 g_loss : 0.489561\n",
            "Epoch 1 batch 114 d_loss : 0.440707\n",
            "Epoch 1 batch 114 g_loss : 0.491082\n",
            "Epoch 1 batch 115 d_loss : 0.482826\n",
            "Epoch 1 batch 115 g_loss : 0.491717\n",
            "Epoch 1 batch 116 d_loss : 0.447782\n",
            "Epoch 1 batch 116 g_loss : 0.482345\n",
            "Epoch 1 batch 117 d_loss : 0.454751\n",
            "Epoch 1 batch 117 g_loss : 0.482252\n",
            "Epoch 1 batch 118 d_loss : 0.451433\n",
            "Epoch 1 batch 118 g_loss : 0.474417\n",
            "Epoch 1 batch 119 d_loss : 0.451895\n",
            "Epoch 1 batch 119 g_loss : 0.466660\n",
            "Epoch 1 batch 120 d_loss : 0.432800\n",
            "Epoch 1 batch 120 g_loss : 0.478427\n",
            "Epoch 1 batch 121 d_loss : 0.443741\n",
            "Epoch 1 batch 121 g_loss : 0.474257\n",
            "Epoch 1 batch 122 d_loss : 0.441725\n",
            "Epoch 1 batch 122 g_loss : 0.461415\n",
            "Epoch 1 batch 123 d_loss : 0.424051\n",
            "Epoch 1 batch 123 g_loss : 0.431185\n",
            "Epoch 1 batch 124 d_loss : 0.433121\n",
            "Epoch 1 batch 124 g_loss : 0.443599\n",
            "Epoch 1 batch 125 d_loss : 0.426532\n",
            "Epoch 1 batch 125 g_loss : 0.463870\n",
            "Epoch 1 batch 126 d_loss : 0.406608\n",
            "Epoch 1 batch 126 g_loss : 0.458020\n",
            "Epoch 1 batch 127 d_loss : 0.398073\n",
            "Epoch 1 batch 127 g_loss : 0.465789\n",
            "Epoch 1 batch 128 d_loss : 0.388701\n",
            "Epoch 1 batch 128 g_loss : 0.441392\n",
            "Epoch 1 batch 129 d_loss : 0.449407\n",
            "Epoch 1 batch 129 g_loss : 0.442421\n",
            "Epoch 1 batch 130 d_loss : 0.431906\n",
            "Epoch 1 batch 130 g_loss : 0.407927\n",
            "Epoch 1 batch 131 d_loss : 0.438631\n",
            "Epoch 1 batch 131 g_loss : 0.371073\n",
            "Epoch 1 batch 132 d_loss : 0.444231\n",
            "Epoch 1 batch 132 g_loss : 0.350334\n",
            "Epoch 1 batch 133 d_loss : 0.455646\n",
            "Epoch 1 batch 133 g_loss : 0.374614\n",
            "Epoch 1 batch 134 d_loss : 0.419369\n",
            "Epoch 1 batch 134 g_loss : 0.424656\n",
            "Epoch 1 batch 135 d_loss : 0.398349\n",
            "Epoch 1 batch 135 g_loss : 0.415869\n",
            "Epoch 1 batch 136 d_loss : 0.424862\n",
            "Epoch 1 batch 136 g_loss : 0.374243\n",
            "Epoch 1 batch 137 d_loss : 0.481271\n",
            "Epoch 1 batch 137 g_loss : 0.361655\n",
            "Epoch 1 batch 138 d_loss : 0.449125\n",
            "Epoch 1 batch 138 g_loss : 0.308129\n",
            "Epoch 1 batch 139 d_loss : 0.472457\n",
            "Epoch 1 batch 139 g_loss : 0.350523\n",
            "Epoch 1 batch 140 d_loss : 0.518087\n",
            "Epoch 1 batch 140 g_loss : 0.463921\n",
            "Epoch 1 batch 141 d_loss : 0.516403\n",
            "Epoch 1 batch 141 g_loss : 0.618255\n",
            "Epoch 1 batch 142 d_loss : 0.471059\n",
            "Epoch 1 batch 142 g_loss : 0.532512\n",
            "Epoch 1 batch 143 d_loss : 0.431559\n",
            "Epoch 1 batch 143 g_loss : 0.476186\n",
            "Epoch 1 batch 144 d_loss : 0.468119\n",
            "Epoch 1 batch 144 g_loss : 0.435623\n",
            "Epoch 1 batch 145 d_loss : 0.457524\n",
            "Epoch 1 batch 145 g_loss : 0.373961\n",
            "Epoch 1 batch 146 d_loss : 0.438507\n",
            "Epoch 1 batch 146 g_loss : 0.370264\n",
            "Epoch 1 batch 147 d_loss : 0.459538\n",
            "Epoch 1 batch 147 g_loss : 0.370565\n",
            "Epoch 1 batch 148 d_loss : 0.456289\n",
            "Epoch 1 batch 148 g_loss : 0.400931\n",
            "Epoch 1 batch 149 d_loss : 0.448894\n",
            "Epoch 1 batch 149 g_loss : 0.427552\n",
            "Epoch 1 batch 150 d_loss : 0.454694\n",
            "Epoch 1 batch 150 g_loss : 0.436177\n",
            "Epoch 1 batch 151 d_loss : 0.468612\n",
            "Epoch 1 batch 151 g_loss : 0.483861\n",
            "Epoch 1 batch 152 d_loss : 0.453926\n",
            "Epoch 1 batch 152 g_loss : 0.486451\n",
            "Epoch 1 batch 153 d_loss : 0.452249\n",
            "Epoch 1 batch 153 g_loss : 0.505705\n",
            "Epoch 1 batch 154 d_loss : 0.482657\n",
            "Epoch 1 batch 154 g_loss : 0.469862\n",
            "Epoch 1 batch 155 d_loss : 0.490589\n",
            "Epoch 1 batch 155 g_loss : 0.472126\n",
            "Epoch 1 batch 156 d_loss : 0.452398\n",
            "Epoch 1 batch 156 g_loss : 0.450294\n",
            "Epoch 1 batch 157 d_loss : 0.464185\n",
            "Epoch 1 batch 157 g_loss : 0.438028\n",
            "Epoch 1 batch 158 d_loss : 0.462951\n",
            "Epoch 1 batch 158 g_loss : 0.405121\n",
            "Epoch 1 batch 159 d_loss : 0.437420\n",
            "Epoch 1 batch 159 g_loss : 0.421295\n",
            "Epoch 1 batch 160 d_loss : 0.477566\n",
            "Epoch 1 batch 160 g_loss : 0.433323\n",
            "Epoch 1 batch 161 d_loss : 0.472770\n",
            "Epoch 1 batch 161 g_loss : 0.434163\n",
            "Epoch 1 batch 162 d_loss : 0.478192\n",
            "Epoch 1 batch 162 g_loss : 0.431392\n",
            "Epoch 1 batch 163 d_loss : 0.478479\n",
            "Epoch 1 batch 163 g_loss : 0.422138\n",
            "Epoch 1 batch 164 d_loss : 0.452448\n",
            "Epoch 1 batch 164 g_loss : 0.404318\n",
            "Epoch 1 batch 165 d_loss : 0.437552\n",
            "Epoch 1 batch 165 g_loss : 0.392504\n",
            "Epoch 1 batch 166 d_loss : 0.456514\n",
            "Epoch 1 batch 166 g_loss : 0.420236\n",
            "Epoch 1 batch 167 d_loss : 0.452712\n",
            "Epoch 1 batch 167 g_loss : 0.388428\n",
            "Epoch 1 batch 168 d_loss : 0.447336\n",
            "Epoch 1 batch 168 g_loss : 0.408120\n",
            "Epoch 1 batch 169 d_loss : 0.444300\n",
            "Epoch 1 batch 169 g_loss : 0.408453\n",
            "Epoch 1 batch 170 d_loss : 0.444214\n",
            "Epoch 1 batch 170 g_loss : 0.412018\n",
            "Epoch 1 batch 171 d_loss : 0.455104\n",
            "Epoch 1 batch 171 g_loss : 0.430111\n",
            "Epoch 1 batch 172 d_loss : 0.416985\n",
            "Epoch 1 batch 172 g_loss : 0.434839\n",
            "Epoch 1 batch 173 d_loss : 0.439363\n",
            "Epoch 1 batch 173 g_loss : 0.444273\n",
            "Epoch 1 batch 174 d_loss : 0.410467\n",
            "Epoch 1 batch 174 g_loss : 0.416600\n",
            "Epoch 1 batch 175 d_loss : 0.424868\n",
            "Epoch 1 batch 175 g_loss : 0.451651\n",
            "Epoch 1 batch 176 d_loss : 0.433700\n",
            "Epoch 1 batch 176 g_loss : 0.457253\n",
            "Epoch 1 batch 177 d_loss : 0.423863\n",
            "Epoch 1 batch 177 g_loss : 0.411670\n",
            "Epoch 1 batch 178 d_loss : 0.431497\n",
            "Epoch 1 batch 178 g_loss : 0.388496\n",
            "Epoch 1 batch 179 d_loss : 0.450093\n",
            "Epoch 1 batch 179 g_loss : 0.400274\n",
            "Epoch 1 batch 180 d_loss : 0.455327\n",
            "Epoch 1 batch 180 g_loss : 0.402893\n",
            "Epoch 1 batch 181 d_loss : 0.455857\n",
            "Epoch 1 batch 181 g_loss : 0.401780\n",
            "Epoch 1 batch 182 d_loss : 0.442399\n",
            "Epoch 1 batch 182 g_loss : 0.421778\n",
            "Epoch 1 batch 183 d_loss : 0.426968\n",
            "Epoch 1 batch 183 g_loss : 0.438310\n",
            "Epoch 1 batch 184 d_loss : 0.418795\n",
            "Epoch 1 batch 184 g_loss : 0.443816\n",
            "Epoch 1 batch 185 d_loss : 0.415285\n",
            "Epoch 1 batch 185 g_loss : 0.424743\n",
            "Epoch 1 batch 186 d_loss : 0.402911\n",
            "Epoch 1 batch 186 g_loss : 0.407574\n",
            "Epoch 1 batch 187 d_loss : 0.436264\n",
            "Epoch 1 batch 187 g_loss : 0.401328\n",
            "Epoch 1 batch 188 d_loss : 0.423092\n",
            "Epoch 1 batch 188 g_loss : 0.401746\n",
            "Epoch 1 batch 189 d_loss : 0.472295\n",
            "Epoch 1 batch 189 g_loss : 0.422982\n",
            "Epoch 1 batch 190 d_loss : 0.449864\n",
            "Epoch 1 batch 190 g_loss : 0.413809\n",
            "Epoch 1 batch 191 d_loss : 0.521100\n",
            "Epoch 1 batch 191 g_loss : 0.421194\n",
            "Epoch 1 batch 192 d_loss : 0.469944\n",
            "Epoch 1 batch 192 g_loss : 0.394560\n",
            "Epoch 1 batch 193 d_loss : 0.470138\n",
            "Epoch 1 batch 193 g_loss : 0.376994\n",
            "Epoch 1 batch 194 d_loss : 0.455805\n",
            "Epoch 1 batch 194 g_loss : 0.365770\n",
            "Epoch 1 batch 195 d_loss : 0.582095\n",
            "Epoch 1 batch 195 g_loss : 0.367491\n",
            "Epoch 1 batch 196 d_loss : 0.469658\n",
            "Epoch 1 batch 196 g_loss : 0.357544\n",
            "Epoch 1 batch 197 d_loss : 0.455663\n",
            "Epoch 1 batch 197 g_loss : 0.373480\n",
            "Epoch 1 batch 198 d_loss : 0.459451\n",
            "Epoch 1 batch 198 g_loss : 0.385724\n",
            "Epoch 1 batch 199 d_loss : 0.432353\n",
            "Epoch 1 batch 199 g_loss : 0.388155\n",
            "Epoch 1 batch 200 d_loss : 0.425712\n",
            "Epoch 1 batch 200 g_loss : 0.409252\n",
            "Epoch 1 batch 201 d_loss : 0.416541\n",
            "Epoch 1 batch 201 g_loss : 0.402891\n",
            "Epoch 1 batch 202 d_loss : 0.416639\n",
            "Epoch 1 batch 202 g_loss : 0.409851\n",
            "Epoch 1 batch 203 d_loss : 0.424744\n",
            "Epoch 1 batch 203 g_loss : 0.401620\n",
            "Epoch 1 batch 204 d_loss : 0.391987\n",
            "Epoch 1 batch 204 g_loss : 0.395370\n",
            "Epoch 1 batch 205 d_loss : 0.492734\n",
            "Epoch 1 batch 205 g_loss : 0.420666\n",
            "Epoch 1 batch 206 d_loss : 0.393009\n",
            "Epoch 1 batch 206 g_loss : 0.399317\n",
            "Epoch 1 batch 207 d_loss : 0.533925\n",
            "Epoch 1 batch 207 g_loss : 0.406176\n",
            "Epoch 1 batch 208 d_loss : 0.501787\n",
            "Epoch 1 batch 208 g_loss : 0.388415\n",
            "Epoch 1 batch 209 d_loss : 0.447269\n",
            "Epoch 1 batch 209 g_loss : 0.379253\n",
            "Epoch 1 batch 210 d_loss : 0.430846\n",
            "Epoch 1 batch 210 g_loss : 0.392444\n",
            "Epoch 1 batch 211 d_loss : 0.480599\n",
            "Epoch 1 batch 211 g_loss : 0.408615\n",
            "Epoch 1 batch 212 d_loss : 0.489905\n",
            "Epoch 1 batch 212 g_loss : 0.393106\n",
            "Epoch 1 batch 213 d_loss : 0.517497\n",
            "Epoch 1 batch 213 g_loss : 0.376732\n",
            "Epoch 1 batch 214 d_loss : 0.532541\n",
            "Epoch 1 batch 214 g_loss : 0.361717\n",
            "Epoch 1 batch 215 d_loss : 0.498492\n",
            "Epoch 1 batch 215 g_loss : 0.342737\n",
            "Epoch 1 batch 216 d_loss : 0.425642\n",
            "Epoch 1 batch 216 g_loss : 0.336215\n",
            "Epoch 1 batch 217 d_loss : 0.477680\n",
            "Epoch 1 batch 217 g_loss : 0.341126\n",
            "Epoch 1 batch 218 d_loss : 0.453710\n",
            "Epoch 1 batch 218 g_loss : 0.334661\n",
            "Epoch 1 batch 219 d_loss : 0.468871\n",
            "Epoch 1 batch 219 g_loss : 0.342372\n",
            "Epoch 1 batch 220 d_loss : 0.539268\n",
            "Epoch 1 batch 220 g_loss : 0.338878\n",
            "Epoch 1 batch 221 d_loss : 0.461635\n",
            "Epoch 1 batch 221 g_loss : 0.331876\n",
            "Epoch 1 batch 222 d_loss : 0.459539\n",
            "Epoch 1 batch 222 g_loss : 0.323216\n",
            "Epoch 1 batch 223 d_loss : 0.460411\n",
            "Epoch 1 batch 223 g_loss : 0.346517\n",
            "Epoch 1 batch 224 d_loss : 0.471721\n",
            "Epoch 1 batch 224 g_loss : 0.315568\n",
            "Epoch 1 batch 225 d_loss : 0.442225\n",
            "Epoch 1 batch 225 g_loss : 0.318004\n",
            "Epoch 1 batch 226 d_loss : 0.483418\n",
            "Epoch 1 batch 226 g_loss : 0.313517\n",
            "Epoch 1 batch 227 d_loss : 0.460386\n",
            "Epoch 1 batch 227 g_loss : 0.317643\n",
            "Epoch 1 batch 228 d_loss : 0.411529\n",
            "Epoch 1 batch 228 g_loss : 0.318710\n",
            "Epoch 1 batch 229 d_loss : 0.514757\n",
            "Epoch 1 batch 229 g_loss : 0.325880\n",
            "Epoch 1 batch 230 d_loss : 0.578711\n",
            "Epoch 1 batch 230 g_loss : 0.339145\n",
            "Epoch 1 batch 231 d_loss : 0.485765\n",
            "Epoch 1 batch 231 g_loss : 0.325429\n",
            "Epoch 1 batch 232 d_loss : 0.507811\n",
            "Epoch 1 batch 232 g_loss : 0.322534\n",
            "Epoch 1 batch 233 d_loss : 0.470219\n",
            "Epoch 1 batch 233 g_loss : 0.325360\n",
            "Epoch 1 batch 234 d_loss : 0.397792\n",
            "Epoch 1 batch 234 g_loss : 0.312437\n",
            "Epoch 1 batch 235 d_loss : 0.374259\n",
            "Epoch 1 batch 235 g_loss : 0.320465\n",
            "Epoch 1 batch 236 d_loss : 0.387500\n",
            "Epoch 1 batch 236 g_loss : 0.336787\n",
            "Epoch 1 batch 237 d_loss : 0.412583\n",
            "Epoch 1 batch 237 g_loss : 0.333437\n",
            "Epoch 1 batch 238 d_loss : 0.378516\n",
            "Epoch 1 batch 238 g_loss : 0.334518\n",
            "Epoch 1 batch 239 d_loss : 0.448663\n",
            "Epoch 1 batch 239 g_loss : 0.345492\n",
            "Epoch 1 batch 240 d_loss : 0.476322\n",
            "Epoch 1 batch 240 g_loss : 0.387116\n",
            "Epoch 1 batch 241 d_loss : 0.404973\n",
            "Epoch 1 batch 241 g_loss : 0.377964\n",
            "Epoch 1 batch 242 d_loss : 0.470291\n",
            "Epoch 1 batch 242 g_loss : 0.353127\n",
            "Epoch 1 batch 243 d_loss : 0.434510\n",
            "Epoch 1 batch 243 g_loss : 0.349678\n",
            "Epoch 1 batch 244 d_loss : 0.427845\n",
            "Epoch 1 batch 244 g_loss : 0.384678\n",
            "Epoch 1 batch 245 d_loss : 0.439975\n",
            "Epoch 1 batch 245 g_loss : 0.379538\n",
            "Epoch 1 batch 246 d_loss : 0.489013\n",
            "Epoch 1 batch 246 g_loss : 0.342635\n",
            "Epoch 1 batch 247 d_loss : 0.437885\n",
            "Epoch 1 batch 247 g_loss : 0.348866\n",
            "Epoch 1 batch 248 d_loss : 0.432389\n",
            "Epoch 1 batch 248 g_loss : 0.325921\n",
            "Epoch 1 batch 249 d_loss : 0.443719\n",
            "Epoch 1 batch 249 g_loss : 0.313376\n",
            "Epoch 1 batch 250 d_loss : 0.587571\n",
            "Epoch 1 batch 250 g_loss : 0.299386\n",
            "Epoch 1 batch 251 d_loss : 0.547888\n",
            "Epoch 1 batch 251 g_loss : 0.275708\n",
            "Epoch 1 batch 252 d_loss : 0.541318\n",
            "Epoch 1 batch 252 g_loss : 0.267263\n",
            "Epoch 1 batch 253 d_loss : 0.618012\n",
            "Epoch 1 batch 253 g_loss : 0.269786\n",
            "Epoch 1 batch 254 d_loss : 0.533044\n",
            "Epoch 1 batch 254 g_loss : 0.253528\n",
            "Epoch 1 batch 255 d_loss : 0.422811\n",
            "Epoch 1 batch 255 g_loss : 0.279182\n",
            "Epoch 1 batch 256 d_loss : 0.441273\n",
            "Epoch 1 batch 256 g_loss : 0.323874\n",
            "Epoch 1 batch 257 d_loss : 0.390059\n",
            "Epoch 1 batch 257 g_loss : 0.326881\n",
            "Epoch 1 batch 258 d_loss : 0.424717\n",
            "Epoch 1 batch 258 g_loss : 0.352437\n",
            "Epoch 1 batch 259 d_loss : 0.455249\n",
            "Epoch 1 batch 259 g_loss : 0.350178\n",
            "Epoch 1 batch 260 d_loss : 0.471417\n",
            "Epoch 1 batch 260 g_loss : 0.353943\n",
            "Epoch 1 batch 261 d_loss : 0.390704\n",
            "Epoch 1 batch 261 g_loss : 0.353234\n",
            "Epoch 1 batch 262 d_loss : 0.491460\n",
            "Epoch 1 batch 262 g_loss : 0.349108\n",
            "Epoch 1 batch 263 d_loss : 0.462721\n",
            "Epoch 1 batch 263 g_loss : 0.354610\n",
            "Epoch 1 batch 264 d_loss : 0.410040\n",
            "Epoch 1 batch 264 g_loss : 0.357308\n",
            "Epoch 1 batch 265 d_loss : 0.457720\n",
            "Epoch 1 batch 265 g_loss : 0.357051\n",
            "Epoch 1 batch 266 d_loss : 0.439113\n",
            "Epoch 1 batch 266 g_loss : 0.344185\n",
            "Epoch 1 batch 267 d_loss : 0.472349\n",
            "Epoch 1 batch 267 g_loss : 0.367275\n",
            "Epoch 1 batch 268 d_loss : 0.542758\n",
            "Epoch 1 batch 268 g_loss : 0.362433\n",
            "Epoch 1 batch 269 d_loss : 0.420792\n",
            "Epoch 1 batch 269 g_loss : 0.361658\n",
            "Epoch 1 batch 270 d_loss : 0.484916\n",
            "Epoch 1 batch 270 g_loss : 0.389831\n",
            "Epoch 1 batch 271 d_loss : 0.418110\n",
            "Epoch 1 batch 271 g_loss : 0.435281\n",
            "Epoch 1 batch 272 d_loss : 0.424612\n",
            "Epoch 1 batch 272 g_loss : 0.382851\n",
            "Epoch 1 batch 273 d_loss : 0.429050\n",
            "Epoch 1 batch 273 g_loss : 0.385764\n",
            "Epoch 1 batch 274 d_loss : 0.420845\n",
            "Epoch 1 batch 274 g_loss : 0.376326\n",
            "Epoch 1 batch 275 d_loss : 0.539112\n",
            "Epoch 1 batch 275 g_loss : 0.337561\n",
            "Epoch 1 batch 276 d_loss : 0.478680\n",
            "Epoch 1 batch 276 g_loss : 0.350488\n",
            "Epoch 1 batch 277 d_loss : 0.511137\n",
            "Epoch 1 batch 277 g_loss : 0.347952\n",
            "Epoch 1 batch 278 d_loss : 0.561164\n",
            "Epoch 1 batch 278 g_loss : 0.350577\n",
            "Epoch 1 batch 279 d_loss : 0.474244\n",
            "Epoch 1 batch 279 g_loss : 0.329152\n",
            "Epoch 1 batch 280 d_loss : 0.596590\n",
            "Epoch 1 batch 280 g_loss : 0.354376\n",
            "Epoch 1 batch 281 d_loss : 0.546010\n",
            "Epoch 1 batch 281 g_loss : 0.380826\n",
            "Epoch 1 batch 282 d_loss : 0.509167\n",
            "Epoch 1 batch 282 g_loss : 0.396501\n",
            "Epoch 1 batch 283 d_loss : 0.496454\n",
            "Epoch 1 batch 283 g_loss : 0.390988\n",
            "Epoch 1 batch 284 d_loss : 0.507913\n",
            "Epoch 1 batch 284 g_loss : 0.422344\n",
            "Epoch 1 batch 285 d_loss : 0.547273\n",
            "Epoch 1 batch 285 g_loss : 0.492587\n",
            "Epoch 1 batch 286 d_loss : 0.499132\n",
            "Epoch 1 batch 286 g_loss : 0.496564\n",
            "Epoch 1 batch 287 d_loss : 0.487847\n",
            "Epoch 1 batch 287 g_loss : 0.492423\n",
            "Epoch 1 batch 288 d_loss : 0.464497\n",
            "Epoch 1 batch 288 g_loss : 0.515996\n",
            "Epoch 1 batch 289 d_loss : 0.507899\n",
            "Epoch 1 batch 289 g_loss : 0.429737\n",
            "Epoch 1 batch 290 d_loss : 0.508207\n",
            "Epoch 1 batch 290 g_loss : 0.412270\n",
            "Epoch 1 batch 291 d_loss : 0.516765\n",
            "Epoch 1 batch 291 g_loss : 0.376299\n",
            "Epoch 1 batch 292 d_loss : 0.485285\n",
            "Epoch 1 batch 292 g_loss : 0.357464\n",
            "Epoch 1 batch 293 d_loss : 0.454974\n",
            "Epoch 1 batch 293 g_loss : 0.357458\n",
            "Epoch 1 batch 294 d_loss : 0.433900\n",
            "Epoch 1 batch 294 g_loss : 0.355976\n",
            "Epoch 1 batch 295 d_loss : 0.456801\n",
            "Epoch 1 batch 295 g_loss : 0.365611\n",
            "Epoch 1 batch 296 d_loss : 0.460193\n",
            "Epoch 1 batch 296 g_loss : 0.398352\n",
            "Epoch 1 batch 297 d_loss : 0.456410\n",
            "Epoch 1 batch 297 g_loss : 0.433706\n",
            "Epoch 1 batch 298 d_loss : 0.442267\n",
            "Epoch 1 batch 298 g_loss : 0.552487\n",
            "Epoch 1 batch 299 d_loss : 0.445930\n",
            "Epoch 1 batch 299 g_loss : 0.558705\n",
            "Epoch 1 batch 300 d_loss : 0.492864\n",
            "Epoch 1 batch 300 g_loss : 0.563597\n",
            "Epoch 1 batch 301 d_loss : 0.484875\n",
            "Epoch 1 batch 301 g_loss : 0.547098\n",
            "Epoch 1 batch 302 d_loss : 0.465996\n",
            "Epoch 1 batch 302 g_loss : 0.505969\n",
            "Epoch 1 batch 303 d_loss : 0.483578\n",
            "Epoch 1 batch 303 g_loss : 0.509769\n",
            "Epoch 1 batch 304 d_loss : 0.444772\n",
            "Epoch 1 batch 304 g_loss : 0.458077\n",
            "Epoch 1 batch 305 d_loss : 0.519446\n",
            "Epoch 1 batch 305 g_loss : 0.451203\n",
            "Epoch 1 batch 306 d_loss : 0.555698\n",
            "Epoch 1 batch 306 g_loss : 0.532396\n",
            "Epoch 1 batch 307 d_loss : 0.533909\n",
            "Epoch 1 batch 307 g_loss : 0.505359\n",
            "Epoch 1 batch 308 d_loss : 0.536563\n",
            "Epoch 1 batch 308 g_loss : 0.481593\n",
            "Epoch 1 batch 309 d_loss : 0.505511\n",
            "Epoch 1 batch 309 g_loss : 0.425747\n",
            "Epoch 1 batch 310 d_loss : 0.492909\n",
            "Epoch 1 batch 310 g_loss : 0.386091\n",
            "Epoch 1 batch 311 d_loss : 0.484223\n",
            "Epoch 1 batch 311 g_loss : 0.388296\n",
            "Epoch 1 batch 312 d_loss : 0.473500\n",
            "Epoch 1 batch 312 g_loss : 0.390489\n",
            "Epoch 1 batch 313 d_loss : 0.479733\n",
            "Epoch 1 batch 313 g_loss : 0.403773\n",
            "Epoch 1 batch 314 d_loss : 0.486711\n",
            "Epoch 1 batch 314 g_loss : 0.421167\n",
            "Epoch 1 batch 315 d_loss : 0.465577\n",
            "Epoch 1 batch 315 g_loss : 0.444312\n",
            "Epoch 1 batch 316 d_loss : 0.448735\n",
            "Epoch 1 batch 316 g_loss : 0.444138\n",
            "Epoch 1 batch 317 d_loss : 0.460383\n",
            "Epoch 1 batch 317 g_loss : 0.456623\n",
            "Epoch 1 batch 318 d_loss : 0.465357\n",
            "Epoch 1 batch 318 g_loss : 0.487526\n",
            "Epoch 1 batch 319 d_loss : 0.488724\n",
            "Epoch 1 batch 319 g_loss : 0.480151\n",
            "Epoch 1 batch 320 d_loss : 0.441191\n",
            "Epoch 1 batch 320 g_loss : 0.473217\n",
            "Epoch 1 batch 321 d_loss : 0.497326\n",
            "Epoch 1 batch 321 g_loss : 0.496874\n",
            "Epoch 1 batch 322 d_loss : 0.453318\n",
            "Epoch 1 batch 322 g_loss : 0.535025\n",
            "Epoch 1 batch 323 d_loss : 0.431304\n",
            "Epoch 1 batch 323 g_loss : 0.566497\n",
            "Epoch 1 batch 324 d_loss : 0.440753\n",
            "Epoch 1 batch 324 g_loss : 0.552591\n",
            "Epoch 1 batch 325 d_loss : 0.493933\n",
            "Epoch 1 batch 325 g_loss : 0.559889\n",
            "Epoch 1 batch 326 d_loss : 0.487440\n",
            "Epoch 1 batch 326 g_loss : 0.580186\n",
            "Epoch 1 batch 327 d_loss : 0.477550\n",
            "Epoch 1 batch 327 g_loss : 0.576123\n",
            "Epoch 1 batch 328 d_loss : 0.561275\n",
            "Epoch 1 batch 328 g_loss : 0.568128\n",
            "Epoch 1 batch 329 d_loss : 0.506224\n",
            "Epoch 1 batch 329 g_loss : 0.555302\n",
            "Epoch 1 batch 330 d_loss : 0.490013\n",
            "Epoch 1 batch 330 g_loss : 0.533096\n",
            "Epoch 1 batch 331 d_loss : 0.486542\n",
            "Epoch 1 batch 331 g_loss : 0.522526\n",
            "Epoch 1 batch 332 d_loss : 0.482015\n",
            "Epoch 1 batch 332 g_loss : 0.506905\n",
            "Epoch 1 batch 333 d_loss : 0.485785\n",
            "Epoch 1 batch 333 g_loss : 0.496333\n",
            "Epoch 1 batch 334 d_loss : 0.521797\n",
            "Epoch 1 batch 334 g_loss : 0.479632\n",
            "Epoch 1 batch 335 d_loss : 0.477624\n",
            "Epoch 1 batch 335 g_loss : 0.471505\n",
            "Epoch 1 batch 336 d_loss : 0.514158\n",
            "Epoch 1 batch 336 g_loss : 0.459332\n",
            "Epoch 1 batch 337 d_loss : 0.499333\n",
            "Epoch 1 batch 337 g_loss : 0.455141\n",
            "Epoch 1 batch 338 d_loss : 0.479634\n",
            "Epoch 1 batch 338 g_loss : 0.452490\n",
            "Epoch 1 batch 339 d_loss : 0.445453\n",
            "Epoch 1 batch 339 g_loss : 0.450788\n",
            "Epoch 1 batch 340 d_loss : 0.465170\n",
            "Epoch 1 batch 340 g_loss : 0.453537\n",
            "Epoch 1 batch 341 d_loss : 0.500223\n",
            "Epoch 1 batch 341 g_loss : 0.462499\n",
            "Epoch 1 batch 342 d_loss : 0.471741\n",
            "Epoch 1 batch 342 g_loss : 0.472878\n",
            "Epoch 1 batch 343 d_loss : 0.478916\n",
            "Epoch 1 batch 343 g_loss : 0.480565\n",
            "Epoch 1 batch 344 d_loss : 0.475914\n",
            "Epoch 1 batch 344 g_loss : 0.487793\n",
            "Epoch 1 batch 345 d_loss : 0.470557\n",
            "Epoch 1 batch 345 g_loss : 0.487644\n",
            "Epoch 1 batch 346 d_loss : 0.478310\n",
            "Epoch 1 batch 346 g_loss : 0.496709\n",
            "Epoch 1 batch 347 d_loss : 0.506066\n",
            "Epoch 1 batch 347 g_loss : 0.506874\n",
            "Epoch 1 batch 348 d_loss : 0.497744\n",
            "Epoch 1 batch 348 g_loss : 0.517247\n",
            "Epoch 1 batch 349 d_loss : 0.472189\n",
            "Epoch 1 batch 349 g_loss : 0.516762\n",
            "Epoch 1 batch 350 d_loss : 0.470372\n",
            "Epoch 1 batch 350 g_loss : 0.523629\n",
            "Epoch 1 batch 351 d_loss : 0.505381\n",
            "Epoch 1 batch 351 g_loss : 0.529057\n",
            "Epoch 1 batch 352 d_loss : 0.479489\n",
            "Epoch 1 batch 352 g_loss : 0.531287\n",
            "Epoch 1 batch 353 d_loss : 0.473649\n",
            "Epoch 1 batch 353 g_loss : 0.538199\n",
            "Epoch 1 batch 354 d_loss : 0.484546\n",
            "Epoch 1 batch 354 g_loss : 0.543847\n",
            "Epoch 1 batch 355 d_loss : 0.465467\n",
            "Epoch 1 batch 355 g_loss : 0.551968\n",
            "Epoch 1 batch 356 d_loss : 0.452646\n",
            "Epoch 1 batch 356 g_loss : 0.556366\n",
            "Epoch 1 batch 357 d_loss : 0.459628\n",
            "Epoch 1 batch 357 g_loss : 0.559209\n",
            "Epoch 1 batch 358 d_loss : 0.461335\n",
            "Epoch 1 batch 358 g_loss : 0.549046\n",
            "Epoch 1 batch 359 d_loss : 0.460120\n",
            "Epoch 1 batch 359 g_loss : 0.544186\n",
            "Epoch 1 batch 360 d_loss : 0.463400\n",
            "Epoch 1 batch 360 g_loss : 0.546258\n",
            "Epoch 1 batch 361 d_loss : 0.476343\n",
            "Epoch 1 batch 361 g_loss : 0.540644\n",
            "Epoch 1 batch 362 d_loss : 0.456369\n",
            "Epoch 1 batch 362 g_loss : 0.548513\n",
            "Epoch 1 batch 363 d_loss : 0.460643\n",
            "Epoch 1 batch 363 g_loss : 0.542952\n",
            "Epoch 1 batch 364 d_loss : 0.466074\n",
            "Epoch 1 batch 364 g_loss : 0.535006\n",
            "Epoch 1 batch 365 d_loss : 0.458210\n",
            "Epoch 1 batch 365 g_loss : 0.524565\n",
            "Epoch 1 batch 366 d_loss : 0.455630\n",
            "Epoch 1 batch 366 g_loss : 0.517120\n",
            "Epoch 1 batch 367 d_loss : 0.453653\n",
            "Epoch 1 batch 367 g_loss : 0.514139\n",
            "Epoch 1 batch 368 d_loss : 0.446973\n",
            "Epoch 1 batch 368 g_loss : 0.510471\n",
            "Epoch 1 batch 369 d_loss : 0.481902\n",
            "Epoch 1 batch 369 g_loss : 0.505168\n",
            "Epoch 1 batch 370 d_loss : 0.469765\n",
            "Epoch 1 batch 370 g_loss : 0.504320\n",
            "Epoch 1 batch 371 d_loss : 0.464943\n",
            "Epoch 1 batch 371 g_loss : 0.504463\n",
            "Epoch 1 batch 372 d_loss : 0.469920\n",
            "Epoch 1 batch 372 g_loss : 0.510222\n",
            "Epoch 1 batch 373 d_loss : 0.466377\n",
            "Epoch 1 batch 373 g_loss : 0.511635\n",
            "Epoch 1 batch 374 d_loss : 0.469933\n",
            "Epoch 1 batch 374 g_loss : 0.510577\n",
            "Epoch 1 batch 375 d_loss : 0.467679\n",
            "Epoch 1 batch 375 g_loss : 0.508671\n",
            "Epoch 1 batch 376 d_loss : 0.469784\n",
            "Epoch 1 batch 376 g_loss : 0.511979\n",
            "Epoch 1 batch 377 d_loss : 0.446291\n",
            "Epoch 1 batch 377 g_loss : 0.512304\n",
            "Epoch 1 batch 378 d_loss : 0.456464\n",
            "Epoch 1 batch 378 g_loss : 0.518012\n",
            "Epoch 1 batch 379 d_loss : 0.463161\n",
            "Epoch 1 batch 379 g_loss : 0.518350\n",
            "Epoch 1 batch 380 d_loss : 0.462635\n",
            "Epoch 1 batch 380 g_loss : 0.520264\n",
            "Epoch 1 batch 381 d_loss : 0.454427\n",
            "Epoch 1 batch 381 g_loss : 0.521688\n",
            "Epoch 1 batch 382 d_loss : 0.450962\n",
            "Epoch 1 batch 382 g_loss : 0.524339\n",
            "Epoch 1 batch 383 d_loss : 0.469416\n",
            "Epoch 1 batch 383 g_loss : 0.527110\n",
            "Epoch 1 batch 384 d_loss : 0.484981\n",
            "Epoch 1 batch 384 g_loss : 0.535565\n",
            "Epoch 1 batch 385 d_loss : 0.480414\n",
            "Epoch 1 batch 385 g_loss : 0.534924\n",
            "Epoch 1 batch 386 d_loss : 0.497395\n",
            "Epoch 1 batch 386 g_loss : 0.531159\n",
            "Epoch 1 batch 387 d_loss : 0.480051\n",
            "Epoch 1 batch 387 g_loss : 0.528671\n",
            "Epoch 1 batch 388 d_loss : 0.471630\n",
            "Epoch 1 batch 388 g_loss : 0.524850\n",
            "Epoch 1 batch 389 d_loss : 0.468724\n",
            "Epoch 1 batch 389 g_loss : 0.521188\n",
            "Epoch 1 batch 390 d_loss : 0.456719\n",
            "Epoch 1 batch 390 g_loss : 0.522003\n",
            "Epoch 1 batch 391 d_loss : 0.459101\n",
            "Epoch 1 batch 391 g_loss : 0.524880\n",
            "Epoch 1 batch 392 d_loss : 0.452674\n",
            "Epoch 1 batch 392 g_loss : 0.523440\n",
            "Epoch 1 batch 393 d_loss : 0.452815\n",
            "Epoch 1 batch 393 g_loss : 0.520169\n",
            "Epoch 1 batch 394 d_loss : 0.458352\n",
            "Epoch 1 batch 394 g_loss : 0.519788\n",
            "Epoch 1 batch 395 d_loss : 0.449828\n",
            "Epoch 1 batch 395 g_loss : 0.522861\n",
            "Epoch 1 batch 396 d_loss : 0.458609\n",
            "Epoch 1 batch 396 g_loss : 0.520199\n",
            "Epoch 1 batch 397 d_loss : 0.457768\n",
            "Epoch 1 batch 397 g_loss : 0.523735\n",
            "Epoch 1 batch 398 d_loss : 0.456375\n",
            "Epoch 1 batch 398 g_loss : 0.529112\n",
            "Epoch 1 batch 399 d_loss : 0.457836\n",
            "Epoch 1 batch 399 g_loss : 0.531252\n",
            "Epoch 1 batch 400 d_loss : 0.468218\n",
            "Epoch 1 batch 400 g_loss : 0.535734\n",
            "Epoch 1 batch 401 d_loss : 0.481702\n",
            "Epoch 1 batch 401 g_loss : 0.540535\n",
            "Epoch 1 batch 402 d_loss : 0.468521\n",
            "Epoch 1 batch 402 g_loss : 0.544520\n",
            "Epoch 1 batch 403 d_loss : 0.459421\n",
            "Epoch 1 batch 403 g_loss : 0.551514\n",
            "Epoch 1 batch 404 d_loss : 0.466172\n",
            "Epoch 1 batch 404 g_loss : 0.552627\n",
            "Epoch 1 batch 405 d_loss : 0.459686\n",
            "Epoch 1 batch 405 g_loss : 0.552382\n",
            "Epoch 1 batch 406 d_loss : 0.464724\n",
            "Epoch 1 batch 406 g_loss : 0.551789\n",
            "Epoch 1 batch 407 d_loss : 0.461024\n",
            "Epoch 1 batch 407 g_loss : 0.545348\n",
            "Epoch 1 batch 408 d_loss : 0.451307\n",
            "Epoch 1 batch 408 g_loss : 0.524185\n",
            "Epoch 1 batch 409 d_loss : 0.453735\n",
            "Epoch 1 batch 409 g_loss : 0.523598\n",
            "Epoch 1 batch 410 d_loss : 0.460591\n",
            "Epoch 1 batch 410 g_loss : 0.518986\n",
            "Epoch 1 batch 411 d_loss : 0.455479\n",
            "Epoch 1 batch 411 g_loss : 0.520605\n",
            "Epoch 1 batch 412 d_loss : 0.461416\n",
            "Epoch 1 batch 412 g_loss : 0.521590\n",
            "Epoch 1 batch 413 d_loss : 0.459337\n",
            "Epoch 1 batch 413 g_loss : 0.521365\n",
            "Epoch 1 batch 414 d_loss : 0.465309\n",
            "Epoch 1 batch 414 g_loss : 0.526978\n",
            "Epoch 1 batch 415 d_loss : 0.452511\n",
            "Epoch 1 batch 415 g_loss : 0.534639\n",
            "Epoch 1 batch 416 d_loss : 0.458786\n",
            "Epoch 1 batch 416 g_loss : 0.550880\n",
            "Epoch 1 batch 417 d_loss : 0.453481\n",
            "Epoch 1 batch 417 g_loss : 0.552823\n",
            "Epoch 1 batch 418 d_loss : 0.456821\n",
            "Epoch 1 batch 418 g_loss : 0.532175\n",
            "Epoch 1 batch 419 d_loss : 0.440688\n",
            "Epoch 1 batch 419 g_loss : 0.523879\n",
            "Epoch 1 batch 420 d_loss : 0.441738\n",
            "Epoch 1 batch 420 g_loss : 0.548341\n",
            "Epoch 1 batch 421 d_loss : 0.462550\n",
            "Epoch 1 batch 421 g_loss : 0.647215\n",
            "Epoch 1 batch 422 d_loss : 0.472894\n",
            "Epoch 1 batch 422 g_loss : 0.662767\n",
            "Epoch 1 batch 423 d_loss : 0.486838\n",
            "Epoch 1 batch 423 g_loss : 0.665092\n",
            "Epoch 1 batch 424 d_loss : 0.474071\n",
            "Epoch 1 batch 424 g_loss : 0.648697\n",
            "Epoch 1 batch 425 d_loss : 0.488468\n",
            "Epoch 1 batch 425 g_loss : 0.642862\n",
            "Epoch 1 batch 426 d_loss : 0.487919\n",
            "Epoch 1 batch 426 g_loss : 0.635264\n",
            "Epoch 1 batch 427 d_loss : 0.480249\n",
            "Epoch 1 batch 427 g_loss : 0.614077\n",
            "Epoch 1 batch 428 d_loss : 0.474938\n",
            "Epoch 1 batch 428 g_loss : 0.565037\n",
            "Epoch 1 batch 429 d_loss : 0.479406\n",
            "Epoch 1 batch 429 g_loss : 0.551584\n",
            "Epoch 1 batch 430 d_loss : 0.463492\n",
            "Epoch 1 batch 430 g_loss : 0.532409\n",
            "Epoch 1 batch 431 d_loss : 0.488103\n",
            "Epoch 1 batch 431 g_loss : 0.528119\n",
            "Epoch 1 batch 432 d_loss : 0.474313\n",
            "Epoch 1 batch 432 g_loss : 0.529915\n",
            "Epoch 1 batch 433 d_loss : 0.461940\n",
            "Epoch 1 batch 433 g_loss : 0.514992\n",
            "Epoch 1 batch 434 d_loss : 0.470298\n",
            "Epoch 1 batch 434 g_loss : 0.516100\n",
            "Epoch 1 batch 435 d_loss : 0.462901\n",
            "Epoch 1 batch 435 g_loss : 0.518390\n",
            "Epoch 1 batch 436 d_loss : 0.458873\n",
            "Epoch 1 batch 436 g_loss : 0.530634\n",
            "Epoch 1 batch 437 d_loss : 0.458635\n",
            "Epoch 1 batch 437 g_loss : 0.534739\n",
            "Epoch 1 batch 438 d_loss : 0.471674\n",
            "Epoch 1 batch 438 g_loss : 0.565735\n",
            "Epoch 1 batch 439 d_loss : 0.466813\n",
            "Epoch 1 batch 439 g_loss : 0.576658\n",
            "Epoch 1 batch 440 d_loss : 0.464131\n",
            "Epoch 1 batch 440 g_loss : 0.577982\n",
            "Epoch 1 batch 441 d_loss : 0.454978\n",
            "Epoch 1 batch 441 g_loss : 0.587937\n",
            "Epoch 1 batch 442 d_loss : 0.460844\n",
            "Epoch 1 batch 442 g_loss : 0.591916\n",
            "Epoch 1 batch 443 d_loss : 0.446460\n",
            "Epoch 1 batch 443 g_loss : 0.580838\n",
            "Epoch 1 batch 444 d_loss : 0.450159\n",
            "Epoch 1 batch 444 g_loss : 0.585451\n",
            "Epoch 1 batch 445 d_loss : 0.459788\n",
            "Epoch 1 batch 445 g_loss : 0.594509\n",
            "Epoch 1 batch 446 d_loss : 0.457831\n",
            "Epoch 1 batch 446 g_loss : 0.594904\n",
            "Epoch 1 batch 447 d_loss : 0.453488\n",
            "Epoch 1 batch 447 g_loss : 0.575616\n",
            "Epoch 1 batch 448 d_loss : 0.457122\n",
            "Epoch 1 batch 448 g_loss : 0.526158\n",
            "Epoch 1 batch 449 d_loss : 0.452647\n",
            "Epoch 1 batch 449 g_loss : 0.533163\n",
            "Epoch 1 batch 450 d_loss : 0.443829\n",
            "Epoch 1 batch 450 g_loss : 0.602094\n",
            "Epoch 1 batch 451 d_loss : 0.462964\n",
            "Epoch 1 batch 451 g_loss : 0.596521\n",
            "Epoch 1 batch 452 d_loss : 0.474753\n",
            "Epoch 1 batch 452 g_loss : 0.597804\n",
            "Epoch 1 batch 453 d_loss : 0.490935\n",
            "Epoch 1 batch 453 g_loss : 0.608297\n",
            "Epoch 1 batch 454 d_loss : 0.464090\n",
            "Epoch 1 batch 454 g_loss : 0.569997\n",
            "Epoch 1 batch 455 d_loss : 0.448558\n",
            "Epoch 1 batch 455 g_loss : 0.577285\n",
            "Epoch 1 batch 456 d_loss : 0.431848\n",
            "Epoch 1 batch 456 g_loss : 0.498594\n",
            "Epoch 1 batch 457 d_loss : 0.390774\n",
            "Epoch 1 batch 457 g_loss : 0.448703\n",
            "Epoch 1 batch 458 d_loss : 0.409026\n",
            "Epoch 1 batch 458 g_loss : 0.470556\n",
            "Epoch 1 batch 459 d_loss : 0.394387\n",
            "Epoch 1 batch 459 g_loss : 0.478549\n",
            "Epoch 1 batch 460 d_loss : 0.415173\n",
            "Epoch 1 batch 460 g_loss : 0.507010\n",
            "Epoch 1 batch 461 d_loss : 0.392494\n",
            "Epoch 1 batch 461 g_loss : 0.509523\n",
            "Epoch 1 batch 462 d_loss : 0.402451\n",
            "Epoch 1 batch 462 g_loss : 0.512464\n",
            "Epoch 1 batch 463 d_loss : 0.376626\n",
            "Epoch 1 batch 463 g_loss : 0.541144\n",
            "Epoch 1 batch 464 d_loss : 0.371191\n",
            "Epoch 1 batch 464 g_loss : 0.511403\n",
            "Epoch 1 batch 465 d_loss : 0.378013\n",
            "Epoch 1 batch 465 g_loss : 0.530341\n",
            "Epoch 1 batch 466 d_loss : 0.504380\n",
            "Epoch 1 batch 466 g_loss : 0.650153\n",
            "Epoch 1 batch 467 d_loss : 0.481302\n",
            "Epoch 1 batch 467 g_loss : 0.689314\n",
            "Epoch 1 batch 468 d_loss : 0.481625\n",
            "Epoch 1 batch 468 g_loss : 0.590984\n",
            "Epoch 1 batch 469 d_loss : 0.490526\n",
            "Epoch 1 batch 469 g_loss : 0.478659\n",
            "Epoch 1 batch 470 d_loss : 0.435959\n",
            "Epoch 1 batch 470 g_loss : 0.407809\n",
            "Epoch 1 batch 471 d_loss : 0.473380\n",
            "Epoch 1 batch 471 g_loss : 0.465580\n",
            "Epoch 1 batch 472 d_loss : 0.443489\n",
            "Epoch 1 batch 472 g_loss : 0.496099\n",
            "Epoch 1 batch 473 d_loss : 0.455786\n",
            "Epoch 1 batch 473 g_loss : 0.577949\n",
            "Epoch 1 batch 474 d_loss : 0.486562\n",
            "Epoch 1 batch 474 g_loss : 0.719905\n",
            "Epoch 1 batch 475 d_loss : 0.510353\n",
            "Epoch 1 batch 475 g_loss : 0.807921\n",
            "Epoch 1 batch 476 d_loss : 0.492207\n",
            "Epoch 1 batch 476 g_loss : 0.769080\n",
            "Epoch 1 batch 477 d_loss : 0.485633\n",
            "Epoch 1 batch 477 g_loss : 0.746100\n",
            "Epoch 1 batch 478 d_loss : 0.470170\n",
            "Epoch 1 batch 478 g_loss : 0.678691\n",
            "Epoch 1 batch 479 d_loss : 0.467080\n",
            "Epoch 1 batch 479 g_loss : 0.631713\n",
            "Epoch 1 batch 480 d_loss : 0.473377\n",
            "Epoch 1 batch 480 g_loss : 0.607473\n",
            "Epoch 1 batch 481 d_loss : 0.461823\n",
            "Epoch 1 batch 481 g_loss : 0.584832\n",
            "Epoch 1 batch 482 d_loss : 0.478497\n",
            "Epoch 1 batch 482 g_loss : 0.586859\n",
            "Epoch 1 batch 483 d_loss : 0.451229\n",
            "Epoch 1 batch 483 g_loss : 0.585399\n",
            "Epoch 1 batch 484 d_loss : 0.476059\n",
            "Epoch 1 batch 484 g_loss : 0.574671\n",
            "Epoch 1 batch 485 d_loss : 0.458133\n",
            "Epoch 1 batch 485 g_loss : 0.570913\n",
            "Epoch 1 batch 486 d_loss : 0.452967\n",
            "Epoch 1 batch 486 g_loss : 0.584421\n",
            "Epoch 1 batch 487 d_loss : 0.443219\n",
            "Epoch 1 batch 487 g_loss : 0.581446\n",
            "Epoch 1 batch 488 d_loss : 0.461757\n",
            "Epoch 1 batch 488 g_loss : 0.513174\n",
            "Epoch 1 batch 489 d_loss : 0.473792\n",
            "Epoch 1 batch 489 g_loss : 0.534696\n",
            "Epoch 1 batch 490 d_loss : 0.471319\n",
            "Epoch 1 batch 490 g_loss : 0.570257\n",
            "Epoch 1 batch 491 d_loss : 0.467818\n",
            "Epoch 1 batch 491 g_loss : 0.566342\n",
            "Epoch 1 batch 492 d_loss : 0.484049\n",
            "Epoch 1 batch 492 g_loss : 0.571214\n",
            "Epoch 1 batch 493 d_loss : 0.485342\n",
            "Epoch 1 batch 493 g_loss : 0.570618\n",
            "Epoch 1 batch 494 d_loss : 0.487448\n",
            "Epoch 1 batch 494 g_loss : 0.571612\n",
            "Epoch 1 batch 495 d_loss : 0.475312\n",
            "Epoch 1 batch 495 g_loss : 0.569089\n",
            "Epoch 1 batch 496 d_loss : 0.466933\n",
            "Epoch 1 batch 496 g_loss : 0.560288\n",
            "Epoch 1 batch 497 d_loss : 0.469344\n",
            "Epoch 1 batch 497 g_loss : 0.560173\n",
            "Epoch 1 batch 498 d_loss : 0.448953\n",
            "Epoch 1 batch 498 g_loss : 0.546740\n",
            "Epoch 1 batch 499 d_loss : 0.453799\n",
            "Epoch 1 batch 499 g_loss : 0.549030\n",
            "Epoch 1 batch 500 d_loss : 0.448777\n",
            "Epoch 1 batch 500 g_loss : 0.514761\n",
            "Epoch 1 batch 501 d_loss : 0.449773\n",
            "Epoch 1 batch 501 g_loss : 0.518030\n",
            "Epoch 1 batch 502 d_loss : 0.445049\n",
            "Epoch 1 batch 502 g_loss : 0.510811\n",
            "Epoch 1 batch 503 d_loss : 0.464623\n",
            "Epoch 1 batch 503 g_loss : 0.557411\n",
            "Epoch 1 batch 504 d_loss : 0.455610\n",
            "Epoch 1 batch 504 g_loss : 0.545194\n",
            "Epoch 1 batch 505 d_loss : 0.453838\n",
            "Epoch 1 batch 505 g_loss : 0.530926\n",
            "Epoch 1 batch 506 d_loss : 0.448797\n",
            "Epoch 1 batch 506 g_loss : 0.511234\n",
            "Epoch 1 batch 507 d_loss : 0.465056\n",
            "Epoch 1 batch 507 g_loss : 0.535575\n",
            "Epoch 1 batch 508 d_loss : 0.466935\n",
            "Epoch 1 batch 508 g_loss : 0.539362\n",
            "Epoch 1 batch 509 d_loss : 0.464758\n",
            "Epoch 1 batch 509 g_loss : 0.540506\n",
            "Epoch 1 batch 510 d_loss : 0.468920\n",
            "Epoch 1 batch 510 g_loss : 0.546172\n",
            "Epoch 2 batch 0 d_loss : 0.448918\n",
            "Epoch 2 batch 0 g_loss : 0.525837\n",
            "Epoch 2 batch 1 d_loss : 0.454621\n",
            "Epoch 2 batch 1 g_loss : 0.527902\n",
            "Epoch 2 batch 2 d_loss : 0.458022\n",
            "Epoch 2 batch 2 g_loss : 0.530366\n",
            "Epoch 2 batch 3 d_loss : 0.455136\n",
            "Epoch 2 batch 3 g_loss : 0.525645\n",
            "Epoch 2 batch 4 d_loss : 0.462159\n",
            "Epoch 2 batch 4 g_loss : 0.533118\n",
            "Epoch 2 batch 5 d_loss : 0.441004\n",
            "Epoch 2 batch 5 g_loss : 0.531702\n",
            "Epoch 2 batch 6 d_loss : 0.453670\n",
            "Epoch 2 batch 6 g_loss : 0.534857\n",
            "Epoch 2 batch 7 d_loss : 0.453671\n",
            "Epoch 2 batch 7 g_loss : 0.530434\n",
            "Epoch 2 batch 8 d_loss : 0.446901\n",
            "Epoch 2 batch 8 g_loss : 0.530816\n",
            "Epoch 2 batch 9 d_loss : 0.453387\n",
            "Epoch 2 batch 9 g_loss : 0.532686\n",
            "Epoch 2 batch 10 d_loss : 0.451591\n",
            "Epoch 2 batch 10 g_loss : 0.533799\n",
            "Epoch 2 batch 11 d_loss : 0.445884\n",
            "Epoch 2 batch 11 g_loss : 0.532349\n",
            "Epoch 2 batch 12 d_loss : 0.451241\n",
            "Epoch 2 batch 12 g_loss : 0.532736\n",
            "Epoch 2 batch 13 d_loss : 0.448678\n",
            "Epoch 2 batch 13 g_loss : 0.526956\n",
            "Epoch 2 batch 14 d_loss : 0.432686\n",
            "Epoch 2 batch 14 g_loss : 0.525580\n",
            "Epoch 2 batch 15 d_loss : 0.452275\n",
            "Epoch 2 batch 15 g_loss : 0.536910\n",
            "Epoch 2 batch 16 d_loss : 0.466489\n",
            "Epoch 2 batch 16 g_loss : 0.560452\n",
            "Epoch 2 batch 17 d_loss : 0.450472\n",
            "Epoch 2 batch 17 g_loss : 0.550739\n",
            "Epoch 2 batch 18 d_loss : 0.446009\n",
            "Epoch 2 batch 18 g_loss : 0.546331\n",
            "Epoch 2 batch 19 d_loss : 0.450965\n",
            "Epoch 2 batch 19 g_loss : 0.537884\n",
            "Epoch 2 batch 20 d_loss : 0.445548\n",
            "Epoch 2 batch 20 g_loss : 0.533502\n",
            "Epoch 2 batch 21 d_loss : 0.457601\n",
            "Epoch 2 batch 21 g_loss : 0.530506\n",
            "Epoch 2 batch 22 d_loss : 0.463819\n",
            "Epoch 2 batch 22 g_loss : 0.523936\n",
            "Epoch 2 batch 23 d_loss : 0.462858\n",
            "Epoch 2 batch 23 g_loss : 0.522550\n",
            "Epoch 2 batch 24 d_loss : 0.440142\n",
            "Epoch 2 batch 24 g_loss : 0.516627\n",
            "Epoch 2 batch 25 d_loss : 0.458633\n",
            "Epoch 2 batch 25 g_loss : 0.518114\n",
            "Epoch 2 batch 26 d_loss : 0.451563\n",
            "Epoch 2 batch 26 g_loss : 0.519100\n",
            "Epoch 2 batch 27 d_loss : 0.449587\n",
            "Epoch 2 batch 27 g_loss : 0.511906\n",
            "Epoch 2 batch 28 d_loss : 0.447194\n",
            "Epoch 2 batch 28 g_loss : 0.516377\n",
            "Epoch 2 batch 29 d_loss : 0.455287\n",
            "Epoch 2 batch 29 g_loss : 0.515702\n",
            "Epoch 2 batch 30 d_loss : 0.442143\n",
            "Epoch 2 batch 30 g_loss : 0.509865\n",
            "Epoch 2 batch 31 d_loss : 0.458361\n",
            "Epoch 2 batch 31 g_loss : 0.520962\n",
            "Epoch 2 batch 32 d_loss : 0.449713\n",
            "Epoch 2 batch 32 g_loss : 0.514539\n",
            "Epoch 2 batch 33 d_loss : 0.449219\n",
            "Epoch 2 batch 33 g_loss : 0.521174\n",
            "Epoch 2 batch 34 d_loss : 0.459485\n",
            "Epoch 2 batch 34 g_loss : 0.516923\n",
            "Epoch 2 batch 35 d_loss : 0.458006\n",
            "Epoch 2 batch 35 g_loss : 0.522749\n",
            "Epoch 2 batch 36 d_loss : 0.443726\n",
            "Epoch 2 batch 36 g_loss : 0.521142\n",
            "Epoch 2 batch 37 d_loss : 0.516176\n",
            "Epoch 2 batch 37 g_loss : 0.524812\n",
            "Epoch 2 batch 38 d_loss : 0.497358\n",
            "Epoch 2 batch 38 g_loss : 0.534518\n",
            "Epoch 2 batch 39 d_loss : 0.501953\n",
            "Epoch 2 batch 39 g_loss : 0.524662\n",
            "Epoch 2 batch 40 d_loss : 0.507924\n",
            "Epoch 2 batch 40 g_loss : 0.527893\n",
            "Epoch 2 batch 41 d_loss : 0.520719\n",
            "Epoch 2 batch 41 g_loss : 0.519633\n",
            "Epoch 2 batch 42 d_loss : 0.499291\n",
            "Epoch 2 batch 42 g_loss : 0.514717\n",
            "Epoch 2 batch 43 d_loss : 0.520342\n",
            "Epoch 2 batch 43 g_loss : 0.507788\n",
            "Epoch 2 batch 44 d_loss : 0.495738\n",
            "Epoch 2 batch 44 g_loss : 0.499311\n",
            "Epoch 2 batch 45 d_loss : 0.487692\n",
            "Epoch 2 batch 45 g_loss : 0.498139\n",
            "Epoch 2 batch 46 d_loss : 0.481410\n",
            "Epoch 2 batch 46 g_loss : 0.490965\n",
            "Epoch 2 batch 47 d_loss : 0.476555\n",
            "Epoch 2 batch 47 g_loss : 0.496048\n",
            "Epoch 2 batch 48 d_loss : 0.477170\n",
            "Epoch 2 batch 48 g_loss : 0.483015\n",
            "Epoch 2 batch 49 d_loss : 0.462553\n",
            "Epoch 2 batch 49 g_loss : 0.481689\n",
            "Epoch 2 batch 50 d_loss : 0.457500\n",
            "Epoch 2 batch 50 g_loss : 0.486540\n",
            "Epoch 2 batch 51 d_loss : 0.461059\n",
            "Epoch 2 batch 51 g_loss : 0.489011\n",
            "Epoch 2 batch 52 d_loss : 0.458224\n",
            "Epoch 2 batch 52 g_loss : 0.498450\n",
            "Epoch 2 batch 53 d_loss : 0.452380\n",
            "Epoch 2 batch 53 g_loss : 0.508754\n",
            "Epoch 2 batch 54 d_loss : 0.454992\n",
            "Epoch 2 batch 54 g_loss : 0.516664\n",
            "Epoch 2 batch 55 d_loss : 0.457112\n",
            "Epoch 2 batch 55 g_loss : 0.530658\n",
            "Epoch 2 batch 56 d_loss : 0.460755\n",
            "Epoch 2 batch 56 g_loss : 0.534265\n",
            "Epoch 2 batch 57 d_loss : 0.462269\n",
            "Epoch 2 batch 57 g_loss : 0.543291\n",
            "Epoch 2 batch 58 d_loss : 0.460467\n",
            "Epoch 2 batch 58 g_loss : 0.550811\n",
            "Epoch 2 batch 59 d_loss : 0.460209\n",
            "Epoch 2 batch 59 g_loss : 0.557584\n",
            "Epoch 2 batch 60 d_loss : 0.461100\n",
            "Epoch 2 batch 60 g_loss : 0.563429\n",
            "Epoch 2 batch 61 d_loss : 0.455342\n",
            "Epoch 2 batch 61 g_loss : 0.561476\n",
            "Epoch 2 batch 62 d_loss : 0.457916\n",
            "Epoch 2 batch 62 g_loss : 0.567414\n",
            "Epoch 2 batch 63 d_loss : 0.448532\n",
            "Epoch 2 batch 63 g_loss : 0.573450\n",
            "Epoch 2 batch 64 d_loss : 0.454071\n",
            "Epoch 2 batch 64 g_loss : 0.576001\n",
            "Epoch 2 batch 65 d_loss : 0.461239\n",
            "Epoch 2 batch 65 g_loss : 0.576709\n",
            "Epoch 2 batch 66 d_loss : 0.447716\n",
            "Epoch 2 batch 66 g_loss : 0.565479\n",
            "Epoch 2 batch 67 d_loss : 0.456981\n",
            "Epoch 2 batch 67 g_loss : 0.566582\n",
            "Epoch 2 batch 68 d_loss : 0.447997\n",
            "Epoch 2 batch 68 g_loss : 0.559203\n",
            "Epoch 2 batch 69 d_loss : 0.441720\n",
            "Epoch 2 batch 69 g_loss : 0.562933\n",
            "Epoch 2 batch 70 d_loss : 0.453685\n",
            "Epoch 2 batch 70 g_loss : 0.563642\n",
            "Epoch 2 batch 71 d_loss : 0.454700\n",
            "Epoch 2 batch 71 g_loss : 0.554746\n",
            "Epoch 2 batch 72 d_loss : 0.464566\n",
            "Epoch 2 batch 72 g_loss : 0.548814\n",
            "Epoch 2 batch 73 d_loss : 0.460026\n",
            "Epoch 2 batch 73 g_loss : 0.544220\n",
            "Epoch 2 batch 74 d_loss : 0.453564\n",
            "Epoch 2 batch 74 g_loss : 0.540885\n",
            "Epoch 2 batch 75 d_loss : 0.441764\n",
            "Epoch 2 batch 75 g_loss : 0.538298\n",
            "Epoch 2 batch 76 d_loss : 0.457031\n",
            "Epoch 2 batch 76 g_loss : 0.534239\n",
            "Epoch 2 batch 77 d_loss : 0.457136\n",
            "Epoch 2 batch 77 g_loss : 0.529363\n",
            "Epoch 2 batch 78 d_loss : 0.447682\n",
            "Epoch 2 batch 78 g_loss : 0.527049\n",
            "Epoch 2 batch 79 d_loss : 0.453478\n",
            "Epoch 2 batch 79 g_loss : 0.524179\n",
            "Epoch 2 batch 80 d_loss : 0.455324\n",
            "Epoch 2 batch 80 g_loss : 0.517911\n",
            "Epoch 2 batch 81 d_loss : 0.465953\n",
            "Epoch 2 batch 81 g_loss : 0.520226\n",
            "Epoch 2 batch 82 d_loss : 0.468988\n",
            "Epoch 2 batch 82 g_loss : 0.527810\n",
            "Epoch 2 batch 83 d_loss : 0.446234\n",
            "Epoch 2 batch 83 g_loss : 0.518320\n",
            "Epoch 2 batch 84 d_loss : 0.459012\n",
            "Epoch 2 batch 84 g_loss : 0.537352\n",
            "Epoch 2 batch 85 d_loss : 0.440723\n",
            "Epoch 2 batch 85 g_loss : 0.531068\n",
            "Epoch 2 batch 86 d_loss : 0.436850\n",
            "Epoch 2 batch 86 g_loss : 0.536893\n",
            "Epoch 2 batch 87 d_loss : 0.449422\n",
            "Epoch 2 batch 87 g_loss : 0.534836\n",
            "Epoch 2 batch 88 d_loss : 0.443061\n",
            "Epoch 2 batch 88 g_loss : 0.538259\n",
            "Epoch 2 batch 89 d_loss : 0.447176\n",
            "Epoch 2 batch 89 g_loss : 0.529769\n",
            "Epoch 2 batch 90 d_loss : 0.453364\n",
            "Epoch 2 batch 90 g_loss : 0.527833\n",
            "Epoch 2 batch 91 d_loss : 0.452285\n",
            "Epoch 2 batch 91 g_loss : 0.524830\n",
            "Epoch 2 batch 92 d_loss : 0.449386\n",
            "Epoch 2 batch 92 g_loss : 0.521667\n",
            "Epoch 2 batch 93 d_loss : 0.471655\n",
            "Epoch 2 batch 93 g_loss : 0.527029\n",
            "Epoch 2 batch 94 d_loss : 0.456678\n",
            "Epoch 2 batch 94 g_loss : 0.521006\n",
            "Epoch 2 batch 95 d_loss : 0.456289\n",
            "Epoch 2 batch 95 g_loss : 0.523038\n",
            "Epoch 2 batch 96 d_loss : 0.448159\n",
            "Epoch 2 batch 96 g_loss : 0.513354\n",
            "Epoch 2 batch 97 d_loss : 0.440906\n",
            "Epoch 2 batch 97 g_loss : 0.522933\n",
            "Epoch 2 batch 98 d_loss : 0.450560\n",
            "Epoch 2 batch 98 g_loss : 0.515550\n",
            "Epoch 2 batch 99 d_loss : 0.479352\n",
            "Epoch 2 batch 99 g_loss : 0.554066\n",
            "Epoch 2 batch 100 d_loss : 0.477334\n",
            "Epoch 2 batch 100 g_loss : 0.546457\n",
            "Epoch 2 batch 101 d_loss : 0.483655\n",
            "Epoch 2 batch 101 g_loss : 0.554498\n",
            "Epoch 2 batch 102 d_loss : 0.470685\n",
            "Epoch 2 batch 102 g_loss : 0.534175\n",
            "Epoch 2 batch 103 d_loss : 0.471911\n",
            "Epoch 2 batch 103 g_loss : 0.543998\n",
            "Epoch 2 batch 104 d_loss : 0.479590\n",
            "Epoch 2 batch 104 g_loss : 0.537994\n",
            "Epoch 2 batch 105 d_loss : 0.492006\n",
            "Epoch 2 batch 105 g_loss : 0.544522\n",
            "Epoch 2 batch 106 d_loss : 0.428037\n",
            "Epoch 2 batch 106 g_loss : 0.501637\n",
            "Epoch 2 batch 107 d_loss : 0.453986\n",
            "Epoch 2 batch 107 g_loss : 0.501348\n",
            "Epoch 2 batch 108 d_loss : 0.455719\n",
            "Epoch 2 batch 108 g_loss : 0.501340\n",
            "Epoch 2 batch 109 d_loss : 0.453390\n",
            "Epoch 2 batch 109 g_loss : 0.503117\n",
            "Epoch 2 batch 110 d_loss : 0.433850\n",
            "Epoch 2 batch 110 g_loss : 0.494951\n",
            "Epoch 2 batch 111 d_loss : 0.449469\n",
            "Epoch 2 batch 111 g_loss : 0.495376\n",
            "Epoch 2 batch 112 d_loss : 0.430145\n",
            "Epoch 2 batch 112 g_loss : 0.506093\n",
            "Epoch 2 batch 113 d_loss : 0.450047\n",
            "Epoch 2 batch 113 g_loss : 0.501466\n",
            "Epoch 2 batch 114 d_loss : 0.441654\n",
            "Epoch 2 batch 114 g_loss : 0.503300\n",
            "Epoch 2 batch 115 d_loss : 0.451003\n",
            "Epoch 2 batch 115 g_loss : 0.512296\n",
            "Epoch 2 batch 116 d_loss : 0.443841\n",
            "Epoch 2 batch 116 g_loss : 0.500951\n",
            "Epoch 2 batch 117 d_loss : 0.449977\n",
            "Epoch 2 batch 117 g_loss : 0.515811\n",
            "Epoch 2 batch 118 d_loss : 0.429165\n",
            "Epoch 2 batch 118 g_loss : 0.514188\n",
            "Epoch 2 batch 119 d_loss : 0.442267\n",
            "Epoch 2 batch 119 g_loss : 0.508983\n",
            "Epoch 2 batch 120 d_loss : 0.433387\n",
            "Epoch 2 batch 120 g_loss : 0.527149\n",
            "Epoch 2 batch 121 d_loss : 0.447785\n",
            "Epoch 2 batch 121 g_loss : 0.518486\n",
            "Epoch 2 batch 122 d_loss : 0.434468\n",
            "Epoch 2 batch 122 g_loss : 0.504047\n",
            "Epoch 2 batch 123 d_loss : 0.411896\n",
            "Epoch 2 batch 123 g_loss : 0.463992\n",
            "Epoch 2 batch 124 d_loss : 0.417691\n",
            "Epoch 2 batch 124 g_loss : 0.462850\n",
            "Epoch 2 batch 125 d_loss : 0.439206\n",
            "Epoch 2 batch 125 g_loss : 0.471323\n",
            "Epoch 2 batch 126 d_loss : 0.389077\n",
            "Epoch 2 batch 126 g_loss : 0.452629\n",
            "Epoch 2 batch 127 d_loss : 0.406141\n",
            "Epoch 2 batch 127 g_loss : 0.462640\n",
            "Epoch 2 batch 128 d_loss : 0.404008\n",
            "Epoch 2 batch 128 g_loss : 0.460357\n",
            "Epoch 2 batch 129 d_loss : 0.419335\n",
            "Epoch 2 batch 129 g_loss : 0.497655\n",
            "Epoch 2 batch 130 d_loss : 0.411010\n",
            "Epoch 2 batch 130 g_loss : 0.511531\n",
            "Epoch 2 batch 131 d_loss : 0.414375\n",
            "Epoch 2 batch 131 g_loss : 0.515902\n",
            "Epoch 2 batch 132 d_loss : 0.393902\n",
            "Epoch 2 batch 132 g_loss : 0.486488\n",
            "Epoch 2 batch 133 d_loss : 0.417824\n",
            "Epoch 2 batch 133 g_loss : 0.472989\n",
            "Epoch 2 batch 134 d_loss : 0.389034\n",
            "Epoch 2 batch 134 g_loss : 0.429778\n",
            "Epoch 2 batch 135 d_loss : 0.390489\n",
            "Epoch 2 batch 135 g_loss : 0.413069\n",
            "Epoch 2 batch 136 d_loss : 0.419934\n",
            "Epoch 2 batch 136 g_loss : 0.406067\n",
            "Epoch 2 batch 137 d_loss : 0.471362\n",
            "Epoch 2 batch 137 g_loss : 0.509045\n",
            "Epoch 2 batch 138 d_loss : 0.440856\n",
            "Epoch 2 batch 138 g_loss : 0.464709\n",
            "Epoch 2 batch 139 d_loss : 0.444364\n",
            "Epoch 2 batch 139 g_loss : 0.464103\n",
            "Epoch 2 batch 140 d_loss : 0.440535\n",
            "Epoch 2 batch 140 g_loss : 0.443986\n",
            "Epoch 2 batch 141 d_loss : 0.493586\n",
            "Epoch 2 batch 141 g_loss : 0.509343\n",
            "Epoch 2 batch 142 d_loss : 0.448135\n",
            "Epoch 2 batch 142 g_loss : 0.438015\n",
            "Epoch 2 batch 143 d_loss : 0.439226\n",
            "Epoch 2 batch 143 g_loss : 0.459349\n",
            "Epoch 2 batch 144 d_loss : 0.448240\n",
            "Epoch 2 batch 144 g_loss : 0.497691\n",
            "Epoch 2 batch 145 d_loss : 0.430928\n",
            "Epoch 2 batch 145 g_loss : 0.508323\n",
            "Epoch 2 batch 146 d_loss : 0.473771\n",
            "Epoch 2 batch 146 g_loss : 0.556813\n",
            "Epoch 2 batch 147 d_loss : 0.443531\n",
            "Epoch 2 batch 147 g_loss : 0.512912\n",
            "Epoch 2 batch 148 d_loss : 0.447759\n",
            "Epoch 2 batch 148 g_loss : 0.533320\n",
            "Epoch 2 batch 149 d_loss : 0.467596\n",
            "Epoch 2 batch 149 g_loss : 0.465549\n",
            "Epoch 2 batch 150 d_loss : 0.451715\n",
            "Epoch 2 batch 150 g_loss : 0.432460\n",
            "Epoch 2 batch 151 d_loss : 0.471071\n",
            "Epoch 2 batch 151 g_loss : 0.516344\n",
            "Epoch 2 batch 152 d_loss : 0.471247\n",
            "Epoch 2 batch 152 g_loss : 0.503092\n",
            "Epoch 2 batch 153 d_loss : 0.489877\n",
            "Epoch 2 batch 153 g_loss : 0.491783\n",
            "Epoch 2 batch 154 d_loss : 0.468356\n",
            "Epoch 2 batch 154 g_loss : 0.455270\n",
            "Epoch 2 batch 155 d_loss : 0.517466\n",
            "Epoch 2 batch 155 g_loss : 0.490530\n",
            "Epoch 2 batch 156 d_loss : 0.459193\n",
            "Epoch 2 batch 156 g_loss : 0.464462\n",
            "Epoch 2 batch 157 d_loss : 0.478313\n",
            "Epoch 2 batch 157 g_loss : 0.464137\n",
            "Epoch 2 batch 158 d_loss : 0.470123\n",
            "Epoch 2 batch 158 g_loss : 0.473020\n",
            "Epoch 2 batch 159 d_loss : 0.461706\n",
            "Epoch 2 batch 159 g_loss : 0.524090\n",
            "Epoch 2 batch 160 d_loss : 0.453192\n",
            "Epoch 2 batch 160 g_loss : 0.559030\n",
            "Epoch 2 batch 161 d_loss : 0.459308\n",
            "Epoch 2 batch 161 g_loss : 0.608938\n",
            "Epoch 2 batch 162 d_loss : 0.466425\n",
            "Epoch 2 batch 162 g_loss : 0.616304\n",
            "Epoch 2 batch 163 d_loss : 0.446992\n",
            "Epoch 2 batch 163 g_loss : 0.596299\n",
            "Epoch 2 batch 164 d_loss : 0.462762\n",
            "Epoch 2 batch 164 g_loss : 0.585607\n",
            "Epoch 2 batch 165 d_loss : 0.450769\n",
            "Epoch 2 batch 165 g_loss : 0.573187\n",
            "Epoch 2 batch 166 d_loss : 0.450819\n",
            "Epoch 2 batch 166 g_loss : 0.571045\n",
            "Epoch 2 batch 167 d_loss : 0.446442\n",
            "Epoch 2 batch 167 g_loss : 0.557100\n",
            "Epoch 2 batch 168 d_loss : 0.439145\n",
            "Epoch 2 batch 168 g_loss : 0.550860\n",
            "Epoch 2 batch 169 d_loss : 0.452596\n",
            "Epoch 2 batch 169 g_loss : 0.551888\n",
            "Epoch 2 batch 170 d_loss : 0.437622\n",
            "Epoch 2 batch 170 g_loss : 0.535197\n",
            "Epoch 2 batch 171 d_loss : 0.462612\n",
            "Epoch 2 batch 171 g_loss : 0.530789\n",
            "Epoch 2 batch 172 d_loss : 0.446867\n",
            "Epoch 2 batch 172 g_loss : 0.516690\n",
            "Epoch 2 batch 173 d_loss : 0.451825\n",
            "Epoch 2 batch 173 g_loss : 0.520014\n",
            "Epoch 2 batch 174 d_loss : 0.439064\n",
            "Epoch 2 batch 174 g_loss : 0.509072\n",
            "Epoch 2 batch 175 d_loss : 0.428253\n",
            "Epoch 2 batch 175 g_loss : 0.516521\n",
            "Epoch 2 batch 176 d_loss : 0.449881\n",
            "Epoch 2 batch 176 g_loss : 0.512915\n",
            "Epoch 2 batch 177 d_loss : 0.450924\n",
            "Epoch 2 batch 177 g_loss : 0.516337\n",
            "Epoch 2 batch 178 d_loss : 0.443374\n",
            "Epoch 2 batch 178 g_loss : 0.515841\n",
            "Epoch 2 batch 179 d_loss : 0.445757\n",
            "Epoch 2 batch 179 g_loss : 0.521319\n",
            "Epoch 2 batch 180 d_loss : 0.444965\n",
            "Epoch 2 batch 180 g_loss : 0.527648\n",
            "Epoch 2 batch 181 d_loss : 0.436928\n",
            "Epoch 2 batch 181 g_loss : 0.521172\n",
            "Epoch 2 batch 182 d_loss : 0.448086\n",
            "Epoch 2 batch 182 g_loss : 0.528072\n",
            "Epoch 2 batch 183 d_loss : 0.446603\n",
            "Epoch 2 batch 183 g_loss : 0.532995\n",
            "Epoch 2 batch 184 d_loss : 0.435826\n",
            "Epoch 2 batch 184 g_loss : 0.531537\n",
            "Epoch 2 batch 185 d_loss : 0.431703\n",
            "Epoch 2 batch 185 g_loss : 0.522972\n",
            "Epoch 2 batch 186 d_loss : 0.425520\n",
            "Epoch 2 batch 186 g_loss : 0.525213\n",
            "Epoch 2 batch 187 d_loss : 0.419883\n",
            "Epoch 2 batch 187 g_loss : 0.525398\n",
            "Epoch 2 batch 188 d_loss : 0.438417\n",
            "Epoch 2 batch 188 g_loss : 0.524999\n",
            "Epoch 2 batch 189 d_loss : 0.447226\n",
            "Epoch 2 batch 189 g_loss : 0.564813\n",
            "Epoch 2 batch 190 d_loss : 0.459527\n",
            "Epoch 2 batch 190 g_loss : 0.563035\n",
            "Epoch 2 batch 191 d_loss : 0.476822\n",
            "Epoch 2 batch 191 g_loss : 0.594413\n",
            "Epoch 2 batch 192 d_loss : 0.450780\n",
            "Epoch 2 batch 192 g_loss : 0.565819\n",
            "Epoch 2 batch 193 d_loss : 0.466806\n",
            "Epoch 2 batch 193 g_loss : 0.534648\n",
            "Epoch 2 batch 194 d_loss : 0.450163\n",
            "Epoch 2 batch 194 g_loss : 0.522323\n",
            "Epoch 2 batch 195 d_loss : 0.485313\n",
            "Epoch 2 batch 195 g_loss : 0.514970\n",
            "Epoch 2 batch 196 d_loss : 0.456097\n",
            "Epoch 2 batch 196 g_loss : 0.508414\n",
            "Epoch 2 batch 197 d_loss : 0.447992\n",
            "Epoch 2 batch 197 g_loss : 0.485692\n",
            "Epoch 2 batch 198 d_loss : 0.450251\n",
            "Epoch 2 batch 198 g_loss : 0.494818\n",
            "Epoch 2 batch 199 d_loss : 0.454113\n",
            "Epoch 2 batch 199 g_loss : 0.498316\n",
            "Epoch 2 batch 200 d_loss : 0.445662\n",
            "Epoch 2 batch 200 g_loss : 0.522322\n",
            "Epoch 2 batch 201 d_loss : 0.445886\n",
            "Epoch 2 batch 201 g_loss : 0.508207\n",
            "Epoch 2 batch 202 d_loss : 0.449563\n",
            "Epoch 2 batch 202 g_loss : 0.519966\n",
            "Epoch 2 batch 203 d_loss : 0.432130\n",
            "Epoch 2 batch 203 g_loss : 0.511512\n",
            "Epoch 2 batch 204 d_loss : 0.444758\n",
            "Epoch 2 batch 204 g_loss : 0.526222\n",
            "Epoch 2 batch 205 d_loss : 0.450247\n",
            "Epoch 2 batch 205 g_loss : 0.554459\n",
            "Epoch 2 batch 206 d_loss : 0.452700\n",
            "Epoch 2 batch 206 g_loss : 0.567095\n",
            "Epoch 2 batch 207 d_loss : 0.475803\n",
            "Epoch 2 batch 207 g_loss : 0.570974\n",
            "Epoch 2 batch 208 d_loss : 0.455292\n",
            "Epoch 2 batch 208 g_loss : 0.559265\n",
            "Epoch 2 batch 209 d_loss : 0.449125\n",
            "Epoch 2 batch 209 g_loss : 0.551611\n",
            "Epoch 2 batch 210 d_loss : 0.490787\n",
            "Epoch 2 batch 210 g_loss : 0.639603\n",
            "Epoch 2 batch 211 d_loss : 0.529142\n",
            "Epoch 2 batch 211 g_loss : 0.723214\n",
            "Epoch 2 batch 212 d_loss : 0.553110\n",
            "Epoch 2 batch 212 g_loss : 0.722453\n",
            "Epoch 2 batch 213 d_loss : 0.503670\n",
            "Epoch 2 batch 213 g_loss : 0.651827\n",
            "Epoch 2 batch 214 d_loss : 0.532242\n",
            "Epoch 2 batch 214 g_loss : 0.638372\n",
            "Epoch 2 batch 215 d_loss : 0.502302\n",
            "Epoch 2 batch 215 g_loss : 0.569207\n",
            "Epoch 2 batch 216 d_loss : 0.499186\n",
            "Epoch 2 batch 216 g_loss : 0.466909\n",
            "Epoch 2 batch 217 d_loss : 0.468536\n",
            "Epoch 2 batch 217 g_loss : 0.454033\n",
            "Epoch 2 batch 218 d_loss : 0.486872\n",
            "Epoch 2 batch 218 g_loss : 0.481861\n",
            "Epoch 2 batch 219 d_loss : 0.460468\n",
            "Epoch 2 batch 219 g_loss : 0.475087\n",
            "Epoch 2 batch 220 d_loss : 0.461573\n",
            "Epoch 2 batch 220 g_loss : 0.492698\n",
            "Epoch 2 batch 221 d_loss : 0.477784\n",
            "Epoch 2 batch 221 g_loss : 0.526410\n",
            "Epoch 2 batch 222 d_loss : 0.475252\n",
            "Epoch 2 batch 222 g_loss : 0.545083\n",
            "Epoch 2 batch 223 d_loss : 0.492886\n",
            "Epoch 2 batch 223 g_loss : 0.564415\n",
            "Epoch 2 batch 224 d_loss : 0.491051\n",
            "Epoch 2 batch 224 g_loss : 0.575812\n",
            "Epoch 2 batch 225 d_loss : 0.460988\n",
            "Epoch 2 batch 225 g_loss : 0.576553\n",
            "Epoch 2 batch 226 d_loss : 0.484283\n",
            "Epoch 2 batch 226 g_loss : 0.589564\n",
            "Epoch 2 batch 227 d_loss : 0.471715\n",
            "Epoch 2 batch 227 g_loss : 0.582930\n",
            "Epoch 2 batch 228 d_loss : 0.440521\n",
            "Epoch 2 batch 228 g_loss : 0.575161\n",
            "Epoch 2 batch 229 d_loss : 0.473989\n",
            "Epoch 2 batch 229 g_loss : 0.573822\n",
            "Epoch 2 batch 230 d_loss : 0.473066\n",
            "Epoch 2 batch 230 g_loss : 0.567649\n",
            "Epoch 2 batch 231 d_loss : 0.458948\n",
            "Epoch 2 batch 231 g_loss : 0.558973\n",
            "Epoch 2 batch 232 d_loss : 0.467631\n",
            "Epoch 2 batch 232 g_loss : 0.550705\n",
            "Epoch 2 batch 233 d_loss : 0.440762\n",
            "Epoch 2 batch 233 g_loss : 0.541840\n",
            "Epoch 2 batch 234 d_loss : 0.449556\n",
            "Epoch 2 batch 234 g_loss : 0.531997\n",
            "Epoch 2 batch 235 d_loss : 0.452700\n",
            "Epoch 2 batch 235 g_loss : 0.524744\n",
            "Epoch 2 batch 236 d_loss : 0.447427\n",
            "Epoch 2 batch 236 g_loss : 0.520503\n",
            "Epoch 2 batch 237 d_loss : 0.443514\n",
            "Epoch 2 batch 237 g_loss : 0.516991\n",
            "Epoch 2 batch 238 d_loss : 0.435830\n",
            "Epoch 2 batch 238 g_loss : 0.517313\n",
            "Epoch 2 batch 239 d_loss : 0.461395\n",
            "Epoch 2 batch 239 g_loss : 0.519179\n",
            "Epoch 2 batch 240 d_loss : 0.461820\n",
            "Epoch 2 batch 240 g_loss : 0.522525\n",
            "Epoch 2 batch 241 d_loss : 0.444825\n",
            "Epoch 2 batch 241 g_loss : 0.527602\n",
            "Epoch 2 batch 242 d_loss : 0.467339\n",
            "Epoch 2 batch 242 g_loss : 0.532357\n",
            "Epoch 2 batch 243 d_loss : 0.453977\n",
            "Epoch 2 batch 243 g_loss : 0.537989\n",
            "Epoch 2 batch 244 d_loss : 0.464516\n",
            "Epoch 2 batch 244 g_loss : 0.545867\n",
            "Epoch 2 batch 245 d_loss : 0.485820\n",
            "Epoch 2 batch 245 g_loss : 0.553766\n",
            "Epoch 2 batch 246 d_loss : 0.468446\n",
            "Epoch 2 batch 246 g_loss : 0.553147\n",
            "Epoch 2 batch 247 d_loss : 0.465203\n",
            "Epoch 2 batch 247 g_loss : 0.554442\n",
            "Epoch 2 batch 248 d_loss : 0.462129\n",
            "Epoch 2 batch 248 g_loss : 0.551737\n",
            "Epoch 2 batch 249 d_loss : 0.451122\n",
            "Epoch 2 batch 249 g_loss : 0.549249\n",
            "Epoch 2 batch 250 d_loss : 0.466264\n",
            "Epoch 2 batch 250 g_loss : 0.541093\n",
            "Epoch 2 batch 251 d_loss : 0.468951\n",
            "Epoch 2 batch 251 g_loss : 0.540992\n",
            "Epoch 2 batch 252 d_loss : 0.468201\n",
            "Epoch 2 batch 252 g_loss : 0.535443\n",
            "Epoch 2 batch 253 d_loss : 0.455368\n",
            "Epoch 2 batch 253 g_loss : 0.533314\n",
            "Epoch 2 batch 254 d_loss : 0.464268\n",
            "Epoch 2 batch 254 g_loss : 0.529492\n",
            "Epoch 2 batch 255 d_loss : 0.459618\n",
            "Epoch 2 batch 255 g_loss : 0.535533\n",
            "Epoch 2 batch 256 d_loss : 0.456128\n",
            "Epoch 2 batch 256 g_loss : 0.537994\n",
            "Epoch 2 batch 257 d_loss : 0.458890\n",
            "Epoch 2 batch 257 g_loss : 0.533709\n",
            "Epoch 2 batch 258 d_loss : 0.471864\n",
            "Epoch 2 batch 258 g_loss : 0.534481\n",
            "Epoch 2 batch 259 d_loss : 0.455789\n",
            "Epoch 2 batch 259 g_loss : 0.535693\n",
            "Epoch 2 batch 260 d_loss : 0.443787\n",
            "Epoch 2 batch 260 g_loss : 0.532750\n",
            "Epoch 2 batch 261 d_loss : 0.453015\n",
            "Epoch 2 batch 261 g_loss : 0.536931\n",
            "Epoch 2 batch 262 d_loss : 0.462413\n",
            "Epoch 2 batch 262 g_loss : 0.533126\n",
            "Epoch 2 batch 263 d_loss : 0.460162\n",
            "Epoch 2 batch 263 g_loss : 0.538781\n",
            "Epoch 2 batch 264 d_loss : 0.457791\n",
            "Epoch 2 batch 264 g_loss : 0.542146\n",
            "Epoch 2 batch 265 d_loss : 0.459144\n",
            "Epoch 2 batch 265 g_loss : 0.536769\n",
            "Epoch 2 batch 266 d_loss : 0.462606\n",
            "Epoch 2 batch 266 g_loss : 0.532443\n",
            "Epoch 2 batch 267 d_loss : 0.462789\n",
            "Epoch 2 batch 267 g_loss : 0.538112\n",
            "Epoch 2 batch 268 d_loss : 0.461450\n",
            "Epoch 2 batch 268 g_loss : 0.535895\n",
            "Epoch 2 batch 269 d_loss : 0.437721\n",
            "Epoch 2 batch 269 g_loss : 0.530058\n",
            "Epoch 2 batch 270 d_loss : 0.464969\n",
            "Epoch 2 batch 270 g_loss : 0.550197\n",
            "Epoch 2 batch 271 d_loss : 0.464350\n",
            "Epoch 2 batch 271 g_loss : 0.560125\n",
            "Epoch 2 batch 272 d_loss : 0.459840\n",
            "Epoch 2 batch 272 g_loss : 0.545927\n",
            "Epoch 2 batch 273 d_loss : 0.466440\n",
            "Epoch 2 batch 273 g_loss : 0.546294\n",
            "Epoch 2 batch 274 d_loss : 0.453281\n",
            "Epoch 2 batch 274 g_loss : 0.534734\n",
            "Epoch 2 batch 275 d_loss : 0.449292\n",
            "Epoch 2 batch 275 g_loss : 0.515045\n",
            "Epoch 2 batch 276 d_loss : 0.448084\n",
            "Epoch 2 batch 276 g_loss : 0.517115\n",
            "Epoch 2 batch 277 d_loss : 0.455364\n",
            "Epoch 2 batch 277 g_loss : 0.521571\n",
            "Epoch 2 batch 278 d_loss : 0.454607\n",
            "Epoch 2 batch 278 g_loss : 0.522422\n",
            "Epoch 2 batch 279 d_loss : 0.444393\n",
            "Epoch 2 batch 279 g_loss : 0.512608\n",
            "Epoch 2 batch 280 d_loss : 0.452724\n",
            "Epoch 2 batch 280 g_loss : 0.534267\n",
            "Epoch 2 batch 281 d_loss : 0.437146\n",
            "Epoch 2 batch 281 g_loss : 0.548238\n",
            "Epoch 2 batch 282 d_loss : 0.450503\n",
            "Epoch 2 batch 282 g_loss : 0.555240\n",
            "Epoch 2 batch 283 d_loss : 0.446387\n",
            "Epoch 2 batch 283 g_loss : 0.552340\n",
            "Epoch 2 batch 284 d_loss : 0.467283\n",
            "Epoch 2 batch 284 g_loss : 0.567977\n",
            "Epoch 2 batch 285 d_loss : 0.481480\n",
            "Epoch 2 batch 285 g_loss : 0.592739\n",
            "Epoch 2 batch 286 d_loss : 0.461807\n",
            "Epoch 2 batch 286 g_loss : 0.595508\n",
            "Epoch 2 batch 287 d_loss : 0.450966\n",
            "Epoch 2 batch 287 g_loss : 0.574480\n",
            "Epoch 2 batch 288 d_loss : 0.460514\n",
            "Epoch 2 batch 288 g_loss : 0.574405\n",
            "Epoch 2 batch 289 d_loss : 0.444935\n",
            "Epoch 2 batch 289 g_loss : 0.542262\n",
            "Epoch 2 batch 290 d_loss : 0.454081\n",
            "Epoch 2 batch 290 g_loss : 0.534105\n",
            "Epoch 2 batch 291 d_loss : 0.464479\n",
            "Epoch 2 batch 291 g_loss : 0.518717\n",
            "Epoch 2 batch 292 d_loss : 0.452565\n",
            "Epoch 2 batch 292 g_loss : 0.511185\n",
            "Epoch 2 batch 293 d_loss : 0.460320\n",
            "Epoch 2 batch 293 g_loss : 0.511772\n",
            "Epoch 2 batch 294 d_loss : 0.443733\n",
            "Epoch 2 batch 294 g_loss : 0.507145\n",
            "Epoch 2 batch 295 d_loss : 0.460651\n",
            "Epoch 2 batch 295 g_loss : 0.506504\n",
            "Epoch 2 batch 296 d_loss : 0.453708\n",
            "Epoch 2 batch 296 g_loss : 0.517498\n",
            "Epoch 2 batch 297 d_loss : 0.465297\n",
            "Epoch 2 batch 297 g_loss : 0.529402\n",
            "Epoch 2 batch 298 d_loss : 0.454913\n",
            "Epoch 2 batch 298 g_loss : 0.554056\n",
            "Epoch 2 batch 299 d_loss : 0.461988\n",
            "Epoch 2 batch 299 g_loss : 0.566799\n",
            "Epoch 2 batch 300 d_loss : 0.469955\n",
            "Epoch 2 batch 300 g_loss : 0.575191\n",
            "Epoch 2 batch 301 d_loss : 0.479070\n",
            "Epoch 2 batch 301 g_loss : 0.569220\n",
            "Epoch 2 batch 302 d_loss : 0.449530\n",
            "Epoch 2 batch 302 g_loss : 0.549400\n",
            "Epoch 2 batch 303 d_loss : 0.458874\n",
            "Epoch 2 batch 303 g_loss : 0.557842\n",
            "Epoch 2 batch 304 d_loss : 0.445702\n",
            "Epoch 2 batch 304 g_loss : 0.535430\n",
            "Epoch 2 batch 305 d_loss : 0.474136\n",
            "Epoch 2 batch 305 g_loss : 0.538198\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-5237a147dc89>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;31m#train the discriminator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mdiscriminator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     d_loss = discriminator.train_on_batch([np.concatenate((image_batch_real, generated_images,image_batch_wrong)),\n\u001b[0m\u001b[1;32m     21\u001b[0m                                                             np.concatenate((text_batch_real, text_batch_real, text_batch_wrong))],\n\u001b[1;32m     22\u001b[0m                                                            np.array([1] * batch_size*10 + [0] * batch_size*10 + [0] * batch_size*10))\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "eWDw7gG6u8BK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}